{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DACON_DNN(lr tuning).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "clI653pQu7Tz",
        "colab_type": "code",
        "outputId": "dfa374cd-01a3-4e84-a959-b3d3762a5bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJ-sGIAw3k1X",
        "outputId": "3a7f5755-faba-4aed-a18a-92f3d0df1e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "\n",
        "# 0. 패키지 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train.csv', index_col=0) # 코랩 사용 시 경로(/content/drive/My Drive/Colab Notebooks/) 추가\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/test.csv', index_col=0)\n",
        "sample_submission = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sample_submission.csv', index_col=0)\n",
        "\n",
        "# 2. Train 데이터의 타입을 Sample_submission에 대응하는 가변수 형태로 변환\n",
        "column_number = {}\n",
        "for i, column in enumerate(sample_submission.columns):\n",
        "    column_number[column] = i\n",
        "    \n",
        "def to_number(x, dic):\n",
        "    return dic[x]\n",
        "\n",
        "train['type_num'] = train['type'].apply(lambda x : to_number(x, column_number))\n",
        "\n",
        "# 3.모델에 적용할 데이터 셋 준비 \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, Normalizer\n",
        "\n",
        "train_x = train.drop(columns=['type', 'type_num'], axis=1)\n",
        "del train_x['fiberID']\n",
        "train_y = train['type_num']\n",
        "test_x = test\n",
        "del test_x['fiberID']\n",
        "\n",
        "train_x.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>psfMag_u</th>\n",
              "      <th>psfMag_g</th>\n",
              "      <th>psfMag_r</th>\n",
              "      <th>psfMag_i</th>\n",
              "      <th>psfMag_z</th>\n",
              "      <th>fiberMag_u</th>\n",
              "      <th>fiberMag_g</th>\n",
              "      <th>fiberMag_r</th>\n",
              "      <th>fiberMag_i</th>\n",
              "      <th>fiberMag_z</th>\n",
              "      <th>petroMag_u</th>\n",
              "      <th>petroMag_g</th>\n",
              "      <th>petroMag_r</th>\n",
              "      <th>petroMag_i</th>\n",
              "      <th>petroMag_z</th>\n",
              "      <th>modelMag_u</th>\n",
              "      <th>modelMag_g</th>\n",
              "      <th>modelMag_r</th>\n",
              "      <th>modelMag_i</th>\n",
              "      <th>modelMag_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.999910e+05</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>1.999910e+05</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-6.750146e+00</td>\n",
              "      <td>18.675373</td>\n",
              "      <td>18.401235</td>\n",
              "      <td>18.043495</td>\n",
              "      <td>17.663526</td>\n",
              "      <td>1.084986e+01</td>\n",
              "      <td>19.072693</td>\n",
              "      <td>19.134483</td>\n",
              "      <td>18.183331</td>\n",
              "      <td>18.000882</td>\n",
              "      <td>21.837903</td>\n",
              "      <td>18.454136</td>\n",
              "      <td>18.481525</td>\n",
              "      <td>17.686617</td>\n",
              "      <td>17.699207</td>\n",
              "      <td>20.110991</td>\n",
              "      <td>18.544375</td>\n",
              "      <td>18.181544</td>\n",
              "      <td>17.692395</td>\n",
              "      <td>17.189281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.187678e+04</td>\n",
              "      <td>155.423024</td>\n",
              "      <td>127.128078</td>\n",
              "      <td>116.622194</td>\n",
              "      <td>123.735298</td>\n",
              "      <td>4.172116e+03</td>\n",
              "      <td>749.256162</td>\n",
              "      <td>90.049058</td>\n",
              "      <td>122.378972</td>\n",
              "      <td>145.862346</td>\n",
              "      <td>789.472333</td>\n",
              "      <td>154.376277</td>\n",
              "      <td>97.240448</td>\n",
              "      <td>145.730872</td>\n",
              "      <td>142.691880</td>\n",
              "      <td>122.299062</td>\n",
              "      <td>161.728183</td>\n",
              "      <td>133.984475</td>\n",
              "      <td>131.183416</td>\n",
              "      <td>133.685138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-5.310802e+06</td>\n",
              "      <td>-40022.466071</td>\n",
              "      <td>-27184.795793</td>\n",
              "      <td>-26566.310827</td>\n",
              "      <td>-24878.828280</td>\n",
              "      <td>-1.864766e+06</td>\n",
              "      <td>-215882.917191</td>\n",
              "      <td>-21802.656144</td>\n",
              "      <td>-20208.516262</td>\n",
              "      <td>-26505.602101</td>\n",
              "      <td>-24463.431833</td>\n",
              "      <td>-25958.752324</td>\n",
              "      <td>-23948.588523</td>\n",
              "      <td>-40438.184078</td>\n",
              "      <td>-30070.729379</td>\n",
              "      <td>-26236.578659</td>\n",
              "      <td>-36902.402336</td>\n",
              "      <td>-36439.638493</td>\n",
              "      <td>-38969.416822</td>\n",
              "      <td>-26050.710196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.965259e+01</td>\n",
              "      <td>18.701180</td>\n",
              "      <td>18.048572</td>\n",
              "      <td>17.747663</td>\n",
              "      <td>17.425523</td>\n",
              "      <td>1.994040e+01</td>\n",
              "      <td>18.902851</td>\n",
              "      <td>18.259352</td>\n",
              "      <td>17.903615</td>\n",
              "      <td>17.606148</td>\n",
              "      <td>19.247795</td>\n",
              "      <td>18.113933</td>\n",
              "      <td>17.479794</td>\n",
              "      <td>17.050294</td>\n",
              "      <td>16.804705</td>\n",
              "      <td>19.266214</td>\n",
              "      <td>18.076120</td>\n",
              "      <td>17.423425</td>\n",
              "      <td>16.977671</td>\n",
              "      <td>16.705774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.087136e+01</td>\n",
              "      <td>19.904235</td>\n",
              "      <td>19.454492</td>\n",
              "      <td>19.043895</td>\n",
              "      <td>18.611799</td>\n",
              "      <td>2.104910e+01</td>\n",
              "      <td>20.069038</td>\n",
              "      <td>19.631419</td>\n",
              "      <td>19.188763</td>\n",
              "      <td>18.710967</td>\n",
              "      <td>20.366848</td>\n",
              "      <td>19.586559</td>\n",
              "      <td>19.182789</td>\n",
              "      <td>18.693370</td>\n",
              "      <td>18.174592</td>\n",
              "      <td>20.406840</td>\n",
              "      <td>19.547674</td>\n",
              "      <td>19.143156</td>\n",
              "      <td>18.641756</td>\n",
              "      <td>18.100997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.216043e+01</td>\n",
              "      <td>21.150297</td>\n",
              "      <td>20.515936</td>\n",
              "      <td>20.073528</td>\n",
              "      <td>19.883760</td>\n",
              "      <td>2.233754e+01</td>\n",
              "      <td>21.385830</td>\n",
              "      <td>20.773911</td>\n",
              "      <td>20.331419</td>\n",
              "      <td>20.133179</td>\n",
              "      <td>21.797480</td>\n",
              "      <td>21.004397</td>\n",
              "      <td>20.457491</td>\n",
              "      <td>20.019112</td>\n",
              "      <td>19.807652</td>\n",
              "      <td>21.992898</td>\n",
              "      <td>20.962386</td>\n",
              "      <td>20.408140</td>\n",
              "      <td>19.968846</td>\n",
              "      <td>19.819554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.877392e+04</td>\n",
              "      <td>3538.984910</td>\n",
              "      <td>3048.110913</td>\n",
              "      <td>4835.218639</td>\n",
              "      <td>9823.740407</td>\n",
              "      <td>4.870154e+03</td>\n",
              "      <td>248077.513380</td>\n",
              "      <td>12084.735440</td>\n",
              "      <td>8059.638535</td>\n",
              "      <td>18358.921741</td>\n",
              "      <td>298771.019041</td>\n",
              "      <td>12139.815877</td>\n",
              "      <td>7003.136546</td>\n",
              "      <td>9772.190537</td>\n",
              "      <td>17403.789263</td>\n",
              "      <td>14488.251976</td>\n",
              "      <td>10582.058590</td>\n",
              "      <td>12237.951703</td>\n",
              "      <td>4062.499371</td>\n",
              "      <td>7420.534172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           psfMag_u       psfMag_g  ...     modelMag_i     modelMag_z\n",
              "count  1.999910e+05  199991.000000  ...  199991.000000  199991.000000\n",
              "mean  -6.750146e+00      18.675373  ...      17.692395      17.189281\n",
              "std    1.187678e+04     155.423024  ...     131.183416     133.685138\n",
              "min   -5.310802e+06  -40022.466071  ...  -38969.416822  -26050.710196\n",
              "25%    1.965259e+01      18.701180  ...      16.977671      16.705774\n",
              "50%    2.087136e+01      19.904235  ...      18.641756      18.100997\n",
              "75%    2.216043e+01      21.150297  ...      19.968846      19.819554\n",
              "max    1.877392e+04    3538.984910  ...    4062.499371    7420.534172\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w_vtUJkLB4Hz",
        "colab": {}
      },
      "source": [
        "# 간단한 이상치 제거\n",
        "\n",
        "# 0.985,0.015\n",
        "x = train_x.copy() \n",
        "\n",
        "down_quantiles = x.quantile(0.002) # 전처리 비율 조정\n",
        "up_quantiles = x.quantile(0.998)\n",
        "\n",
        "outliers_low = (x < down_quantiles)\n",
        "outliers_high = (x > up_quantiles)\n",
        "\n",
        "x[outliers_low] = np.nan\n",
        "x.fillna(down_quantiles, inplace=True)\n",
        "\n",
        "x[outliers_high] = np.nan\n",
        "x.fillna(up_quantiles, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt6kLovCumdY",
        "colab_type": "code",
        "outputId": "1121da4b-5fb6-4341-84f7-48c5960e4fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x.hist(bins=50, figsize=(15, 15))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f1fc9034b70>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb896860>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb846e10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb802400>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb7b29b0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb765f60>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb7a2550>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb753b38>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb753b70>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb6c06a0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb672c50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb62d240>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb65c7f0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb60fda0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb5cc390>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb57c940>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb52def0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb4ea4e0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb51aa90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1fbb4d9080>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAANeCAYAAABEbnxYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzP8AYHg5F5vjavIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UuwQMDFl3k1c",
        "outputId": "34544a9a-a29e-43df-ad87-35b0a5396661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x = x.values\n",
        "train_y = train_y.values\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, train_y, train_size=0.9)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder()\n",
        "y_train = y_train.reshape(len(y_train), -1) \n",
        "y_val = y_val.reshape(len(y_val), -1)\n",
        "y_train = onehot_encoder.fit_transform(y_train)\n",
        "y_val = onehot_encoder.fit_transform(y_val)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(179991, 20)\n",
            "(179991, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "475ff_Tk3k1e",
        "outputId": "0a3acdcb-fd87-4a20-bd33-703a367b4ca1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_val_scaled = scaler.transform(x_val)\n",
        "\n",
        "# 4. 모델 생성하기\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, LeakyReLU\n",
        "from keras import regularizers, optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_shape=(20,))) #0.0007 # 정규화가 어느 정도 된 상태라서..?\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.07))\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.07))\n",
        "model.add(Dropout(0.45))\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization()) \n",
        "model.add(LeakyReLU(alpha=0.07))\n",
        "model.add(Dropout(0.45))\n",
        "model.add(Dense(256))\n",
        "model.add(LeakyReLU(alpha=0.07))\n",
        "model.add(Dropout(0.45))\n",
        "model.add(Dense(256))\n",
        "model.add(LeakyReLU(alpha=0.07))\n",
        "model.add(Dropout(0.45))\n",
        "model.add(Dense(19, activation='softmax'))\n",
        "\n",
        "\n",
        "# 5. 모델 훈련시키기 \n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=800, mode='min')\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "hist = model.fit(x_train_scaled,y_train, epochs=5000, batch_size=256, validation_data = [x_val_scaled, y_val], callbacks=[early_stopping])\n",
        "\n",
        "# # 6. 평가 검증하기\n",
        "loss, acc = model.evaluate(x_val_scaled, y_val)\n",
        "print('loss :', loss)\n",
        "print('acc :', acc)\n",
        "\n",
        "# 7. 예측\n",
        "test_x_scaled = scaler.transform(test_x)\n",
        "y_pred = model.predict(test_x_scaled)\n",
        "\n",
        "\n",
        "# 8. 제출 파일 생성\n",
        "submission = pd.DataFrame(data=y_pred, columns=sample_submission.columns, index=sample_submission.index)\n",
        "submission.to_csv('submission(11).csv', index=True)\n",
        "\n",
        "\n",
        "# early stopping patience 200 이상일 경우 overfitting\n",
        "# Dropout 0.3 이하 overfitting 발생\n",
        "# hidden layer 4개 이하 overfitting 발생\n",
        "# node = 512일 경우 overfitting 발생\n",
        "\n",
        "# 가장 기록 좋았을 때\n",
        "# model = Sequential()\n",
        "\n",
        "# model.add(Dense(128, input_shape=(20,)))\n",
        "# model.add(LeakyReLU(alpha=0.07))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dense(256))\n",
        "# model.add(LeakyReLU(alpha=0.07))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.45))\n",
        "# model.add(Dense(256))\n",
        "# model.add(LeakyReLU(alpha=0.07))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.45))\n",
        "# model.add(Dense(256))\n",
        "# model.add(LeakyReLU(alpha=0.07))\n",
        "# model.add(Dropout(0.45))\n",
        "# model.add(Dense(256))\n",
        "# model.add(LeakyReLU(alpha=0.07))\n",
        "# model.add(Dropout(0.45))\n",
        "# model.add(Dense(19, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 179991 samples, validate on 20000 samples\n",
            "Epoch 1/5000\n",
            "179991/179991 [==============================] - 10s 56us/step - loss: 0.7729 - acc: 0.7593 - val_loss: 0.5777 - val_acc: 0.7882\n",
            "Epoch 2/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.5836 - acc: 0.8105 - val_loss: 0.4881 - val_acc: 0.8338\n",
            "Epoch 3/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.5509 - acc: 0.8177 - val_loss: 0.4731 - val_acc: 0.8374\n",
            "Epoch 4/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.5297 - acc: 0.8235 - val_loss: 0.4564 - val_acc: 0.8400\n",
            "Epoch 5/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.5195 - acc: 0.8266 - val_loss: 0.4578 - val_acc: 0.8420\n",
            "Epoch 6/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.5090 - acc: 0.8295 - val_loss: 0.4621 - val_acc: 0.8404\n",
            "Epoch 7/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.5017 - acc: 0.8315 - val_loss: 0.4465 - val_acc: 0.8431\n",
            "Epoch 8/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4969 - acc: 0.8335 - val_loss: 0.4291 - val_acc: 0.8516\n",
            "Epoch 9/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4916 - acc: 0.8345 - val_loss: 0.4432 - val_acc: 0.8481\n",
            "Epoch 10/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4885 - acc: 0.8354 - val_loss: 0.4538 - val_acc: 0.8385\n",
            "Epoch 11/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4846 - acc: 0.8357 - val_loss: 0.4222 - val_acc: 0.8535\n",
            "Epoch 12/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4792 - acc: 0.8383 - val_loss: 0.4206 - val_acc: 0.8525\n",
            "Epoch 13/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4765 - acc: 0.8388 - val_loss: 0.4262 - val_acc: 0.8495\n",
            "Epoch 14/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4765 - acc: 0.8385 - val_loss: 0.4160 - val_acc: 0.8526\n",
            "Epoch 15/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4712 - acc: 0.8405 - val_loss: 0.4138 - val_acc: 0.8546\n",
            "Epoch 16/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4710 - acc: 0.8399 - val_loss: 0.4352 - val_acc: 0.8488\n",
            "Epoch 17/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4701 - acc: 0.8405 - val_loss: 0.4420 - val_acc: 0.8471\n",
            "Epoch 18/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4680 - acc: 0.8404 - val_loss: 0.4296 - val_acc: 0.8514\n",
            "Epoch 19/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4662 - acc: 0.8413 - val_loss: 0.4424 - val_acc: 0.8446\n",
            "Epoch 20/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4669 - acc: 0.8408 - val_loss: 0.4113 - val_acc: 0.8561\n",
            "Epoch 21/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4609 - acc: 0.8427 - val_loss: 0.4122 - val_acc: 0.8587\n",
            "Epoch 22/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4574 - acc: 0.8445 - val_loss: 0.4130 - val_acc: 0.8580\n",
            "Epoch 23/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4605 - acc: 0.8425 - val_loss: 0.4283 - val_acc: 0.8470\n",
            "Epoch 24/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4588 - acc: 0.8435 - val_loss: 0.4082 - val_acc: 0.8581\n",
            "Epoch 25/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4586 - acc: 0.8436 - val_loss: 0.4073 - val_acc: 0.8568\n",
            "Epoch 26/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4575 - acc: 0.8436 - val_loss: 0.4119 - val_acc: 0.8577\n",
            "Epoch 27/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4565 - acc: 0.8437 - val_loss: 0.4113 - val_acc: 0.8575\n",
            "Epoch 28/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4528 - acc: 0.8457 - val_loss: 0.4021 - val_acc: 0.8603\n",
            "Epoch 29/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4529 - acc: 0.8449 - val_loss: 0.4098 - val_acc: 0.8571\n",
            "Epoch 30/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4536 - acc: 0.8444 - val_loss: 0.4142 - val_acc: 0.8557\n",
            "Epoch 31/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4520 - acc: 0.8461 - val_loss: 0.4008 - val_acc: 0.8612\n",
            "Epoch 32/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4501 - acc: 0.8459 - val_loss: 0.4045 - val_acc: 0.8585\n",
            "Epoch 33/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4490 - acc: 0.8462 - val_loss: 0.4138 - val_acc: 0.8572\n",
            "Epoch 34/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4501 - acc: 0.8462 - val_loss: 0.4021 - val_acc: 0.8581\n",
            "Epoch 35/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4482 - acc: 0.8465 - val_loss: 0.4115 - val_acc: 0.8568\n",
            "Epoch 36/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4485 - acc: 0.8477 - val_loss: 0.4111 - val_acc: 0.8552\n",
            "Epoch 37/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4486 - acc: 0.8467 - val_loss: 0.3971 - val_acc: 0.8613\n",
            "Epoch 38/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4472 - acc: 0.8470 - val_loss: 0.4492 - val_acc: 0.8367\n",
            "Epoch 39/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4471 - acc: 0.8470 - val_loss: 0.4088 - val_acc: 0.8559\n",
            "Epoch 40/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4472 - acc: 0.8467 - val_loss: 0.3949 - val_acc: 0.8638\n",
            "Epoch 41/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4446 - acc: 0.8482 - val_loss: 0.3957 - val_acc: 0.8621\n",
            "Epoch 42/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4443 - acc: 0.8480 - val_loss: 0.3969 - val_acc: 0.8637\n",
            "Epoch 43/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4428 - acc: 0.8486 - val_loss: 0.4006 - val_acc: 0.8591\n",
            "Epoch 44/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4442 - acc: 0.8477 - val_loss: 0.3946 - val_acc: 0.8613\n",
            "Epoch 45/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4447 - acc: 0.8480 - val_loss: 0.3986 - val_acc: 0.8599\n",
            "Epoch 46/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4418 - acc: 0.8487 - val_loss: 0.3921 - val_acc: 0.8611\n",
            "Epoch 47/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4422 - acc: 0.8488 - val_loss: 0.3991 - val_acc: 0.8604\n",
            "Epoch 48/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4404 - acc: 0.8494 - val_loss: 0.3906 - val_acc: 0.8633\n",
            "Epoch 49/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4417 - acc: 0.8483 - val_loss: 0.4213 - val_acc: 0.8556\n",
            "Epoch 50/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4422 - acc: 0.8478 - val_loss: 0.3963 - val_acc: 0.8625\n",
            "Epoch 51/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4438 - acc: 0.8475 - val_loss: 0.3991 - val_acc: 0.8616\n",
            "Epoch 52/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4404 - acc: 0.8485 - val_loss: 0.3993 - val_acc: 0.8586\n",
            "Epoch 53/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4398 - acc: 0.8494 - val_loss: 0.3963 - val_acc: 0.8614\n",
            "Epoch 54/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4408 - acc: 0.8489 - val_loss: 0.3934 - val_acc: 0.8635\n",
            "Epoch 55/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4364 - acc: 0.8501 - val_loss: 0.4006 - val_acc: 0.8612\n",
            "Epoch 56/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4366 - acc: 0.8500 - val_loss: 0.4089 - val_acc: 0.8583\n",
            "Epoch 57/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4394 - acc: 0.8504 - val_loss: 0.4002 - val_acc: 0.8596\n",
            "Epoch 58/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4377 - acc: 0.8499 - val_loss: 0.4018 - val_acc: 0.8616\n",
            "Epoch 59/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4391 - acc: 0.8493 - val_loss: 0.3881 - val_acc: 0.8654\n",
            "Epoch 60/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4355 - acc: 0.8504 - val_loss: 0.4038 - val_acc: 0.8572\n",
            "Epoch 61/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4373 - acc: 0.8492 - val_loss: 0.3917 - val_acc: 0.8612\n",
            "Epoch 62/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4342 - acc: 0.8508 - val_loss: 0.3897 - val_acc: 0.8628\n",
            "Epoch 63/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4354 - acc: 0.8507 - val_loss: 0.3936 - val_acc: 0.8609\n",
            "Epoch 64/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4355 - acc: 0.8497 - val_loss: 0.3967 - val_acc: 0.8630\n",
            "Epoch 65/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4353 - acc: 0.8504 - val_loss: 0.4456 - val_acc: 0.8377\n",
            "Epoch 66/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4354 - acc: 0.8505 - val_loss: 0.3900 - val_acc: 0.8641\n",
            "Epoch 67/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4349 - acc: 0.8499 - val_loss: 0.3942 - val_acc: 0.8624\n",
            "Epoch 68/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4329 - acc: 0.8511 - val_loss: 0.3913 - val_acc: 0.8625\n",
            "Epoch 69/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4353 - acc: 0.8503 - val_loss: 0.3959 - val_acc: 0.8610\n",
            "Epoch 70/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4364 - acc: 0.8497 - val_loss: 0.3960 - val_acc: 0.8616\n",
            "Epoch 71/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4333 - acc: 0.8513 - val_loss: 0.3869 - val_acc: 0.8649\n",
            "Epoch 72/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4352 - acc: 0.8504 - val_loss: 0.3941 - val_acc: 0.8613\n",
            "Epoch 73/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4326 - acc: 0.8503 - val_loss: 0.3874 - val_acc: 0.8658\n",
            "Epoch 74/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4333 - acc: 0.8516 - val_loss: 0.3870 - val_acc: 0.8649\n",
            "Epoch 75/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4336 - acc: 0.8511 - val_loss: 0.3938 - val_acc: 0.8633\n",
            "Epoch 76/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4332 - acc: 0.8507 - val_loss: 0.3862 - val_acc: 0.8653\n",
            "Epoch 77/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4330 - acc: 0.8514 - val_loss: 0.3869 - val_acc: 0.8657\n",
            "Epoch 78/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4331 - acc: 0.8513 - val_loss: 0.3897 - val_acc: 0.8635\n",
            "Epoch 79/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4333 - acc: 0.8505 - val_loss: 0.3993 - val_acc: 0.8619\n",
            "Epoch 80/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4313 - acc: 0.8519 - val_loss: 0.3992 - val_acc: 0.8622\n",
            "Epoch 81/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4295 - acc: 0.8522 - val_loss: 0.3883 - val_acc: 0.8641\n",
            "Epoch 82/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4338 - acc: 0.8512 - val_loss: 0.3894 - val_acc: 0.8629\n",
            "Epoch 83/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4303 - acc: 0.8517 - val_loss: 0.3879 - val_acc: 0.8657\n",
            "Epoch 84/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4304 - acc: 0.8516 - val_loss: 0.4031 - val_acc: 0.8575\n",
            "Epoch 85/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4294 - acc: 0.8522 - val_loss: 0.3844 - val_acc: 0.8652\n",
            "Epoch 86/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4322 - acc: 0.8514 - val_loss: 0.3843 - val_acc: 0.8644\n",
            "Epoch 87/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4296 - acc: 0.8517 - val_loss: 0.3910 - val_acc: 0.8621\n",
            "Epoch 88/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4294 - acc: 0.8524 - val_loss: 0.3971 - val_acc: 0.8624\n",
            "Epoch 89/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4325 - acc: 0.8514 - val_loss: 0.3848 - val_acc: 0.8643\n",
            "Epoch 90/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4296 - acc: 0.8524 - val_loss: 0.3899 - val_acc: 0.8628\n",
            "Epoch 91/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4274 - acc: 0.8527 - val_loss: 0.4088 - val_acc: 0.8548\n",
            "Epoch 92/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4275 - acc: 0.8528 - val_loss: 0.3922 - val_acc: 0.8612\n",
            "Epoch 93/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4299 - acc: 0.8521 - val_loss: 0.4040 - val_acc: 0.8575\n",
            "Epoch 94/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4295 - acc: 0.8529 - val_loss: 0.3897 - val_acc: 0.8647\n",
            "Epoch 95/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4259 - acc: 0.8522 - val_loss: 0.3923 - val_acc: 0.8626\n",
            "Epoch 96/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4293 - acc: 0.8523 - val_loss: 0.3913 - val_acc: 0.8640\n",
            "Epoch 97/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4274 - acc: 0.8530 - val_loss: 0.3968 - val_acc: 0.8587\n",
            "Epoch 98/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4275 - acc: 0.8529 - val_loss: 0.4012 - val_acc: 0.8624\n",
            "Epoch 99/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4290 - acc: 0.8533 - val_loss: 0.3843 - val_acc: 0.8670\n",
            "Epoch 100/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4269 - acc: 0.8527 - val_loss: 0.3907 - val_acc: 0.8639\n",
            "Epoch 101/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4264 - acc: 0.8537 - val_loss: 0.3834 - val_acc: 0.8666\n",
            "Epoch 102/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4256 - acc: 0.8540 - val_loss: 0.3864 - val_acc: 0.8640\n",
            "Epoch 103/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4267 - acc: 0.8533 - val_loss: 0.3947 - val_acc: 0.8608\n",
            "Epoch 104/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4264 - acc: 0.8533 - val_loss: 0.3868 - val_acc: 0.8652\n",
            "Epoch 105/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4251 - acc: 0.8537 - val_loss: 0.3835 - val_acc: 0.8662\n",
            "Epoch 106/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4245 - acc: 0.8545 - val_loss: 0.3943 - val_acc: 0.8624\n",
            "Epoch 107/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4262 - acc: 0.8530 - val_loss: 0.3969 - val_acc: 0.8595\n",
            "Epoch 108/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4255 - acc: 0.8533 - val_loss: 0.3897 - val_acc: 0.8612\n",
            "Epoch 109/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4241 - acc: 0.8536 - val_loss: 0.3863 - val_acc: 0.8670\n",
            "Epoch 110/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4240 - acc: 0.8541 - val_loss: 0.3824 - val_acc: 0.8677\n",
            "Epoch 111/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4263 - acc: 0.8525 - val_loss: 0.3921 - val_acc: 0.8638\n",
            "Epoch 112/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4240 - acc: 0.8533 - val_loss: 0.3848 - val_acc: 0.8647\n",
            "Epoch 113/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4224 - acc: 0.8539 - val_loss: 0.3939 - val_acc: 0.8629\n",
            "Epoch 114/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4229 - acc: 0.8543 - val_loss: 0.3904 - val_acc: 0.8641\n",
            "Epoch 115/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4257 - acc: 0.8534 - val_loss: 0.3870 - val_acc: 0.8658\n",
            "Epoch 116/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4229 - acc: 0.8539 - val_loss: 0.3822 - val_acc: 0.8665\n",
            "Epoch 117/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4242 - acc: 0.8535 - val_loss: 0.3990 - val_acc: 0.8615\n",
            "Epoch 118/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4227 - acc: 0.8538 - val_loss: 0.3936 - val_acc: 0.8628\n",
            "Epoch 119/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4231 - acc: 0.8536 - val_loss: 0.3855 - val_acc: 0.8657\n",
            "Epoch 120/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4233 - acc: 0.8540 - val_loss: 0.3821 - val_acc: 0.8660\n",
            "Epoch 121/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.4236 - acc: 0.8539 - val_loss: 0.3876 - val_acc: 0.8668\n",
            "Epoch 122/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4238 - acc: 0.8534 - val_loss: 0.3940 - val_acc: 0.8617\n",
            "Epoch 123/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4240 - acc: 0.8533 - val_loss: 0.3934 - val_acc: 0.8657\n",
            "Epoch 124/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4233 - acc: 0.8541 - val_loss: 0.3915 - val_acc: 0.8641\n",
            "Epoch 125/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4246 - acc: 0.8536 - val_loss: 0.3859 - val_acc: 0.8654\n",
            "Epoch 126/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4222 - acc: 0.8544 - val_loss: 0.3856 - val_acc: 0.8669\n",
            "Epoch 127/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4198 - acc: 0.8548 - val_loss: 0.3826 - val_acc: 0.8665\n",
            "Epoch 128/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4228 - acc: 0.8549 - val_loss: 0.3858 - val_acc: 0.8660\n",
            "Epoch 129/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4226 - acc: 0.8541 - val_loss: 0.3899 - val_acc: 0.8653\n",
            "Epoch 130/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4222 - acc: 0.8545 - val_loss: 0.3808 - val_acc: 0.8690\n",
            "Epoch 131/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4231 - acc: 0.8543 - val_loss: 0.3955 - val_acc: 0.8609\n",
            "Epoch 132/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4203 - acc: 0.8548 - val_loss: 0.3823 - val_acc: 0.8665\n",
            "Epoch 133/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4216 - acc: 0.8547 - val_loss: 0.3928 - val_acc: 0.8607\n",
            "Epoch 134/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4220 - acc: 0.8540 - val_loss: 0.4109 - val_acc: 0.8599\n",
            "Epoch 135/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4225 - acc: 0.8544 - val_loss: 0.3843 - val_acc: 0.8639\n",
            "Epoch 136/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4211 - acc: 0.8537 - val_loss: 0.3932 - val_acc: 0.8626\n",
            "Epoch 137/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4223 - acc: 0.8546 - val_loss: 0.3944 - val_acc: 0.8621\n",
            "Epoch 138/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4190 - acc: 0.8550 - val_loss: 0.4081 - val_acc: 0.8574\n",
            "Epoch 139/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4198 - acc: 0.8545 - val_loss: 0.3915 - val_acc: 0.8619\n",
            "Epoch 140/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4202 - acc: 0.8556 - val_loss: 0.3824 - val_acc: 0.8665\n",
            "Epoch 141/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4207 - acc: 0.8544 - val_loss: 0.3988 - val_acc: 0.8614\n",
            "Epoch 142/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4208 - acc: 0.8543 - val_loss: 0.3865 - val_acc: 0.8623\n",
            "Epoch 143/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4191 - acc: 0.8555 - val_loss: 0.3865 - val_acc: 0.8642\n",
            "Epoch 144/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4183 - acc: 0.8564 - val_loss: 0.3867 - val_acc: 0.8675\n",
            "Epoch 145/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4203 - acc: 0.8552 - val_loss: 0.3806 - val_acc: 0.8693\n",
            "Epoch 146/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4218 - acc: 0.8531 - val_loss: 0.3891 - val_acc: 0.8635\n",
            "Epoch 147/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4199 - acc: 0.8551 - val_loss: 0.3912 - val_acc: 0.8630\n",
            "Epoch 148/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4198 - acc: 0.8554 - val_loss: 0.4146 - val_acc: 0.8544\n",
            "Epoch 149/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4192 - acc: 0.8552 - val_loss: 0.3810 - val_acc: 0.8682\n",
            "Epoch 150/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4175 - acc: 0.8556 - val_loss: 0.3814 - val_acc: 0.8670\n",
            "Epoch 151/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4185 - acc: 0.8554 - val_loss: 0.3860 - val_acc: 0.8624\n",
            "Epoch 152/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4226 - acc: 0.8539 - val_loss: 0.3849 - val_acc: 0.8659\n",
            "Epoch 153/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4198 - acc: 0.8552 - val_loss: 0.3945 - val_acc: 0.8622\n",
            "Epoch 154/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4207 - acc: 0.8541 - val_loss: 0.3873 - val_acc: 0.8654\n",
            "Epoch 155/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4192 - acc: 0.8557 - val_loss: 0.3873 - val_acc: 0.8639\n",
            "Epoch 156/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4185 - acc: 0.8548 - val_loss: 0.3897 - val_acc: 0.8632\n",
            "Epoch 157/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4191 - acc: 0.8547 - val_loss: 0.3890 - val_acc: 0.8622\n",
            "Epoch 158/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4192 - acc: 0.8551 - val_loss: 0.3911 - val_acc: 0.8638\n",
            "Epoch 159/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4226 - acc: 0.8543 - val_loss: 0.3990 - val_acc: 0.8623\n",
            "Epoch 160/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4176 - acc: 0.8555 - val_loss: 0.3886 - val_acc: 0.8667\n",
            "Epoch 161/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4170 - acc: 0.8563 - val_loss: 0.4006 - val_acc: 0.8636\n",
            "Epoch 162/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4182 - acc: 0.8553 - val_loss: 0.3818 - val_acc: 0.8681\n",
            "Epoch 163/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4189 - acc: 0.8549 - val_loss: 0.3829 - val_acc: 0.8650\n",
            "Epoch 164/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4182 - acc: 0.8552 - val_loss: 0.3837 - val_acc: 0.8639\n",
            "Epoch 165/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4170 - acc: 0.8564 - val_loss: 0.3824 - val_acc: 0.8675\n",
            "Epoch 166/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4170 - acc: 0.8551 - val_loss: 0.3784 - val_acc: 0.8673\n",
            "Epoch 167/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4191 - acc: 0.8552 - val_loss: 0.3910 - val_acc: 0.8606\n",
            "Epoch 168/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4166 - acc: 0.8554 - val_loss: 0.3844 - val_acc: 0.8660\n",
            "Epoch 169/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4179 - acc: 0.8552 - val_loss: 0.3820 - val_acc: 0.8663\n",
            "Epoch 170/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4192 - acc: 0.8554 - val_loss: 0.3857 - val_acc: 0.8676\n",
            "Epoch 171/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4206 - acc: 0.8559 - val_loss: 0.3913 - val_acc: 0.8629\n",
            "Epoch 172/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4162 - acc: 0.8560 - val_loss: 0.3817 - val_acc: 0.8657\n",
            "Epoch 173/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4176 - acc: 0.8556 - val_loss: 0.3939 - val_acc: 0.8643\n",
            "Epoch 174/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4177 - acc: 0.8553 - val_loss: 0.3825 - val_acc: 0.8653\n",
            "Epoch 175/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4170 - acc: 0.8557 - val_loss: 0.3893 - val_acc: 0.8620\n",
            "Epoch 176/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4184 - acc: 0.8547 - val_loss: 0.3874 - val_acc: 0.8639\n",
            "Epoch 177/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4165 - acc: 0.8555 - val_loss: 0.3894 - val_acc: 0.8624\n",
            "Epoch 178/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4157 - acc: 0.8567 - val_loss: 0.3797 - val_acc: 0.8679\n",
            "Epoch 179/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4163 - acc: 0.8559 - val_loss: 0.3938 - val_acc: 0.8663\n",
            "Epoch 180/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4174 - acc: 0.8555 - val_loss: 0.3890 - val_acc: 0.8650\n",
            "Epoch 181/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4149 - acc: 0.8565 - val_loss: 0.3842 - val_acc: 0.8662\n",
            "Epoch 182/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4165 - acc: 0.8554 - val_loss: 0.3981 - val_acc: 0.8608\n",
            "Epoch 183/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4171 - acc: 0.8564 - val_loss: 0.3819 - val_acc: 0.8669\n",
            "Epoch 184/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4161 - acc: 0.8552 - val_loss: 0.3783 - val_acc: 0.8662\n",
            "Epoch 185/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4147 - acc: 0.8566 - val_loss: 0.3904 - val_acc: 0.8606\n",
            "Epoch 186/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4153 - acc: 0.8557 - val_loss: 0.3964 - val_acc: 0.8593\n",
            "Epoch 187/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4161 - acc: 0.8558 - val_loss: 0.3797 - val_acc: 0.8671\n",
            "Epoch 188/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4144 - acc: 0.8562 - val_loss: 0.3791 - val_acc: 0.8689\n",
            "Epoch 189/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4161 - acc: 0.8561 - val_loss: 0.3840 - val_acc: 0.8675\n",
            "Epoch 190/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4175 - acc: 0.8557 - val_loss: 0.3849 - val_acc: 0.8647\n",
            "Epoch 191/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4161 - acc: 0.8559 - val_loss: 0.3785 - val_acc: 0.8678\n",
            "Epoch 192/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4155 - acc: 0.8558 - val_loss: 0.3847 - val_acc: 0.8660\n",
            "Epoch 193/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4179 - acc: 0.8552 - val_loss: 0.3925 - val_acc: 0.8625\n",
            "Epoch 194/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4155 - acc: 0.8560 - val_loss: 0.3857 - val_acc: 0.8643\n",
            "Epoch 195/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4149 - acc: 0.8561 - val_loss: 0.3815 - val_acc: 0.8670\n",
            "Epoch 196/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4168 - acc: 0.8561 - val_loss: 0.3912 - val_acc: 0.8621\n",
            "Epoch 197/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4166 - acc: 0.8560 - val_loss: 0.3822 - val_acc: 0.8656\n",
            "Epoch 198/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4141 - acc: 0.8569 - val_loss: 0.3860 - val_acc: 0.8672\n",
            "Epoch 199/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4142 - acc: 0.8563 - val_loss: 0.3755 - val_acc: 0.8694\n",
            "Epoch 200/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4158 - acc: 0.8556 - val_loss: 0.3801 - val_acc: 0.8672\n",
            "Epoch 201/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4147 - acc: 0.8568 - val_loss: 0.3850 - val_acc: 0.8656\n",
            "Epoch 202/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4153 - acc: 0.8562 - val_loss: 0.3869 - val_acc: 0.8649\n",
            "Epoch 203/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4163 - acc: 0.8563 - val_loss: 0.3931 - val_acc: 0.8642\n",
            "Epoch 204/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4122 - acc: 0.8562 - val_loss: 0.3821 - val_acc: 0.8660\n",
            "Epoch 205/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4156 - acc: 0.8566 - val_loss: 0.3840 - val_acc: 0.8666\n",
            "Epoch 206/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4121 - acc: 0.8575 - val_loss: 0.3890 - val_acc: 0.8655\n",
            "Epoch 207/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4146 - acc: 0.8562 - val_loss: 0.3775 - val_acc: 0.8687\n",
            "Epoch 208/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4125 - acc: 0.8569 - val_loss: 0.3875 - val_acc: 0.8642\n",
            "Epoch 209/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4143 - acc: 0.8566 - val_loss: 0.3819 - val_acc: 0.8655\n",
            "Epoch 210/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4133 - acc: 0.8566 - val_loss: 0.3809 - val_acc: 0.8672\n",
            "Epoch 211/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4169 - acc: 0.8561 - val_loss: 0.3805 - val_acc: 0.8675\n",
            "Epoch 212/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4137 - acc: 0.8570 - val_loss: 0.3812 - val_acc: 0.8685\n",
            "Epoch 213/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4128 - acc: 0.8569 - val_loss: 0.3888 - val_acc: 0.8630\n",
            "Epoch 214/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4129 - acc: 0.8572 - val_loss: 0.3769 - val_acc: 0.8691\n",
            "Epoch 215/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4149 - acc: 0.8569 - val_loss: 0.3847 - val_acc: 0.8658\n",
            "Epoch 216/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4165 - acc: 0.8559 - val_loss: 0.3754 - val_acc: 0.8685\n",
            "Epoch 217/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4127 - acc: 0.8571 - val_loss: 0.3871 - val_acc: 0.8642\n",
            "Epoch 218/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4128 - acc: 0.8565 - val_loss: 0.3794 - val_acc: 0.8675\n",
            "Epoch 219/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4150 - acc: 0.8558 - val_loss: 0.3841 - val_acc: 0.8673\n",
            "Epoch 220/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4134 - acc: 0.8571 - val_loss: 0.3747 - val_acc: 0.8681\n",
            "Epoch 221/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4135 - acc: 0.8569 - val_loss: 0.3796 - val_acc: 0.8677\n",
            "Epoch 222/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4143 - acc: 0.8567 - val_loss: 0.3832 - val_acc: 0.8657\n",
            "Epoch 223/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4132 - acc: 0.8575 - val_loss: 0.3796 - val_acc: 0.8663\n",
            "Epoch 224/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4114 - acc: 0.8577 - val_loss: 0.3889 - val_acc: 0.8628\n",
            "Epoch 225/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4179 - acc: 0.8556 - val_loss: 0.3881 - val_acc: 0.8653\n",
            "Epoch 226/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4118 - acc: 0.8573 - val_loss: 0.3884 - val_acc: 0.8640\n",
            "Epoch 227/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4126 - acc: 0.8569 - val_loss: 0.3792 - val_acc: 0.8677\n",
            "Epoch 228/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4112 - acc: 0.8578 - val_loss: 0.3813 - val_acc: 0.8648\n",
            "Epoch 229/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4133 - acc: 0.8569 - val_loss: 0.3802 - val_acc: 0.8676\n",
            "Epoch 230/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4122 - acc: 0.8578 - val_loss: 0.3796 - val_acc: 0.8663\n",
            "Epoch 231/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4146 - acc: 0.8566 - val_loss: 0.3792 - val_acc: 0.8683\n",
            "Epoch 232/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4119 - acc: 0.8568 - val_loss: 0.3810 - val_acc: 0.8669\n",
            "Epoch 233/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4126 - acc: 0.8570 - val_loss: 0.3861 - val_acc: 0.8652\n",
            "Epoch 234/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4133 - acc: 0.8570 - val_loss: 0.3880 - val_acc: 0.8638\n",
            "Epoch 235/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4137 - acc: 0.8562 - val_loss: 0.3906 - val_acc: 0.8642\n",
            "Epoch 236/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4111 - acc: 0.8575 - val_loss: 0.3827 - val_acc: 0.8655\n",
            "Epoch 237/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4124 - acc: 0.8566 - val_loss: 0.3777 - val_acc: 0.8691\n",
            "Epoch 238/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4124 - acc: 0.8571 - val_loss: 0.3820 - val_acc: 0.8683\n",
            "Epoch 239/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4104 - acc: 0.8578 - val_loss: 0.3821 - val_acc: 0.8669\n",
            "Epoch 240/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4132 - acc: 0.8567 - val_loss: 0.3783 - val_acc: 0.8676\n",
            "Epoch 241/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4121 - acc: 0.8571 - val_loss: 0.3860 - val_acc: 0.8675\n",
            "Epoch 242/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4154 - acc: 0.8564 - val_loss: 0.3822 - val_acc: 0.8669\n",
            "Epoch 243/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4127 - acc: 0.8574 - val_loss: 0.3917 - val_acc: 0.8626\n",
            "Epoch 244/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4111 - acc: 0.8580 - val_loss: 0.3764 - val_acc: 0.8686\n",
            "Epoch 245/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4115 - acc: 0.8578 - val_loss: 0.3748 - val_acc: 0.8691\n",
            "Epoch 246/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4127 - acc: 0.8569 - val_loss: 0.3858 - val_acc: 0.8662\n",
            "Epoch 247/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4091 - acc: 0.8587 - val_loss: 0.3851 - val_acc: 0.8644\n",
            "Epoch 248/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4115 - acc: 0.8580 - val_loss: 0.3861 - val_acc: 0.8639\n",
            "Epoch 249/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4130 - acc: 0.8560 - val_loss: 0.3863 - val_acc: 0.8617\n",
            "Epoch 250/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4117 - acc: 0.8572 - val_loss: 0.3855 - val_acc: 0.8669\n",
            "Epoch 251/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4136 - acc: 0.8576 - val_loss: 0.3811 - val_acc: 0.8671\n",
            "Epoch 252/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4120 - acc: 0.8571 - val_loss: 0.3813 - val_acc: 0.8659\n",
            "Epoch 253/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4086 - acc: 0.8576 - val_loss: 0.3803 - val_acc: 0.8669\n",
            "Epoch 254/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4100 - acc: 0.8583 - val_loss: 0.3772 - val_acc: 0.8680\n",
            "Epoch 255/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4109 - acc: 0.8579 - val_loss: 0.3786 - val_acc: 0.8690\n",
            "Epoch 256/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4114 - acc: 0.8575 - val_loss: 0.3845 - val_acc: 0.8646\n",
            "Epoch 257/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.4114 - acc: 0.8575 - val_loss: 0.3766 - val_acc: 0.8685\n",
            "Epoch 258/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4114 - acc: 0.8569 - val_loss: 0.3815 - val_acc: 0.8641\n",
            "Epoch 259/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4100 - acc: 0.8576 - val_loss: 0.3751 - val_acc: 0.8713\n",
            "Epoch 260/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4106 - acc: 0.8577 - val_loss: 0.3805 - val_acc: 0.8677\n",
            "Epoch 261/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4113 - acc: 0.8566 - val_loss: 0.3795 - val_acc: 0.8685\n",
            "Epoch 262/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4107 - acc: 0.8580 - val_loss: 0.3891 - val_acc: 0.8641\n",
            "Epoch 263/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4098 - acc: 0.8575 - val_loss: 0.3879 - val_acc: 0.8621\n",
            "Epoch 264/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4108 - acc: 0.8579 - val_loss: 0.3824 - val_acc: 0.8651\n",
            "Epoch 265/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4119 - acc: 0.8573 - val_loss: 0.3780 - val_acc: 0.8675\n",
            "Epoch 266/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4103 - acc: 0.8579 - val_loss: 0.3941 - val_acc: 0.8637\n",
            "Epoch 267/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4115 - acc: 0.8584 - val_loss: 0.3904 - val_acc: 0.8629\n",
            "Epoch 268/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4121 - acc: 0.8567 - val_loss: 0.3774 - val_acc: 0.8689\n",
            "Epoch 269/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4095 - acc: 0.8577 - val_loss: 0.3859 - val_acc: 0.8656\n",
            "Epoch 270/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4111 - acc: 0.8580 - val_loss: 0.3827 - val_acc: 0.8659\n",
            "Epoch 271/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4108 - acc: 0.8580 - val_loss: 0.3885 - val_acc: 0.8633\n",
            "Epoch 272/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4092 - acc: 0.8588 - val_loss: 0.3877 - val_acc: 0.8643\n",
            "Epoch 273/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4102 - acc: 0.8576 - val_loss: 0.3840 - val_acc: 0.8663\n",
            "Epoch 274/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4103 - acc: 0.8573 - val_loss: 0.3831 - val_acc: 0.8652\n",
            "Epoch 275/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4092 - acc: 0.8586 - val_loss: 0.3854 - val_acc: 0.8655\n",
            "Epoch 276/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4110 - acc: 0.8579 - val_loss: 0.3756 - val_acc: 0.8682\n",
            "Epoch 277/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4115 - acc: 0.8580 - val_loss: 0.3840 - val_acc: 0.8657\n",
            "Epoch 278/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4113 - acc: 0.8568 - val_loss: 0.3788 - val_acc: 0.8659\n",
            "Epoch 279/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4103 - acc: 0.8582 - val_loss: 0.3777 - val_acc: 0.8688\n",
            "Epoch 280/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4102 - acc: 0.8578 - val_loss: 0.3778 - val_acc: 0.8681\n",
            "Epoch 281/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4106 - acc: 0.8579 - val_loss: 0.3846 - val_acc: 0.8659\n",
            "Epoch 282/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.4087 - acc: 0.8578 - val_loss: 0.3759 - val_acc: 0.8693\n",
            "Epoch 283/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4112 - acc: 0.8577 - val_loss: 0.3840 - val_acc: 0.8657\n",
            "Epoch 284/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4092 - acc: 0.8585 - val_loss: 0.3766 - val_acc: 0.8683\n",
            "Epoch 285/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4088 - acc: 0.8577 - val_loss: 0.3818 - val_acc: 0.8648\n",
            "Epoch 286/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4108 - acc: 0.8581 - val_loss: 0.3811 - val_acc: 0.8675\n",
            "Epoch 287/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4103 - acc: 0.8576 - val_loss: 0.3822 - val_acc: 0.8654\n",
            "Epoch 288/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4111 - acc: 0.8578 - val_loss: 0.3789 - val_acc: 0.8663\n",
            "Epoch 289/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4080 - acc: 0.8585 - val_loss: 0.3815 - val_acc: 0.8660\n",
            "Epoch 290/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4109 - acc: 0.8566 - val_loss: 0.3844 - val_acc: 0.8646\n",
            "Epoch 291/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4089 - acc: 0.8591 - val_loss: 0.3774 - val_acc: 0.8688\n",
            "Epoch 292/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4093 - acc: 0.8582 - val_loss: 0.3824 - val_acc: 0.8656\n",
            "Epoch 293/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4101 - acc: 0.8581 - val_loss: 0.3804 - val_acc: 0.8669\n",
            "Epoch 294/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4072 - acc: 0.8591 - val_loss: 0.3937 - val_acc: 0.8624\n",
            "Epoch 295/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4094 - acc: 0.8578 - val_loss: 0.3885 - val_acc: 0.8634\n",
            "Epoch 296/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4099 - acc: 0.8576 - val_loss: 0.3826 - val_acc: 0.8682\n",
            "Epoch 297/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4090 - acc: 0.8583 - val_loss: 0.3814 - val_acc: 0.8672\n",
            "Epoch 298/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4093 - acc: 0.8589 - val_loss: 0.3805 - val_acc: 0.8655\n",
            "Epoch 299/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4080 - acc: 0.8579 - val_loss: 0.3778 - val_acc: 0.8675\n",
            "Epoch 300/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4086 - acc: 0.8575 - val_loss: 0.3825 - val_acc: 0.8656\n",
            "Epoch 301/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4101 - acc: 0.8577 - val_loss: 0.3799 - val_acc: 0.8690\n",
            "Epoch 302/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4087 - acc: 0.8583 - val_loss: 0.3744 - val_acc: 0.8711\n",
            "Epoch 303/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4093 - acc: 0.8588 - val_loss: 0.3804 - val_acc: 0.8667\n",
            "Epoch 304/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4102 - acc: 0.8574 - val_loss: 0.3799 - val_acc: 0.8672\n",
            "Epoch 305/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4076 - acc: 0.8579 - val_loss: 0.3756 - val_acc: 0.8678\n",
            "Epoch 306/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4100 - acc: 0.8581 - val_loss: 0.3759 - val_acc: 0.8699\n",
            "Epoch 307/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4080 - acc: 0.8575 - val_loss: 0.3803 - val_acc: 0.8657\n",
            "Epoch 308/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4061 - acc: 0.8583 - val_loss: 0.3829 - val_acc: 0.8670\n",
            "Epoch 309/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4088 - acc: 0.8584 - val_loss: 0.3809 - val_acc: 0.8678\n",
            "Epoch 310/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4098 - acc: 0.8584 - val_loss: 0.3769 - val_acc: 0.8707\n",
            "Epoch 311/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4081 - acc: 0.8581 - val_loss: 0.3866 - val_acc: 0.8649\n",
            "Epoch 312/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4090 - acc: 0.8582 - val_loss: 0.3871 - val_acc: 0.8648\n",
            "Epoch 313/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4093 - acc: 0.8582 - val_loss: 0.3792 - val_acc: 0.8688\n",
            "Epoch 314/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4081 - acc: 0.8590 - val_loss: 0.3792 - val_acc: 0.8681\n",
            "Epoch 315/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4097 - acc: 0.8573 - val_loss: 0.3748 - val_acc: 0.8709\n",
            "Epoch 316/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4068 - acc: 0.8588 - val_loss: 0.3759 - val_acc: 0.8706\n",
            "Epoch 317/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4069 - acc: 0.8583 - val_loss: 0.3798 - val_acc: 0.8684\n",
            "Epoch 318/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4081 - acc: 0.8585 - val_loss: 0.3745 - val_acc: 0.8691\n",
            "Epoch 319/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4073 - acc: 0.8589 - val_loss: 0.3787 - val_acc: 0.8677\n",
            "Epoch 320/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4082 - acc: 0.8592 - val_loss: 0.3861 - val_acc: 0.8638\n",
            "Epoch 321/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4084 - acc: 0.8585 - val_loss: 0.3787 - val_acc: 0.8682\n",
            "Epoch 322/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4074 - acc: 0.8582 - val_loss: 0.3739 - val_acc: 0.8701\n",
            "Epoch 323/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4074 - acc: 0.8593 - val_loss: 0.3794 - val_acc: 0.8677\n",
            "Epoch 324/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4094 - acc: 0.8576 - val_loss: 0.3840 - val_acc: 0.8646\n",
            "Epoch 325/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4076 - acc: 0.8585 - val_loss: 0.3794 - val_acc: 0.8683\n",
            "Epoch 326/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4084 - acc: 0.8590 - val_loss: 0.3868 - val_acc: 0.8628\n",
            "Epoch 327/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4066 - acc: 0.8588 - val_loss: 0.4040 - val_acc: 0.8623\n",
            "Epoch 328/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.4085 - acc: 0.8581 - val_loss: 0.3853 - val_acc: 0.8641\n",
            "Epoch 329/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4076 - acc: 0.8587 - val_loss: 0.3768 - val_acc: 0.8671\n",
            "Epoch 330/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4067 - acc: 0.8590 - val_loss: 0.3854 - val_acc: 0.8642\n",
            "Epoch 331/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4093 - acc: 0.8585 - val_loss: 0.3822 - val_acc: 0.8657\n",
            "Epoch 332/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4059 - acc: 0.8591 - val_loss: 0.3763 - val_acc: 0.8672\n",
            "Epoch 333/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4073 - acc: 0.8586 - val_loss: 0.3817 - val_acc: 0.8664\n",
            "Epoch 334/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4070 - acc: 0.8588 - val_loss: 0.3860 - val_acc: 0.8650\n",
            "Epoch 335/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4090 - acc: 0.8585 - val_loss: 0.3893 - val_acc: 0.8618\n",
            "Epoch 336/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4087 - acc: 0.8577 - val_loss: 0.3814 - val_acc: 0.8685\n",
            "Epoch 337/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4062 - acc: 0.8596 - val_loss: 0.3861 - val_acc: 0.8622\n",
            "Epoch 338/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4085 - acc: 0.8580 - val_loss: 0.3823 - val_acc: 0.8676\n",
            "Epoch 339/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4066 - acc: 0.8595 - val_loss: 0.3792 - val_acc: 0.8657\n",
            "Epoch 340/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4063 - acc: 0.8589 - val_loss: 0.3750 - val_acc: 0.8696\n",
            "Epoch 341/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4074 - acc: 0.8583 - val_loss: 0.3807 - val_acc: 0.8672\n",
            "Epoch 342/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4075 - acc: 0.8579 - val_loss: 0.3780 - val_acc: 0.8667\n",
            "Epoch 343/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4090 - acc: 0.8582 - val_loss: 0.3888 - val_acc: 0.8626\n",
            "Epoch 344/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4078 - acc: 0.8591 - val_loss: 0.3846 - val_acc: 0.8666\n",
            "Epoch 345/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4078 - acc: 0.8574 - val_loss: 0.3799 - val_acc: 0.8668\n",
            "Epoch 346/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4064 - acc: 0.8587 - val_loss: 0.3757 - val_acc: 0.8688\n",
            "Epoch 347/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4097 - acc: 0.8576 - val_loss: 0.3793 - val_acc: 0.8671\n",
            "Epoch 348/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4067 - acc: 0.8585 - val_loss: 0.3835 - val_acc: 0.8666\n",
            "Epoch 349/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4056 - acc: 0.8590 - val_loss: 0.3752 - val_acc: 0.8668\n",
            "Epoch 350/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4063 - acc: 0.8595 - val_loss: 0.3847 - val_acc: 0.8666\n",
            "Epoch 351/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4079 - acc: 0.8587 - val_loss: 0.3796 - val_acc: 0.8678\n",
            "Epoch 352/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4068 - acc: 0.8587 - val_loss: 0.3800 - val_acc: 0.8650\n",
            "Epoch 353/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4073 - acc: 0.8589 - val_loss: 0.3756 - val_acc: 0.8675\n",
            "Epoch 354/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4051 - acc: 0.8592 - val_loss: 0.3803 - val_acc: 0.8679\n",
            "Epoch 355/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4063 - acc: 0.8591 - val_loss: 0.3765 - val_acc: 0.8677\n",
            "Epoch 356/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4079 - acc: 0.8582 - val_loss: 0.3824 - val_acc: 0.8655\n",
            "Epoch 357/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4074 - acc: 0.8589 - val_loss: 0.3818 - val_acc: 0.8649\n",
            "Epoch 358/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4081 - acc: 0.8589 - val_loss: 0.3747 - val_acc: 0.8705\n",
            "Epoch 359/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4063 - acc: 0.8585 - val_loss: 0.3798 - val_acc: 0.8680\n",
            "Epoch 360/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4053 - acc: 0.8595 - val_loss: 0.3782 - val_acc: 0.8691\n",
            "Epoch 361/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4080 - acc: 0.8587 - val_loss: 0.3756 - val_acc: 0.8677\n",
            "Epoch 362/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.4063 - acc: 0.8587 - val_loss: 0.3945 - val_acc: 0.8620\n",
            "Epoch 363/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4068 - acc: 0.8588 - val_loss: 0.3809 - val_acc: 0.8667\n",
            "Epoch 364/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4049 - acc: 0.8597 - val_loss: 0.3739 - val_acc: 0.8682\n",
            "Epoch 365/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4062 - acc: 0.8588 - val_loss: 0.3802 - val_acc: 0.8669\n",
            "Epoch 366/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4066 - acc: 0.8590 - val_loss: 0.3829 - val_acc: 0.8650\n",
            "Epoch 367/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4083 - acc: 0.8590 - val_loss: 0.3771 - val_acc: 0.8685\n",
            "Epoch 368/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4059 - acc: 0.8590 - val_loss: 0.3765 - val_acc: 0.8675\n",
            "Epoch 369/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4063 - acc: 0.8593 - val_loss: 0.3930 - val_acc: 0.8622\n",
            "Epoch 370/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4050 - acc: 0.8598 - val_loss: 0.3773 - val_acc: 0.8694\n",
            "Epoch 371/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4062 - acc: 0.8589 - val_loss: 0.3755 - val_acc: 0.8700\n",
            "Epoch 372/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4031 - acc: 0.8597 - val_loss: 0.3760 - val_acc: 0.8683\n",
            "Epoch 373/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4055 - acc: 0.8600 - val_loss: 0.3804 - val_acc: 0.8675\n",
            "Epoch 374/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4069 - acc: 0.8588 - val_loss: 0.3884 - val_acc: 0.8679\n",
            "Epoch 375/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4062 - acc: 0.8590 - val_loss: 0.3813 - val_acc: 0.8677\n",
            "Epoch 376/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4055 - acc: 0.8593 - val_loss: 0.3806 - val_acc: 0.8688\n",
            "Epoch 377/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4042 - acc: 0.8598 - val_loss: 0.3769 - val_acc: 0.8678\n",
            "Epoch 378/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4047 - acc: 0.8596 - val_loss: 0.3761 - val_acc: 0.8694\n",
            "Epoch 379/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4065 - acc: 0.8593 - val_loss: 0.3829 - val_acc: 0.8657\n",
            "Epoch 380/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4051 - acc: 0.8593 - val_loss: 0.3721 - val_acc: 0.8696\n",
            "Epoch 381/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4057 - acc: 0.8589 - val_loss: 0.3857 - val_acc: 0.8660\n",
            "Epoch 382/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4051 - acc: 0.8596 - val_loss: 0.3751 - val_acc: 0.8685\n",
            "Epoch 383/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4050 - acc: 0.8587 - val_loss: 0.3858 - val_acc: 0.8645\n",
            "Epoch 384/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4027 - acc: 0.8603 - val_loss: 0.3739 - val_acc: 0.8693\n",
            "Epoch 385/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4035 - acc: 0.8598 - val_loss: 0.3870 - val_acc: 0.8646\n",
            "Epoch 386/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4065 - acc: 0.8592 - val_loss: 0.3759 - val_acc: 0.8688\n",
            "Epoch 387/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4055 - acc: 0.8590 - val_loss: 0.3788 - val_acc: 0.8650\n",
            "Epoch 388/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4059 - acc: 0.8581 - val_loss: 0.3800 - val_acc: 0.8667\n",
            "Epoch 389/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4047 - acc: 0.8588 - val_loss: 0.3811 - val_acc: 0.8644\n",
            "Epoch 390/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4056 - acc: 0.8596 - val_loss: 0.3756 - val_acc: 0.8673\n",
            "Epoch 391/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4058 - acc: 0.8588 - val_loss: 0.3815 - val_acc: 0.8668\n",
            "Epoch 392/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4072 - acc: 0.8593 - val_loss: 0.3896 - val_acc: 0.8620\n",
            "Epoch 393/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4054 - acc: 0.8596 - val_loss: 0.3738 - val_acc: 0.8710\n",
            "Epoch 394/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4056 - acc: 0.8588 - val_loss: 0.3792 - val_acc: 0.8693\n",
            "Epoch 395/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4044 - acc: 0.8596 - val_loss: 0.3760 - val_acc: 0.8695\n",
            "Epoch 396/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4051 - acc: 0.8587 - val_loss: 0.3823 - val_acc: 0.8666\n",
            "Epoch 397/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4036 - acc: 0.8601 - val_loss: 0.3818 - val_acc: 0.8679\n",
            "Epoch 398/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4056 - acc: 0.8588 - val_loss: 0.3722 - val_acc: 0.8693\n",
            "Epoch 399/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4032 - acc: 0.8594 - val_loss: 0.3759 - val_acc: 0.8658\n",
            "Epoch 400/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4037 - acc: 0.8601 - val_loss: 0.3768 - val_acc: 0.8681\n",
            "Epoch 401/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4050 - acc: 0.8598 - val_loss: 0.3731 - val_acc: 0.8694\n",
            "Epoch 402/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4050 - acc: 0.8597 - val_loss: 0.3852 - val_acc: 0.8641\n",
            "Epoch 403/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4043 - acc: 0.8594 - val_loss: 0.3771 - val_acc: 0.8676\n",
            "Epoch 404/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4085 - acc: 0.8586 - val_loss: 0.3769 - val_acc: 0.8678\n",
            "Epoch 405/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4041 - acc: 0.8594 - val_loss: 0.3912 - val_acc: 0.8603\n",
            "Epoch 406/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4038 - acc: 0.8588 - val_loss: 0.3830 - val_acc: 0.8649\n",
            "Epoch 407/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4051 - acc: 0.8592 - val_loss: 0.3794 - val_acc: 0.8667\n",
            "Epoch 408/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4053 - acc: 0.8592 - val_loss: 0.3749 - val_acc: 0.8697\n",
            "Epoch 409/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4043 - acc: 0.8591 - val_loss: 0.3754 - val_acc: 0.8680\n",
            "Epoch 410/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4060 - acc: 0.8594 - val_loss: 0.3815 - val_acc: 0.8658\n",
            "Epoch 411/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4057 - acc: 0.8603 - val_loss: 0.3729 - val_acc: 0.8687\n",
            "Epoch 412/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4051 - acc: 0.8595 - val_loss: 0.3795 - val_acc: 0.8676\n",
            "Epoch 413/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4061 - acc: 0.8592 - val_loss: 0.3772 - val_acc: 0.8682\n",
            "Epoch 414/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4050 - acc: 0.8597 - val_loss: 0.3789 - val_acc: 0.8677\n",
            "Epoch 415/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4042 - acc: 0.8600 - val_loss: 0.3790 - val_acc: 0.8679\n",
            "Epoch 416/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4049 - acc: 0.8589 - val_loss: 0.3870 - val_acc: 0.8645\n",
            "Epoch 417/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4057 - acc: 0.8602 - val_loss: 0.3836 - val_acc: 0.8661\n",
            "Epoch 418/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4049 - acc: 0.8587 - val_loss: 0.3756 - val_acc: 0.8665\n",
            "Epoch 419/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4041 - acc: 0.8598 - val_loss: 0.3823 - val_acc: 0.8679\n",
            "Epoch 420/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4042 - acc: 0.8595 - val_loss: 0.3766 - val_acc: 0.8662\n",
            "Epoch 421/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4049 - acc: 0.8603 - val_loss: 0.3930 - val_acc: 0.8623\n",
            "Epoch 422/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4051 - acc: 0.8600 - val_loss: 0.3751 - val_acc: 0.8682\n",
            "Epoch 423/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4038 - acc: 0.8598 - val_loss: 0.3774 - val_acc: 0.8673\n",
            "Epoch 424/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4048 - acc: 0.8600 - val_loss: 0.3786 - val_acc: 0.8690\n",
            "Epoch 425/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4037 - acc: 0.8593 - val_loss: 0.3743 - val_acc: 0.8699\n",
            "Epoch 426/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4021 - acc: 0.8601 - val_loss: 0.3725 - val_acc: 0.8691\n",
            "Epoch 427/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4054 - acc: 0.8598 - val_loss: 0.3708 - val_acc: 0.8685\n",
            "Epoch 428/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4031 - acc: 0.8599 - val_loss: 0.3749 - val_acc: 0.8685\n",
            "Epoch 429/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4045 - acc: 0.8597 - val_loss: 0.3772 - val_acc: 0.8672\n",
            "Epoch 430/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4054 - acc: 0.8592 - val_loss: 0.3741 - val_acc: 0.8683\n",
            "Epoch 431/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4037 - acc: 0.8589 - val_loss: 0.3800 - val_acc: 0.8645\n",
            "Epoch 432/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4037 - acc: 0.8598 - val_loss: 0.3754 - val_acc: 0.8676\n",
            "Epoch 433/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4054 - acc: 0.8590 - val_loss: 0.3787 - val_acc: 0.8657\n",
            "Epoch 434/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4038 - acc: 0.8600 - val_loss: 0.3744 - val_acc: 0.8707\n",
            "Epoch 435/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4040 - acc: 0.8606 - val_loss: 0.3842 - val_acc: 0.8653\n",
            "Epoch 436/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4053 - acc: 0.8593 - val_loss: 0.3812 - val_acc: 0.8678\n",
            "Epoch 437/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4043 - acc: 0.8593 - val_loss: 0.3794 - val_acc: 0.8687\n",
            "Epoch 438/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4046 - acc: 0.8600 - val_loss: 0.3775 - val_acc: 0.8691\n",
            "Epoch 439/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4040 - acc: 0.8595 - val_loss: 0.3729 - val_acc: 0.8710\n",
            "Epoch 440/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4043 - acc: 0.8596 - val_loss: 0.3764 - val_acc: 0.8685\n",
            "Epoch 441/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4065 - acc: 0.8588 - val_loss: 0.3797 - val_acc: 0.8672\n",
            "Epoch 442/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4027 - acc: 0.8598 - val_loss: 0.3813 - val_acc: 0.8656\n",
            "Epoch 443/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4045 - acc: 0.8597 - val_loss: 0.3737 - val_acc: 0.8699\n",
            "Epoch 444/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4046 - acc: 0.8602 - val_loss: 0.3775 - val_acc: 0.8690\n",
            "Epoch 445/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4022 - acc: 0.8605 - val_loss: 0.3769 - val_acc: 0.8699\n",
            "Epoch 446/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4029 - acc: 0.8603 - val_loss: 0.3733 - val_acc: 0.8681\n",
            "Epoch 447/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4040 - acc: 0.8598 - val_loss: 0.3742 - val_acc: 0.8703\n",
            "Epoch 448/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4040 - acc: 0.8598 - val_loss: 0.3757 - val_acc: 0.8687\n",
            "Epoch 449/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4024 - acc: 0.8603 - val_loss: 0.3762 - val_acc: 0.8682\n",
            "Epoch 450/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4046 - acc: 0.8600 - val_loss: 0.3784 - val_acc: 0.8686\n",
            "Epoch 451/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4051 - acc: 0.8591 - val_loss: 0.3761 - val_acc: 0.8689\n",
            "Epoch 452/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4021 - acc: 0.8599 - val_loss: 0.3756 - val_acc: 0.8682\n",
            "Epoch 453/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4032 - acc: 0.8603 - val_loss: 0.3750 - val_acc: 0.8685\n",
            "Epoch 454/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4029 - acc: 0.8595 - val_loss: 0.3736 - val_acc: 0.8703\n",
            "Epoch 455/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4039 - acc: 0.8594 - val_loss: 0.3762 - val_acc: 0.8675\n",
            "Epoch 456/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4017 - acc: 0.8609 - val_loss: 0.3794 - val_acc: 0.8672\n",
            "Epoch 457/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4051 - acc: 0.8600 - val_loss: 0.3790 - val_acc: 0.8684\n",
            "Epoch 458/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4022 - acc: 0.8606 - val_loss: 0.3804 - val_acc: 0.8671\n",
            "Epoch 459/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4029 - acc: 0.8598 - val_loss: 0.3800 - val_acc: 0.8663\n",
            "Epoch 460/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4035 - acc: 0.8595 - val_loss: 0.3819 - val_acc: 0.8645\n",
            "Epoch 461/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4053 - acc: 0.8590 - val_loss: 0.3785 - val_acc: 0.8667\n",
            "Epoch 462/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4026 - acc: 0.8603 - val_loss: 0.3785 - val_acc: 0.8691\n",
            "Epoch 463/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4034 - acc: 0.8600 - val_loss: 0.3761 - val_acc: 0.8681\n",
            "Epoch 464/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4011 - acc: 0.8605 - val_loss: 0.3752 - val_acc: 0.8675\n",
            "Epoch 465/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.4039 - acc: 0.8599 - val_loss: 0.3760 - val_acc: 0.8672\n",
            "Epoch 466/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4032 - acc: 0.8599 - val_loss: 0.3761 - val_acc: 0.8687\n",
            "Epoch 467/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4017 - acc: 0.8602 - val_loss: 0.3755 - val_acc: 0.8704\n",
            "Epoch 468/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4033 - acc: 0.8602 - val_loss: 0.3753 - val_acc: 0.8675\n",
            "Epoch 469/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4043 - acc: 0.8600 - val_loss: 0.3775 - val_acc: 0.8679\n",
            "Epoch 470/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4029 - acc: 0.8596 - val_loss: 0.3804 - val_acc: 0.8669\n",
            "Epoch 471/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4030 - acc: 0.8598 - val_loss: 0.3735 - val_acc: 0.8698\n",
            "Epoch 472/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4037 - acc: 0.8600 - val_loss: 0.3745 - val_acc: 0.8703\n",
            "Epoch 473/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4041 - acc: 0.8597 - val_loss: 0.3802 - val_acc: 0.8648\n",
            "Epoch 474/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4030 - acc: 0.8599 - val_loss: 0.3762 - val_acc: 0.8693\n",
            "Epoch 475/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4048 - acc: 0.8598 - val_loss: 0.3764 - val_acc: 0.8687\n",
            "Epoch 476/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4027 - acc: 0.8608 - val_loss: 0.3742 - val_acc: 0.8705\n",
            "Epoch 477/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4035 - acc: 0.8596 - val_loss: 0.3818 - val_acc: 0.8647\n",
            "Epoch 478/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4016 - acc: 0.8602 - val_loss: 0.3765 - val_acc: 0.8662\n",
            "Epoch 479/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4007 - acc: 0.8607 - val_loss: 0.3745 - val_acc: 0.8711\n",
            "Epoch 480/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4047 - acc: 0.8601 - val_loss: 0.3739 - val_acc: 0.8695\n",
            "Epoch 481/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4041 - acc: 0.8597 - val_loss: 0.3817 - val_acc: 0.8655\n",
            "Epoch 482/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4031 - acc: 0.8597 - val_loss: 0.3873 - val_acc: 0.8645\n",
            "Epoch 483/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4021 - acc: 0.8603 - val_loss: 0.3787 - val_acc: 0.8681\n",
            "Epoch 484/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4041 - acc: 0.8598 - val_loss: 0.3761 - val_acc: 0.8677\n",
            "Epoch 485/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4033 - acc: 0.8600 - val_loss: 0.3876 - val_acc: 0.8597\n",
            "Epoch 486/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4036 - acc: 0.8606 - val_loss: 0.3768 - val_acc: 0.8664\n",
            "Epoch 487/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4029 - acc: 0.8598 - val_loss: 0.3847 - val_acc: 0.8661\n",
            "Epoch 488/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4037 - acc: 0.8603 - val_loss: 0.3870 - val_acc: 0.8632\n",
            "Epoch 489/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4007 - acc: 0.8603 - val_loss: 0.3803 - val_acc: 0.8645\n",
            "Epoch 490/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4019 - acc: 0.8604 - val_loss: 0.3728 - val_acc: 0.8690\n",
            "Epoch 491/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4030 - acc: 0.8599 - val_loss: 0.3753 - val_acc: 0.8685\n",
            "Epoch 492/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4051 - acc: 0.8595 - val_loss: 0.3728 - val_acc: 0.8683\n",
            "Epoch 493/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4027 - acc: 0.8600 - val_loss: 0.3779 - val_acc: 0.8673\n",
            "Epoch 494/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4036 - acc: 0.8600 - val_loss: 0.3755 - val_acc: 0.8664\n",
            "Epoch 495/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4029 - acc: 0.8604 - val_loss: 0.3819 - val_acc: 0.8650\n",
            "Epoch 496/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4028 - acc: 0.8599 - val_loss: 0.3749 - val_acc: 0.8697\n",
            "Epoch 497/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4035 - acc: 0.8602 - val_loss: 0.3786 - val_acc: 0.8697\n",
            "Epoch 498/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4007 - acc: 0.8599 - val_loss: 0.3794 - val_acc: 0.8684\n",
            "Epoch 499/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4021 - acc: 0.8607 - val_loss: 0.3726 - val_acc: 0.8697\n",
            "Epoch 500/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4023 - acc: 0.8600 - val_loss: 0.3768 - val_acc: 0.8669\n",
            "Epoch 501/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4015 - acc: 0.8607 - val_loss: 0.3791 - val_acc: 0.8673\n",
            "Epoch 502/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4014 - acc: 0.8612 - val_loss: 0.3750 - val_acc: 0.8677\n",
            "Epoch 503/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4009 - acc: 0.8604 - val_loss: 0.3771 - val_acc: 0.8668\n",
            "Epoch 504/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4025 - acc: 0.8595 - val_loss: 0.3768 - val_acc: 0.8677\n",
            "Epoch 505/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4026 - acc: 0.8605 - val_loss: 0.3792 - val_acc: 0.8656\n",
            "Epoch 506/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4015 - acc: 0.8608 - val_loss: 0.3731 - val_acc: 0.8698\n",
            "Epoch 507/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4022 - acc: 0.8600 - val_loss: 0.3755 - val_acc: 0.8693\n",
            "Epoch 508/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4013 - acc: 0.8597 - val_loss: 0.3772 - val_acc: 0.8669\n",
            "Epoch 509/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4014 - acc: 0.8606 - val_loss: 0.3822 - val_acc: 0.8677\n",
            "Epoch 510/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4021 - acc: 0.8603 - val_loss: 0.3743 - val_acc: 0.8697\n",
            "Epoch 511/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4010 - acc: 0.8603 - val_loss: 0.3759 - val_acc: 0.8691\n",
            "Epoch 512/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4021 - acc: 0.8604 - val_loss: 0.3800 - val_acc: 0.8669\n",
            "Epoch 513/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4029 - acc: 0.8612 - val_loss: 0.3766 - val_acc: 0.8675\n",
            "Epoch 514/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3999 - acc: 0.8616 - val_loss: 0.3878 - val_acc: 0.8656\n",
            "Epoch 515/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4012 - acc: 0.8604 - val_loss: 0.3759 - val_acc: 0.8688\n",
            "Epoch 516/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4016 - acc: 0.8606 - val_loss: 0.3742 - val_acc: 0.8681\n",
            "Epoch 517/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4014 - acc: 0.8607 - val_loss: 0.3716 - val_acc: 0.8713\n",
            "Epoch 518/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4007 - acc: 0.8603 - val_loss: 0.3793 - val_acc: 0.8673\n",
            "Epoch 519/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4002 - acc: 0.8613 - val_loss: 0.3767 - val_acc: 0.8679\n",
            "Epoch 520/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4022 - acc: 0.8606 - val_loss: 0.3718 - val_acc: 0.8711\n",
            "Epoch 521/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4005 - acc: 0.8608 - val_loss: 0.3844 - val_acc: 0.8686\n",
            "Epoch 522/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4021 - acc: 0.8600 - val_loss: 0.3740 - val_acc: 0.8694\n",
            "Epoch 523/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4015 - acc: 0.8605 - val_loss: 0.3853 - val_acc: 0.8669\n",
            "Epoch 524/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4038 - acc: 0.8601 - val_loss: 0.3867 - val_acc: 0.8618\n",
            "Epoch 525/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4015 - acc: 0.8602 - val_loss: 0.3788 - val_acc: 0.8675\n",
            "Epoch 526/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4017 - acc: 0.8606 - val_loss: 0.3732 - val_acc: 0.8685\n",
            "Epoch 527/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4012 - acc: 0.8605 - val_loss: 0.3709 - val_acc: 0.8703\n",
            "Epoch 528/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4041 - acc: 0.8593 - val_loss: 0.3753 - val_acc: 0.8697\n",
            "Epoch 529/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4001 - acc: 0.8617 - val_loss: 0.3792 - val_acc: 0.8679\n",
            "Epoch 530/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4023 - acc: 0.8601 - val_loss: 0.3764 - val_acc: 0.8677\n",
            "Epoch 531/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4035 - acc: 0.8597 - val_loss: 0.3801 - val_acc: 0.8673\n",
            "Epoch 532/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4014 - acc: 0.8606 - val_loss: 0.3837 - val_acc: 0.8672\n",
            "Epoch 533/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4028 - acc: 0.8596 - val_loss: 0.3759 - val_acc: 0.8693\n",
            "Epoch 534/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4006 - acc: 0.8610 - val_loss: 0.3734 - val_acc: 0.8689\n",
            "Epoch 535/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4027 - acc: 0.8606 - val_loss: 0.3797 - val_acc: 0.8690\n",
            "Epoch 536/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4005 - acc: 0.8613 - val_loss: 0.3747 - val_acc: 0.8705\n",
            "Epoch 537/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3999 - acc: 0.8607 - val_loss: 0.3761 - val_acc: 0.8708\n",
            "Epoch 538/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4015 - acc: 0.8608 - val_loss: 0.3797 - val_acc: 0.8652\n",
            "Epoch 539/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8612 - val_loss: 0.3786 - val_acc: 0.8683\n",
            "Epoch 540/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4009 - acc: 0.8612 - val_loss: 0.3748 - val_acc: 0.8658\n",
            "Epoch 541/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4000 - acc: 0.8611 - val_loss: 0.3795 - val_acc: 0.8656\n",
            "Epoch 542/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4043 - acc: 0.8588 - val_loss: 0.3734 - val_acc: 0.8699\n",
            "Epoch 543/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4008 - acc: 0.8610 - val_loss: 0.3805 - val_acc: 0.8655\n",
            "Epoch 544/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4027 - acc: 0.8604 - val_loss: 0.3746 - val_acc: 0.8691\n",
            "Epoch 545/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8609 - val_loss: 0.3815 - val_acc: 0.8655\n",
            "Epoch 546/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4046 - acc: 0.8608 - val_loss: 0.3757 - val_acc: 0.8666\n",
            "Epoch 547/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4007 - acc: 0.8608 - val_loss: 0.3740 - val_acc: 0.8696\n",
            "Epoch 548/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4000 - acc: 0.8615 - val_loss: 0.3778 - val_acc: 0.8674\n",
            "Epoch 549/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3993 - acc: 0.8612 - val_loss: 0.3759 - val_acc: 0.8696\n",
            "Epoch 550/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4008 - acc: 0.8608 - val_loss: 0.3855 - val_acc: 0.8642\n",
            "Epoch 551/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4010 - acc: 0.8604 - val_loss: 0.3778 - val_acc: 0.8685\n",
            "Epoch 552/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4018 - acc: 0.8605 - val_loss: 0.3746 - val_acc: 0.8683\n",
            "Epoch 553/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4009 - acc: 0.8611 - val_loss: 0.3728 - val_acc: 0.8682\n",
            "Epoch 554/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4017 - acc: 0.8600 - val_loss: 0.3747 - val_acc: 0.8693\n",
            "Epoch 555/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4007 - acc: 0.8604 - val_loss: 0.3759 - val_acc: 0.8678\n",
            "Epoch 556/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3998 - acc: 0.8613 - val_loss: 0.3781 - val_acc: 0.8685\n",
            "Epoch 557/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3988 - acc: 0.8620 - val_loss: 0.3743 - val_acc: 0.8674\n",
            "Epoch 558/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4031 - acc: 0.8602 - val_loss: 0.3740 - val_acc: 0.8710\n",
            "Epoch 559/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4001 - acc: 0.8611 - val_loss: 0.3738 - val_acc: 0.8692\n",
            "Epoch 560/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4004 - acc: 0.8610 - val_loss: 0.3812 - val_acc: 0.8657\n",
            "Epoch 561/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8606 - val_loss: 0.3771 - val_acc: 0.8678\n",
            "Epoch 562/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3989 - acc: 0.8615 - val_loss: 0.3768 - val_acc: 0.8660\n",
            "Epoch 563/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3998 - acc: 0.8609 - val_loss: 0.3792 - val_acc: 0.8667\n",
            "Epoch 564/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4012 - acc: 0.8603 - val_loss: 0.3753 - val_acc: 0.8679\n",
            "Epoch 565/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4007 - acc: 0.8609 - val_loss: 0.3765 - val_acc: 0.8685\n",
            "Epoch 566/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3997 - acc: 0.8607 - val_loss: 0.3810 - val_acc: 0.8659\n",
            "Epoch 567/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4002 - acc: 0.8612 - val_loss: 0.3836 - val_acc: 0.8643\n",
            "Epoch 568/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4024 - acc: 0.8604 - val_loss: 0.3758 - val_acc: 0.8673\n",
            "Epoch 569/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3995 - acc: 0.8613 - val_loss: 0.3786 - val_acc: 0.8667\n",
            "Epoch 570/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4011 - acc: 0.8607 - val_loss: 0.3776 - val_acc: 0.8681\n",
            "Epoch 571/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4013 - acc: 0.8605 - val_loss: 0.3743 - val_acc: 0.8681\n",
            "Epoch 572/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4007 - acc: 0.8608 - val_loss: 0.3781 - val_acc: 0.8695\n",
            "Epoch 573/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4023 - acc: 0.8601 - val_loss: 0.3794 - val_acc: 0.8682\n",
            "Epoch 574/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3985 - acc: 0.8614 - val_loss: 0.3817 - val_acc: 0.8664\n",
            "Epoch 575/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4005 - acc: 0.8611 - val_loss: 0.3749 - val_acc: 0.8694\n",
            "Epoch 576/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4004 - acc: 0.8609 - val_loss: 0.3832 - val_acc: 0.8668\n",
            "Epoch 577/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4023 - acc: 0.8601 - val_loss: 0.3734 - val_acc: 0.8717\n",
            "Epoch 578/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3992 - acc: 0.8620 - val_loss: 0.3812 - val_acc: 0.8653\n",
            "Epoch 579/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4027 - acc: 0.8606 - val_loss: 0.3782 - val_acc: 0.8691\n",
            "Epoch 580/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4036 - acc: 0.8602 - val_loss: 0.3726 - val_acc: 0.8673\n",
            "Epoch 581/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3998 - acc: 0.8615 - val_loss: 0.3743 - val_acc: 0.8701\n",
            "Epoch 582/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3998 - acc: 0.8613 - val_loss: 0.3757 - val_acc: 0.8673\n",
            "Epoch 583/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8600 - val_loss: 0.3726 - val_acc: 0.8701\n",
            "Epoch 584/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4020 - acc: 0.8607 - val_loss: 0.3727 - val_acc: 0.8706\n",
            "Epoch 585/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3995 - acc: 0.8614 - val_loss: 0.3818 - val_acc: 0.8671\n",
            "Epoch 586/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3999 - acc: 0.8610 - val_loss: 0.3752 - val_acc: 0.8683\n",
            "Epoch 587/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3999 - acc: 0.8609 - val_loss: 0.3757 - val_acc: 0.8697\n",
            "Epoch 588/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3995 - acc: 0.8609 - val_loss: 0.3724 - val_acc: 0.8708\n",
            "Epoch 589/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4003 - acc: 0.8606 - val_loss: 0.3773 - val_acc: 0.8673\n",
            "Epoch 590/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3985 - acc: 0.8615 - val_loss: 0.3754 - val_acc: 0.8689\n",
            "Epoch 591/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4021 - acc: 0.8602 - val_loss: 0.3814 - val_acc: 0.8670\n",
            "Epoch 592/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3974 - acc: 0.8625 - val_loss: 0.3772 - val_acc: 0.8675\n",
            "Epoch 593/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3985 - acc: 0.8611 - val_loss: 0.3738 - val_acc: 0.8687\n",
            "Epoch 594/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4002 - acc: 0.8613 - val_loss: 0.3736 - val_acc: 0.8699\n",
            "Epoch 595/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4004 - acc: 0.8613 - val_loss: 0.3774 - val_acc: 0.8682\n",
            "Epoch 596/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8608 - val_loss: 0.3740 - val_acc: 0.8692\n",
            "Epoch 597/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3983 - acc: 0.8615 - val_loss: 0.3801 - val_acc: 0.8685\n",
            "Epoch 598/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3995 - acc: 0.8617 - val_loss: 0.3778 - val_acc: 0.8670\n",
            "Epoch 599/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4003 - acc: 0.8603 - val_loss: 0.3786 - val_acc: 0.8667\n",
            "Epoch 600/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4008 - acc: 0.8610 - val_loss: 0.3804 - val_acc: 0.8670\n",
            "Epoch 601/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3994 - acc: 0.8618 - val_loss: 0.3736 - val_acc: 0.8709\n",
            "Epoch 602/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3984 - acc: 0.8618 - val_loss: 0.3759 - val_acc: 0.8675\n",
            "Epoch 603/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4002 - acc: 0.8608 - val_loss: 0.3807 - val_acc: 0.8663\n",
            "Epoch 604/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4006 - acc: 0.8601 - val_loss: 0.3739 - val_acc: 0.8693\n",
            "Epoch 605/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4008 - acc: 0.8598 - val_loss: 0.3846 - val_acc: 0.8625\n",
            "Epoch 606/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4020 - acc: 0.8604 - val_loss: 0.3737 - val_acc: 0.8712\n",
            "Epoch 607/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3989 - acc: 0.8619 - val_loss: 0.3830 - val_acc: 0.8675\n",
            "Epoch 608/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3997 - acc: 0.8612 - val_loss: 0.3771 - val_acc: 0.8666\n",
            "Epoch 609/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.4024 - acc: 0.8608 - val_loss: 0.3812 - val_acc: 0.8659\n",
            "Epoch 610/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3998 - acc: 0.8609 - val_loss: 0.3824 - val_acc: 0.8654\n",
            "Epoch 611/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8607 - val_loss: 0.3718 - val_acc: 0.8686\n",
            "Epoch 612/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3992 - acc: 0.8617 - val_loss: 0.3818 - val_acc: 0.8654\n",
            "Epoch 613/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4001 - acc: 0.8614 - val_loss: 0.3722 - val_acc: 0.8715\n",
            "Epoch 614/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3994 - acc: 0.8612 - val_loss: 0.3805 - val_acc: 0.8659\n",
            "Epoch 615/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4010 - acc: 0.8606 - val_loss: 0.3839 - val_acc: 0.8649\n",
            "Epoch 616/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3983 - acc: 0.8619 - val_loss: 0.3862 - val_acc: 0.8633\n",
            "Epoch 617/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4015 - acc: 0.8608 - val_loss: 0.3752 - val_acc: 0.8672\n",
            "Epoch 618/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4015 - acc: 0.8610 - val_loss: 0.3736 - val_acc: 0.8690\n",
            "Epoch 619/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3991 - acc: 0.8615 - val_loss: 0.3765 - val_acc: 0.8670\n",
            "Epoch 620/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3993 - acc: 0.8598 - val_loss: 0.3754 - val_acc: 0.8683\n",
            "Epoch 621/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3998 - acc: 0.8601 - val_loss: 0.3815 - val_acc: 0.8662\n",
            "Epoch 622/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4001 - acc: 0.8611 - val_loss: 0.3739 - val_acc: 0.8709\n",
            "Epoch 623/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3991 - acc: 0.8601 - val_loss: 0.3732 - val_acc: 0.8691\n",
            "Epoch 624/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3987 - acc: 0.8613 - val_loss: 0.3760 - val_acc: 0.8690\n",
            "Epoch 625/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3981 - acc: 0.8622 - val_loss: 0.3746 - val_acc: 0.8683\n",
            "Epoch 626/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4004 - acc: 0.8604 - val_loss: 0.3785 - val_acc: 0.8658\n",
            "Epoch 627/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4015 - acc: 0.8611 - val_loss: 0.3758 - val_acc: 0.8683\n",
            "Epoch 628/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3997 - acc: 0.8609 - val_loss: 0.3768 - val_acc: 0.8701\n",
            "Epoch 629/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3986 - acc: 0.8610 - val_loss: 0.3723 - val_acc: 0.8711\n",
            "Epoch 630/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3992 - acc: 0.8612 - val_loss: 0.3782 - val_acc: 0.8650\n",
            "Epoch 631/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3996 - acc: 0.8618 - val_loss: 0.3759 - val_acc: 0.8692\n",
            "Epoch 632/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.4007 - acc: 0.8607 - val_loss: 0.3777 - val_acc: 0.8669\n",
            "Epoch 633/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3998 - acc: 0.8604 - val_loss: 0.3915 - val_acc: 0.8612\n",
            "Epoch 634/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3994 - acc: 0.8613 - val_loss: 0.3813 - val_acc: 0.8657\n",
            "Epoch 635/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3992 - acc: 0.8611 - val_loss: 0.3712 - val_acc: 0.8710\n",
            "Epoch 636/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3973 - acc: 0.8615 - val_loss: 0.3717 - val_acc: 0.8716\n",
            "Epoch 637/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3992 - acc: 0.8616 - val_loss: 0.3758 - val_acc: 0.8680\n",
            "Epoch 638/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3964 - acc: 0.8619 - val_loss: 0.3719 - val_acc: 0.8679\n",
            "Epoch 639/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3993 - acc: 0.8613 - val_loss: 0.3740 - val_acc: 0.8691\n",
            "Epoch 640/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3988 - acc: 0.8618 - val_loss: 0.3751 - val_acc: 0.8687\n",
            "Epoch 641/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8615 - val_loss: 0.3842 - val_acc: 0.8636\n",
            "Epoch 642/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4002 - acc: 0.8609 - val_loss: 0.3762 - val_acc: 0.8685\n",
            "Epoch 643/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4005 - acc: 0.8607 - val_loss: 0.3695 - val_acc: 0.8704\n",
            "Epoch 644/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3981 - acc: 0.8609 - val_loss: 0.3796 - val_acc: 0.8679\n",
            "Epoch 645/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4000 - acc: 0.8610 - val_loss: 0.3795 - val_acc: 0.8652\n",
            "Epoch 646/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3994 - acc: 0.8612 - val_loss: 0.3813 - val_acc: 0.8678\n",
            "Epoch 647/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3986 - acc: 0.8605 - val_loss: 0.3738 - val_acc: 0.8705\n",
            "Epoch 648/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4000 - acc: 0.8607 - val_loss: 0.3734 - val_acc: 0.8698\n",
            "Epoch 649/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3993 - acc: 0.8613 - val_loss: 0.3737 - val_acc: 0.8705\n",
            "Epoch 650/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8607 - val_loss: 0.3833 - val_acc: 0.8663\n",
            "Epoch 651/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3995 - acc: 0.8612 - val_loss: 0.3788 - val_acc: 0.8675\n",
            "Epoch 652/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3973 - acc: 0.8613 - val_loss: 0.3777 - val_acc: 0.8688\n",
            "Epoch 653/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3982 - acc: 0.8622 - val_loss: 0.3789 - val_acc: 0.8649\n",
            "Epoch 654/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3979 - acc: 0.8604 - val_loss: 0.3781 - val_acc: 0.8668\n",
            "Epoch 655/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4004 - acc: 0.8605 - val_loss: 0.3816 - val_acc: 0.8670\n",
            "Epoch 656/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3986 - acc: 0.8612 - val_loss: 0.3878 - val_acc: 0.8634\n",
            "Epoch 657/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3996 - acc: 0.8607 - val_loss: 0.3760 - val_acc: 0.8691\n",
            "Epoch 658/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3991 - acc: 0.8617 - val_loss: 0.3748 - val_acc: 0.8688\n",
            "Epoch 659/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3989 - acc: 0.8605 - val_loss: 0.3774 - val_acc: 0.8684\n",
            "Epoch 660/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4012 - acc: 0.8609 - val_loss: 0.3728 - val_acc: 0.8676\n",
            "Epoch 661/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4006 - acc: 0.8607 - val_loss: 0.3759 - val_acc: 0.8685\n",
            "Epoch 662/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3994 - acc: 0.8608 - val_loss: 0.3774 - val_acc: 0.8693\n",
            "Epoch 663/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3981 - acc: 0.8619 - val_loss: 0.3732 - val_acc: 0.8682\n",
            "Epoch 664/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3980 - acc: 0.8615 - val_loss: 0.3715 - val_acc: 0.8716\n",
            "Epoch 665/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3994 - acc: 0.8610 - val_loss: 0.4025 - val_acc: 0.8529\n",
            "Epoch 666/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3980 - acc: 0.8616 - val_loss: 0.3782 - val_acc: 0.8670\n",
            "Epoch 667/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4010 - acc: 0.8603 - val_loss: 0.3730 - val_acc: 0.8715\n",
            "Epoch 668/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3993 - acc: 0.8610 - val_loss: 0.3787 - val_acc: 0.8683\n",
            "Epoch 669/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3982 - acc: 0.8615 - val_loss: 0.3831 - val_acc: 0.8677\n",
            "Epoch 670/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3968 - acc: 0.8612 - val_loss: 0.3761 - val_acc: 0.8698\n",
            "Epoch 671/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.4019 - acc: 0.8604 - val_loss: 0.3776 - val_acc: 0.8690\n",
            "Epoch 672/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3996 - acc: 0.8615 - val_loss: 0.3775 - val_acc: 0.8662\n",
            "Epoch 673/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3979 - acc: 0.8608 - val_loss: 0.3731 - val_acc: 0.8720\n",
            "Epoch 674/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3972 - acc: 0.8617 - val_loss: 0.3803 - val_acc: 0.8673\n",
            "Epoch 675/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3997 - acc: 0.8603 - val_loss: 0.3733 - val_acc: 0.8697\n",
            "Epoch 676/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3988 - acc: 0.8609 - val_loss: 0.3781 - val_acc: 0.8684\n",
            "Epoch 677/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3972 - acc: 0.8619 - val_loss: 0.3766 - val_acc: 0.8677\n",
            "Epoch 678/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3987 - acc: 0.8609 - val_loss: 0.3790 - val_acc: 0.8675\n",
            "Epoch 679/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3987 - acc: 0.8622 - val_loss: 0.3719 - val_acc: 0.8711\n",
            "Epoch 680/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3992 - acc: 0.8612 - val_loss: 0.3855 - val_acc: 0.8671\n",
            "Epoch 681/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3999 - acc: 0.8613 - val_loss: 0.3786 - val_acc: 0.8665\n",
            "Epoch 682/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3985 - acc: 0.8614 - val_loss: 0.3793 - val_acc: 0.8666\n",
            "Epoch 683/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3986 - acc: 0.8612 - val_loss: 0.3847 - val_acc: 0.8623\n",
            "Epoch 684/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3982 - acc: 0.8617 - val_loss: 0.3767 - val_acc: 0.8691\n",
            "Epoch 685/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3973 - acc: 0.8620 - val_loss: 0.3709 - val_acc: 0.8694\n",
            "Epoch 686/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3993 - acc: 0.8616 - val_loss: 0.3731 - val_acc: 0.8665\n",
            "Epoch 687/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3972 - acc: 0.8616 - val_loss: 0.3810 - val_acc: 0.8661\n",
            "Epoch 688/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3986 - acc: 0.8618 - val_loss: 0.3847 - val_acc: 0.8646\n",
            "Epoch 689/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3981 - acc: 0.8624 - val_loss: 0.3715 - val_acc: 0.8720\n",
            "Epoch 690/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3969 - acc: 0.8617 - val_loss: 0.3760 - val_acc: 0.8661\n",
            "Epoch 691/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3993 - acc: 0.8610 - val_loss: 0.3753 - val_acc: 0.8677\n",
            "Epoch 692/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3977 - acc: 0.8611 - val_loss: 0.3750 - val_acc: 0.8678\n",
            "Epoch 693/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3984 - acc: 0.8616 - val_loss: 0.3731 - val_acc: 0.8726\n",
            "Epoch 694/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3995 - acc: 0.8613 - val_loss: 0.3824 - val_acc: 0.8652\n",
            "Epoch 695/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3955 - acc: 0.8626 - val_loss: 0.3830 - val_acc: 0.8666\n",
            "Epoch 696/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3986 - acc: 0.8619 - val_loss: 0.3767 - val_acc: 0.8696\n",
            "Epoch 697/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3987 - acc: 0.8613 - val_loss: 0.3720 - val_acc: 0.8696\n",
            "Epoch 698/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3998 - acc: 0.8610 - val_loss: 0.3707 - val_acc: 0.8702\n",
            "Epoch 699/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3978 - acc: 0.8614 - val_loss: 0.3801 - val_acc: 0.8665\n",
            "Epoch 700/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3984 - acc: 0.8623 - val_loss: 0.3770 - val_acc: 0.8681\n",
            "Epoch 701/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3988 - acc: 0.8613 - val_loss: 0.3721 - val_acc: 0.8705\n",
            "Epoch 702/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3983 - acc: 0.8617 - val_loss: 0.3769 - val_acc: 0.8671\n",
            "Epoch 703/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3976 - acc: 0.8612 - val_loss: 0.3755 - val_acc: 0.8688\n",
            "Epoch 704/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3976 - acc: 0.8623 - val_loss: 0.3707 - val_acc: 0.8705\n",
            "Epoch 705/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3969 - acc: 0.8621 - val_loss: 0.3770 - val_acc: 0.8683\n",
            "Epoch 706/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3987 - acc: 0.8617 - val_loss: 0.3713 - val_acc: 0.8702\n",
            "Epoch 707/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.4005 - acc: 0.8612 - val_loss: 0.3753 - val_acc: 0.8687\n",
            "Epoch 708/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3963 - acc: 0.8626 - val_loss: 0.3721 - val_acc: 0.8709\n",
            "Epoch 709/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3995 - acc: 0.8612 - val_loss: 0.3782 - val_acc: 0.8662\n",
            "Epoch 710/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3967 - acc: 0.8622 - val_loss: 0.3881 - val_acc: 0.8651\n",
            "Epoch 711/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8618 - val_loss: 0.3733 - val_acc: 0.8700\n",
            "Epoch 712/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3962 - acc: 0.8619 - val_loss: 0.3742 - val_acc: 0.8701\n",
            "Epoch 713/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3989 - acc: 0.8613 - val_loss: 0.3745 - val_acc: 0.8694\n",
            "Epoch 714/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3988 - acc: 0.8620 - val_loss: 0.3761 - val_acc: 0.8658\n",
            "Epoch 715/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3979 - acc: 0.8619 - val_loss: 0.3720 - val_acc: 0.8709\n",
            "Epoch 716/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3969 - acc: 0.8624 - val_loss: 0.3704 - val_acc: 0.8722\n",
            "Epoch 717/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3964 - acc: 0.8624 - val_loss: 0.3754 - val_acc: 0.8697\n",
            "Epoch 718/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3975 - acc: 0.8619 - val_loss: 0.3740 - val_acc: 0.8683\n",
            "Epoch 719/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3959 - acc: 0.8623 - val_loss: 0.3763 - val_acc: 0.8678\n",
            "Epoch 720/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3969 - acc: 0.8618 - val_loss: 0.3789 - val_acc: 0.8656\n",
            "Epoch 721/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3981 - acc: 0.8615 - val_loss: 0.3735 - val_acc: 0.8692\n",
            "Epoch 722/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3978 - acc: 0.8614 - val_loss: 0.3775 - val_acc: 0.8697\n",
            "Epoch 723/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3959 - acc: 0.8625 - val_loss: 0.3789 - val_acc: 0.8681\n",
            "Epoch 724/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3993 - acc: 0.8605 - val_loss: 0.3757 - val_acc: 0.8677\n",
            "Epoch 725/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3981 - acc: 0.8622 - val_loss: 0.3760 - val_acc: 0.8671\n",
            "Epoch 726/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.4002 - acc: 0.8608 - val_loss: 0.3719 - val_acc: 0.8718\n",
            "Epoch 727/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3966 - acc: 0.8626 - val_loss: 0.3774 - val_acc: 0.8693\n",
            "Epoch 728/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3985 - acc: 0.8618 - val_loss: 0.3772 - val_acc: 0.8668\n",
            "Epoch 729/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3974 - acc: 0.8618 - val_loss: 0.3763 - val_acc: 0.8686\n",
            "Epoch 730/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3962 - acc: 0.8622 - val_loss: 0.3725 - val_acc: 0.8674\n",
            "Epoch 731/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3961 - acc: 0.8619 - val_loss: 0.3716 - val_acc: 0.8718\n",
            "Epoch 732/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3982 - acc: 0.8620 - val_loss: 0.3750 - val_acc: 0.8675\n",
            "Epoch 733/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8619 - val_loss: 0.3778 - val_acc: 0.8675\n",
            "Epoch 734/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3978 - acc: 0.8612 - val_loss: 0.3761 - val_acc: 0.8690\n",
            "Epoch 735/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8618 - val_loss: 0.3763 - val_acc: 0.8677\n",
            "Epoch 736/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3997 - acc: 0.8612 - val_loss: 0.3757 - val_acc: 0.8684\n",
            "Epoch 737/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3977 - acc: 0.8614 - val_loss: 0.3768 - val_acc: 0.8681\n",
            "Epoch 738/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3977 - acc: 0.8620 - val_loss: 0.3723 - val_acc: 0.8715\n",
            "Epoch 739/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3968 - acc: 0.8621 - val_loss: 0.3787 - val_acc: 0.8681\n",
            "Epoch 740/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3974 - acc: 0.8616 - val_loss: 0.3732 - val_acc: 0.8703\n",
            "Epoch 741/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3969 - acc: 0.8620 - val_loss: 0.3734 - val_acc: 0.8672\n",
            "Epoch 742/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3985 - acc: 0.8619 - val_loss: 0.3744 - val_acc: 0.8702\n",
            "Epoch 743/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3963 - acc: 0.8616 - val_loss: 0.3749 - val_acc: 0.8697\n",
            "Epoch 744/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3980 - acc: 0.8621 - val_loss: 0.3720 - val_acc: 0.8687\n",
            "Epoch 745/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3965 - acc: 0.8622 - val_loss: 0.3704 - val_acc: 0.8703\n",
            "Epoch 746/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3966 - acc: 0.8628 - val_loss: 0.3741 - val_acc: 0.8687\n",
            "Epoch 747/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3975 - acc: 0.8625 - val_loss: 0.3756 - val_acc: 0.8690\n",
            "Epoch 748/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3957 - acc: 0.8620 - val_loss: 0.3745 - val_acc: 0.8682\n",
            "Epoch 749/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3984 - acc: 0.8619 - val_loss: 0.3707 - val_acc: 0.8721\n",
            "Epoch 750/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3961 - acc: 0.8620 - val_loss: 0.3761 - val_acc: 0.8700\n",
            "Epoch 751/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3973 - acc: 0.8615 - val_loss: 0.3725 - val_acc: 0.8703\n",
            "Epoch 752/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3965 - acc: 0.8625 - val_loss: 0.3738 - val_acc: 0.8683\n",
            "Epoch 753/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3966 - acc: 0.8623 - val_loss: 0.3739 - val_acc: 0.8703\n",
            "Epoch 754/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8621 - val_loss: 0.3717 - val_acc: 0.8695\n",
            "Epoch 755/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3965 - acc: 0.8625 - val_loss: 0.3737 - val_acc: 0.8696\n",
            "Epoch 756/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3958 - acc: 0.8626 - val_loss: 0.3814 - val_acc: 0.8672\n",
            "Epoch 757/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3966 - acc: 0.8614 - val_loss: 0.3722 - val_acc: 0.8705\n",
            "Epoch 758/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3981 - acc: 0.8612 - val_loss: 0.3761 - val_acc: 0.8696\n",
            "Epoch 759/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3997 - acc: 0.8612 - val_loss: 0.3766 - val_acc: 0.8690\n",
            "Epoch 760/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3977 - acc: 0.8617 - val_loss: 0.3731 - val_acc: 0.8693\n",
            "Epoch 761/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3946 - acc: 0.8629 - val_loss: 0.3777 - val_acc: 0.8669\n",
            "Epoch 762/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3962 - acc: 0.8623 - val_loss: 0.3746 - val_acc: 0.8700\n",
            "Epoch 763/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3974 - acc: 0.8616 - val_loss: 0.3732 - val_acc: 0.8685\n",
            "Epoch 764/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3979 - acc: 0.8622 - val_loss: 0.3804 - val_acc: 0.8661\n",
            "Epoch 765/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3961 - acc: 0.8621 - val_loss: 0.3723 - val_acc: 0.8673\n",
            "Epoch 766/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3968 - acc: 0.8624 - val_loss: 0.3720 - val_acc: 0.8723\n",
            "Epoch 767/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3989 - acc: 0.8615 - val_loss: 0.3741 - val_acc: 0.8705\n",
            "Epoch 768/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8618 - val_loss: 0.3721 - val_acc: 0.8671\n",
            "Epoch 769/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3967 - acc: 0.8620 - val_loss: 0.3795 - val_acc: 0.8679\n",
            "Epoch 770/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3964 - acc: 0.8629 - val_loss: 0.3721 - val_acc: 0.8722\n",
            "Epoch 771/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3969 - acc: 0.8613 - val_loss: 0.3724 - val_acc: 0.8691\n",
            "Epoch 772/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3969 - acc: 0.8625 - val_loss: 0.3737 - val_acc: 0.8681\n",
            "Epoch 773/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3956 - acc: 0.8629 - val_loss: 0.3763 - val_acc: 0.8679\n",
            "Epoch 774/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3979 - acc: 0.8613 - val_loss: 0.3756 - val_acc: 0.8672\n",
            "Epoch 775/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3965 - acc: 0.8623 - val_loss: 0.3784 - val_acc: 0.8675\n",
            "Epoch 776/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3963 - acc: 0.8624 - val_loss: 0.3804 - val_acc: 0.8647\n",
            "Epoch 777/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3982 - acc: 0.8618 - val_loss: 0.3753 - val_acc: 0.8683\n",
            "Epoch 778/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3963 - acc: 0.8619 - val_loss: 0.3746 - val_acc: 0.8679\n",
            "Epoch 779/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3958 - acc: 0.8632 - val_loss: 0.3771 - val_acc: 0.8682\n",
            "Epoch 780/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3966 - acc: 0.8614 - val_loss: 0.3716 - val_acc: 0.8718\n",
            "Epoch 781/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3957 - acc: 0.8627 - val_loss: 0.3732 - val_acc: 0.8709\n",
            "Epoch 782/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8616 - val_loss: 0.3734 - val_acc: 0.8694\n",
            "Epoch 783/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3959 - acc: 0.8622 - val_loss: 0.3735 - val_acc: 0.8668\n",
            "Epoch 784/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3963 - acc: 0.8627 - val_loss: 0.3765 - val_acc: 0.8683\n",
            "Epoch 785/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3964 - acc: 0.8623 - val_loss: 0.3827 - val_acc: 0.8688\n",
            "Epoch 786/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3970 - acc: 0.8619 - val_loss: 0.3814 - val_acc: 0.8690\n",
            "Epoch 787/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3979 - acc: 0.8621 - val_loss: 0.3738 - val_acc: 0.8688\n",
            "Epoch 788/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3973 - acc: 0.8620 - val_loss: 0.3755 - val_acc: 0.8709\n",
            "Epoch 789/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3984 - acc: 0.8611 - val_loss: 0.3722 - val_acc: 0.8704\n",
            "Epoch 790/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3970 - acc: 0.8622 - val_loss: 0.3712 - val_acc: 0.8716\n",
            "Epoch 791/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3967 - acc: 0.8625 - val_loss: 0.3747 - val_acc: 0.8682\n",
            "Epoch 792/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3953 - acc: 0.8621 - val_loss: 0.3735 - val_acc: 0.8665\n",
            "Epoch 793/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3959 - acc: 0.8624 - val_loss: 0.3779 - val_acc: 0.8701\n",
            "Epoch 794/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3957 - acc: 0.8623 - val_loss: 0.3726 - val_acc: 0.8700\n",
            "Epoch 795/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3952 - acc: 0.8621 - val_loss: 0.3762 - val_acc: 0.8687\n",
            "Epoch 796/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3962 - acc: 0.8619 - val_loss: 0.3826 - val_acc: 0.8666\n",
            "Epoch 797/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3974 - acc: 0.8609 - val_loss: 0.3768 - val_acc: 0.8665\n",
            "Epoch 798/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3958 - acc: 0.8621 - val_loss: 0.3788 - val_acc: 0.8706\n",
            "Epoch 799/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3970 - acc: 0.8629 - val_loss: 0.3732 - val_acc: 0.8697\n",
            "Epoch 800/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3964 - acc: 0.8628 - val_loss: 0.3726 - val_acc: 0.8700\n",
            "Epoch 801/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3966 - acc: 0.8625 - val_loss: 0.3740 - val_acc: 0.8687\n",
            "Epoch 802/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3975 - acc: 0.8609 - val_loss: 0.3833 - val_acc: 0.8666\n",
            "Epoch 803/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3976 - acc: 0.8618 - val_loss: 0.3705 - val_acc: 0.8694\n",
            "Epoch 804/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3984 - acc: 0.8610 - val_loss: 0.3772 - val_acc: 0.8691\n",
            "Epoch 805/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3953 - acc: 0.8631 - val_loss: 0.3756 - val_acc: 0.8680\n",
            "Epoch 806/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3987 - acc: 0.8617 - val_loss: 0.3718 - val_acc: 0.8715\n",
            "Epoch 807/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3967 - acc: 0.8623 - val_loss: 0.3711 - val_acc: 0.8706\n",
            "Epoch 808/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3966 - acc: 0.8618 - val_loss: 0.3821 - val_acc: 0.8668\n",
            "Epoch 809/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3980 - acc: 0.8620 - val_loss: 0.3764 - val_acc: 0.8691\n",
            "Epoch 810/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8615 - val_loss: 0.3740 - val_acc: 0.8707\n",
            "Epoch 811/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3963 - acc: 0.8621 - val_loss: 0.3722 - val_acc: 0.8711\n",
            "Epoch 812/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3954 - acc: 0.8629 - val_loss: 0.3757 - val_acc: 0.8685\n",
            "Epoch 813/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3956 - acc: 0.8630 - val_loss: 0.3778 - val_acc: 0.8664\n",
            "Epoch 814/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3948 - acc: 0.8631 - val_loss: 0.3738 - val_acc: 0.8703\n",
            "Epoch 815/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3950 - acc: 0.8616 - val_loss: 0.3866 - val_acc: 0.8640\n",
            "Epoch 816/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3972 - acc: 0.8616 - val_loss: 0.3714 - val_acc: 0.8719\n",
            "Epoch 817/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3964 - acc: 0.8621 - val_loss: 0.3737 - val_acc: 0.8693\n",
            "Epoch 818/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8624 - val_loss: 0.3767 - val_acc: 0.8689\n",
            "Epoch 819/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3972 - acc: 0.8620 - val_loss: 0.3775 - val_acc: 0.8690\n",
            "Epoch 820/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3985 - acc: 0.8613 - val_loss: 0.3753 - val_acc: 0.8704\n",
            "Epoch 821/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3953 - acc: 0.8630 - val_loss: 0.3736 - val_acc: 0.8707\n",
            "Epoch 822/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3968 - acc: 0.8623 - val_loss: 0.3747 - val_acc: 0.8678\n",
            "Epoch 823/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3957 - acc: 0.8622 - val_loss: 0.3710 - val_acc: 0.8727\n",
            "Epoch 824/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3950 - acc: 0.8624 - val_loss: 0.3736 - val_acc: 0.8695\n",
            "Epoch 825/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8624 - val_loss: 0.3743 - val_acc: 0.8695\n",
            "Epoch 826/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3970 - acc: 0.8616 - val_loss: 0.3827 - val_acc: 0.8639\n",
            "Epoch 827/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3988 - acc: 0.8613 - val_loss: 0.3715 - val_acc: 0.8708\n",
            "Epoch 828/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3960 - acc: 0.8628 - val_loss: 0.3774 - val_acc: 0.8675\n",
            "Epoch 829/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3985 - acc: 0.8607 - val_loss: 0.3701 - val_acc: 0.8703\n",
            "Epoch 830/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3970 - acc: 0.8621 - val_loss: 0.3825 - val_acc: 0.8626\n",
            "Epoch 831/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3962 - acc: 0.8627 - val_loss: 0.3733 - val_acc: 0.8726\n",
            "Epoch 832/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3953 - acc: 0.8628 - val_loss: 0.3784 - val_acc: 0.8678\n",
            "Epoch 833/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3976 - acc: 0.8618 - val_loss: 0.3747 - val_acc: 0.8683\n",
            "Epoch 834/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8631 - val_loss: 0.3748 - val_acc: 0.8720\n",
            "Epoch 835/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3955 - acc: 0.8624 - val_loss: 0.3690 - val_acc: 0.8712\n",
            "Epoch 836/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3975 - acc: 0.8618 - val_loss: 0.3718 - val_acc: 0.8711\n",
            "Epoch 837/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3957 - acc: 0.8631 - val_loss: 0.3753 - val_acc: 0.8707\n",
            "Epoch 838/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3962 - acc: 0.8621 - val_loss: 0.3727 - val_acc: 0.8707\n",
            "Epoch 839/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3972 - acc: 0.8625 - val_loss: 0.3753 - val_acc: 0.8677\n",
            "Epoch 840/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8616 - val_loss: 0.3751 - val_acc: 0.8690\n",
            "Epoch 841/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3967 - acc: 0.8622 - val_loss: 0.3799 - val_acc: 0.8655\n",
            "Epoch 842/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3955 - acc: 0.8627 - val_loss: 0.3723 - val_acc: 0.8700\n",
            "Epoch 843/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3977 - acc: 0.8622 - val_loss: 0.3731 - val_acc: 0.8705\n",
            "Epoch 844/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3965 - acc: 0.8625 - val_loss: 0.3802 - val_acc: 0.8671\n",
            "Epoch 845/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3932 - acc: 0.8632 - val_loss: 0.3787 - val_acc: 0.8687\n",
            "Epoch 846/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3973 - acc: 0.8622 - val_loss: 0.3717 - val_acc: 0.8709\n",
            "Epoch 847/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3969 - acc: 0.8621 - val_loss: 0.3677 - val_acc: 0.8728\n",
            "Epoch 848/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3962 - acc: 0.8626 - val_loss: 0.3714 - val_acc: 0.8707\n",
            "Epoch 849/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3950 - acc: 0.8633 - val_loss: 0.3766 - val_acc: 0.8666\n",
            "Epoch 850/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3965 - acc: 0.8620 - val_loss: 0.3798 - val_acc: 0.8648\n",
            "Epoch 851/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3962 - acc: 0.8620 - val_loss: 0.3736 - val_acc: 0.8685\n",
            "Epoch 852/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3959 - acc: 0.8623 - val_loss: 0.3784 - val_acc: 0.8682\n",
            "Epoch 853/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3968 - acc: 0.8620 - val_loss: 0.3754 - val_acc: 0.8675\n",
            "Epoch 854/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3962 - acc: 0.8615 - val_loss: 0.3787 - val_acc: 0.8675\n",
            "Epoch 855/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3956 - acc: 0.8629 - val_loss: 0.3751 - val_acc: 0.8681\n",
            "Epoch 856/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3960 - acc: 0.8625 - val_loss: 0.3734 - val_acc: 0.8721\n",
            "Epoch 857/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3946 - acc: 0.8622 - val_loss: 0.3725 - val_acc: 0.8712\n",
            "Epoch 858/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8625 - val_loss: 0.3773 - val_acc: 0.8686\n",
            "Epoch 859/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3957 - acc: 0.8621 - val_loss: 0.3765 - val_acc: 0.8669\n",
            "Epoch 860/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3944 - acc: 0.8628 - val_loss: 0.3742 - val_acc: 0.8699\n",
            "Epoch 861/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3940 - acc: 0.8626 - val_loss: 0.3738 - val_acc: 0.8708\n",
            "Epoch 862/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3970 - acc: 0.8621 - val_loss: 0.3762 - val_acc: 0.8664\n",
            "Epoch 863/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3955 - acc: 0.8631 - val_loss: 0.3833 - val_acc: 0.8685\n",
            "Epoch 864/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3951 - acc: 0.8626 - val_loss: 0.3851 - val_acc: 0.8637\n",
            "Epoch 865/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3959 - acc: 0.8624 - val_loss: 0.3770 - val_acc: 0.8649\n",
            "Epoch 866/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3956 - acc: 0.8622 - val_loss: 0.3743 - val_acc: 0.8678\n",
            "Epoch 867/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3952 - acc: 0.8623 - val_loss: 0.3755 - val_acc: 0.8693\n",
            "Epoch 868/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3970 - acc: 0.8618 - val_loss: 0.3791 - val_acc: 0.8660\n",
            "Epoch 869/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3950 - acc: 0.8631 - val_loss: 0.3736 - val_acc: 0.8710\n",
            "Epoch 870/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3941 - acc: 0.8624 - val_loss: 0.3725 - val_acc: 0.8681\n",
            "Epoch 871/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3963 - acc: 0.8625 - val_loss: 0.3730 - val_acc: 0.8697\n",
            "Epoch 872/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3950 - acc: 0.8635 - val_loss: 0.3804 - val_acc: 0.8685\n",
            "Epoch 873/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8620 - val_loss: 0.3738 - val_acc: 0.8679\n",
            "Epoch 874/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3968 - acc: 0.8627 - val_loss: 0.3747 - val_acc: 0.8683\n",
            "Epoch 875/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3936 - acc: 0.8630 - val_loss: 0.3739 - val_acc: 0.8673\n",
            "Epoch 876/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3954 - acc: 0.8620 - val_loss: 0.3712 - val_acc: 0.8701\n",
            "Epoch 877/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3951 - acc: 0.8621 - val_loss: 0.3751 - val_acc: 0.8692\n",
            "Epoch 878/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3952 - acc: 0.8626 - val_loss: 0.3750 - val_acc: 0.8699\n",
            "Epoch 879/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3957 - acc: 0.8625 - val_loss: 0.3724 - val_acc: 0.8697\n",
            "Epoch 880/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3946 - acc: 0.8628 - val_loss: 0.3762 - val_acc: 0.8680\n",
            "Epoch 881/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3944 - acc: 0.8630 - val_loss: 0.3891 - val_acc: 0.8642\n",
            "Epoch 882/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3963 - acc: 0.8626 - val_loss: 0.3746 - val_acc: 0.8693\n",
            "Epoch 883/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3971 - acc: 0.8622 - val_loss: 0.3709 - val_acc: 0.8710\n",
            "Epoch 884/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3940 - acc: 0.8628 - val_loss: 0.3723 - val_acc: 0.8716\n",
            "Epoch 885/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3951 - acc: 0.8623 - val_loss: 0.3742 - val_acc: 0.8673\n",
            "Epoch 886/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3963 - acc: 0.8626 - val_loss: 0.3768 - val_acc: 0.8685\n",
            "Epoch 887/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8622 - val_loss: 0.3740 - val_acc: 0.8697\n",
            "Epoch 888/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3951 - acc: 0.8622 - val_loss: 0.3756 - val_acc: 0.8706\n",
            "Epoch 889/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3969 - acc: 0.8622 - val_loss: 0.3746 - val_acc: 0.8707\n",
            "Epoch 890/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3949 - acc: 0.8623 - val_loss: 0.3725 - val_acc: 0.8711\n",
            "Epoch 891/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8622 - val_loss: 0.3802 - val_acc: 0.8657\n",
            "Epoch 892/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3934 - acc: 0.8632 - val_loss: 0.3740 - val_acc: 0.8693\n",
            "Epoch 893/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3955 - acc: 0.8620 - val_loss: 0.3772 - val_acc: 0.8677\n",
            "Epoch 894/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3945 - acc: 0.8630 - val_loss: 0.3746 - val_acc: 0.8690\n",
            "Epoch 895/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3948 - acc: 0.8631 - val_loss: 0.3777 - val_acc: 0.8681\n",
            "Epoch 896/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3943 - acc: 0.8629 - val_loss: 0.3762 - val_acc: 0.8690\n",
            "Epoch 897/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3937 - acc: 0.8634 - val_loss: 0.3838 - val_acc: 0.8653\n",
            "Epoch 898/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3985 - acc: 0.8617 - val_loss: 0.3717 - val_acc: 0.8705\n",
            "Epoch 899/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3944 - acc: 0.8625 - val_loss: 0.3710 - val_acc: 0.8699\n",
            "Epoch 900/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3943 - acc: 0.8624 - val_loss: 0.3723 - val_acc: 0.8723\n",
            "Epoch 901/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3956 - acc: 0.8625 - val_loss: 0.3742 - val_acc: 0.8678\n",
            "Epoch 902/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3937 - acc: 0.8627 - val_loss: 0.3761 - val_acc: 0.8679\n",
            "Epoch 903/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3945 - acc: 0.8629 - val_loss: 0.3729 - val_acc: 0.8715\n",
            "Epoch 904/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3942 - acc: 0.8633 - val_loss: 0.3743 - val_acc: 0.8716\n",
            "Epoch 905/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3961 - acc: 0.8623 - val_loss: 0.3823 - val_acc: 0.8687\n",
            "Epoch 906/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3945 - acc: 0.8629 - val_loss: 0.3775 - val_acc: 0.8690\n",
            "Epoch 907/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3947 - acc: 0.8625 - val_loss: 0.3776 - val_acc: 0.8663\n",
            "Epoch 908/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3962 - acc: 0.8622 - val_loss: 0.3769 - val_acc: 0.8672\n",
            "Epoch 909/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3937 - acc: 0.8626 - val_loss: 0.3711 - val_acc: 0.8723\n",
            "Epoch 910/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3952 - acc: 0.8629 - val_loss: 0.3726 - val_acc: 0.8709\n",
            "Epoch 911/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3942 - acc: 0.8627 - val_loss: 0.3756 - val_acc: 0.8698\n",
            "Epoch 912/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3956 - acc: 0.8620 - val_loss: 0.3732 - val_acc: 0.8694\n",
            "Epoch 913/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3951 - acc: 0.8624 - val_loss: 0.3725 - val_acc: 0.8715\n",
            "Epoch 914/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3940 - acc: 0.8625 - val_loss: 0.3767 - val_acc: 0.8678\n",
            "Epoch 915/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3949 - acc: 0.8637 - val_loss: 0.3781 - val_acc: 0.8669\n",
            "Epoch 916/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3944 - acc: 0.8636 - val_loss: 0.3767 - val_acc: 0.8661\n",
            "Epoch 917/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3946 - acc: 0.8628 - val_loss: 0.3715 - val_acc: 0.8696\n",
            "Epoch 918/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3939 - acc: 0.8635 - val_loss: 0.3756 - val_acc: 0.8681\n",
            "Epoch 919/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3946 - acc: 0.8630 - val_loss: 0.3723 - val_acc: 0.8708\n",
            "Epoch 920/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3940 - acc: 0.8632 - val_loss: 0.3734 - val_acc: 0.8712\n",
            "Epoch 921/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3957 - acc: 0.8617 - val_loss: 0.3698 - val_acc: 0.8723\n",
            "Epoch 922/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3947 - acc: 0.8623 - val_loss: 0.3734 - val_acc: 0.8685\n",
            "Epoch 923/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3957 - acc: 0.8617 - val_loss: 0.3788 - val_acc: 0.8679\n",
            "Epoch 924/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3936 - acc: 0.8630 - val_loss: 0.3758 - val_acc: 0.8690\n",
            "Epoch 925/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3944 - acc: 0.8621 - val_loss: 0.3769 - val_acc: 0.8663\n",
            "Epoch 926/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3946 - acc: 0.8626 - val_loss: 0.3735 - val_acc: 0.8697\n",
            "Epoch 927/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3939 - acc: 0.8632 - val_loss: 0.3753 - val_acc: 0.8670\n",
            "Epoch 928/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3947 - acc: 0.8629 - val_loss: 0.3778 - val_acc: 0.8665\n",
            "Epoch 929/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3959 - acc: 0.8623 - val_loss: 0.3805 - val_acc: 0.8666\n",
            "Epoch 930/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3929 - acc: 0.8629 - val_loss: 0.3746 - val_acc: 0.8709\n",
            "Epoch 931/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3932 - acc: 0.8632 - val_loss: 0.3731 - val_acc: 0.8700\n",
            "Epoch 932/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3935 - acc: 0.8628 - val_loss: 0.3765 - val_acc: 0.8694\n",
            "Epoch 933/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3947 - acc: 0.8628 - val_loss: 0.3705 - val_acc: 0.8715\n",
            "Epoch 934/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3944 - acc: 0.8633 - val_loss: 0.3741 - val_acc: 0.8703\n",
            "Epoch 935/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3941 - acc: 0.8627 - val_loss: 0.3709 - val_acc: 0.8725\n",
            "Epoch 936/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8629 - val_loss: 0.3761 - val_acc: 0.8677\n",
            "Epoch 937/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3967 - acc: 0.8622 - val_loss: 0.3773 - val_acc: 0.8681\n",
            "Epoch 938/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3959 - acc: 0.8616 - val_loss: 0.3762 - val_acc: 0.8675\n",
            "Epoch 939/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3966 - acc: 0.8616 - val_loss: 0.3717 - val_acc: 0.8694\n",
            "Epoch 940/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3931 - acc: 0.8628 - val_loss: 0.3712 - val_acc: 0.8715\n",
            "Epoch 941/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3954 - acc: 0.8620 - val_loss: 0.3774 - val_acc: 0.8681\n",
            "Epoch 942/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3943 - acc: 0.8620 - val_loss: 0.3829 - val_acc: 0.8655\n",
            "Epoch 943/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3943 - acc: 0.8627 - val_loss: 0.3806 - val_acc: 0.8658\n",
            "Epoch 944/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3954 - acc: 0.8631 - val_loss: 0.3733 - val_acc: 0.8710\n",
            "Epoch 945/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3952 - acc: 0.8621 - val_loss: 0.3715 - val_acc: 0.8727\n",
            "Epoch 946/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3956 - acc: 0.8623 - val_loss: 0.3737 - val_acc: 0.8696\n",
            "Epoch 947/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3951 - acc: 0.8621 - val_loss: 0.3716 - val_acc: 0.8713\n",
            "Epoch 948/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3935 - acc: 0.8627 - val_loss: 0.3722 - val_acc: 0.8690\n",
            "Epoch 949/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3964 - acc: 0.8622 - val_loss: 0.3756 - val_acc: 0.8683\n",
            "Epoch 950/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3945 - acc: 0.8626 - val_loss: 0.3758 - val_acc: 0.8675\n",
            "Epoch 951/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3953 - acc: 0.8617 - val_loss: 0.3724 - val_acc: 0.8708\n",
            "Epoch 952/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3954 - acc: 0.8623 - val_loss: 0.3771 - val_acc: 0.8694\n",
            "Epoch 953/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3958 - acc: 0.8621 - val_loss: 0.3811 - val_acc: 0.8663\n",
            "Epoch 954/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3949 - acc: 0.8630 - val_loss: 0.3730 - val_acc: 0.8698\n",
            "Epoch 955/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3935 - acc: 0.8641 - val_loss: 0.3721 - val_acc: 0.8693\n",
            "Epoch 956/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8634 - val_loss: 0.3713 - val_acc: 0.8708\n",
            "Epoch 957/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3944 - acc: 0.8627 - val_loss: 0.3704 - val_acc: 0.8711\n",
            "Epoch 958/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3958 - acc: 0.8623 - val_loss: 0.3717 - val_acc: 0.8709\n",
            "Epoch 959/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3948 - acc: 0.8627 - val_loss: 0.3723 - val_acc: 0.8699\n",
            "Epoch 960/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3933 - acc: 0.8636 - val_loss: 0.3704 - val_acc: 0.8710\n",
            "Epoch 961/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3941 - acc: 0.8632 - val_loss: 0.3728 - val_acc: 0.8718\n",
            "Epoch 962/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3941 - acc: 0.8632 - val_loss: 0.3848 - val_acc: 0.8651\n",
            "Epoch 963/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3939 - acc: 0.8626 - val_loss: 0.3746 - val_acc: 0.8712\n",
            "Epoch 964/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8632 - val_loss: 0.3715 - val_acc: 0.8707\n",
            "Epoch 965/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3922 - acc: 0.8626 - val_loss: 0.3694 - val_acc: 0.8727\n",
            "Epoch 966/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3941 - acc: 0.8628 - val_loss: 0.3750 - val_acc: 0.8693\n",
            "Epoch 967/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3930 - acc: 0.8629 - val_loss: 0.3727 - val_acc: 0.8718\n",
            "Epoch 968/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3943 - acc: 0.8629 - val_loss: 0.3703 - val_acc: 0.8724\n",
            "Epoch 969/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3952 - acc: 0.8627 - val_loss: 0.3705 - val_acc: 0.8717\n",
            "Epoch 970/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3959 - acc: 0.8624 - val_loss: 0.3747 - val_acc: 0.8698\n",
            "Epoch 971/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3941 - acc: 0.8631 - val_loss: 0.3811 - val_acc: 0.8655\n",
            "Epoch 972/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3930 - acc: 0.8631 - val_loss: 0.3764 - val_acc: 0.8698\n",
            "Epoch 973/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3943 - acc: 0.8625 - val_loss: 0.3687 - val_acc: 0.8720\n",
            "Epoch 974/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3929 - acc: 0.8640 - val_loss: 0.3693 - val_acc: 0.8711\n",
            "Epoch 975/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3945 - acc: 0.8628 - val_loss: 0.3723 - val_acc: 0.8727\n",
            "Epoch 976/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3940 - acc: 0.8624 - val_loss: 0.3740 - val_acc: 0.8695\n",
            "Epoch 977/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3935 - acc: 0.8626 - val_loss: 0.3821 - val_acc: 0.8648\n",
            "Epoch 978/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3938 - acc: 0.8634 - val_loss: 0.3710 - val_acc: 0.8715\n",
            "Epoch 979/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3943 - acc: 0.8629 - val_loss: 0.3754 - val_acc: 0.8694\n",
            "Epoch 980/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3940 - acc: 0.8624 - val_loss: 0.3722 - val_acc: 0.8688\n",
            "Epoch 981/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3947 - acc: 0.8630 - val_loss: 0.3754 - val_acc: 0.8683\n",
            "Epoch 982/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8628 - val_loss: 0.3709 - val_acc: 0.8697\n",
            "Epoch 983/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3932 - acc: 0.8632 - val_loss: 0.3740 - val_acc: 0.8709\n",
            "Epoch 984/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3930 - acc: 0.8628 - val_loss: 0.3698 - val_acc: 0.8718\n",
            "Epoch 985/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3935 - acc: 0.8632 - val_loss: 0.3720 - val_acc: 0.8710\n",
            "Epoch 986/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3943 - acc: 0.8622 - val_loss: 0.3738 - val_acc: 0.8676\n",
            "Epoch 987/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3935 - acc: 0.8638 - val_loss: 0.3704 - val_acc: 0.8703\n",
            "Epoch 988/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3925 - acc: 0.8636 - val_loss: 0.3734 - val_acc: 0.8690\n",
            "Epoch 989/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3946 - acc: 0.8638 - val_loss: 0.3758 - val_acc: 0.8693\n",
            "Epoch 990/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3947 - acc: 0.8629 - val_loss: 0.3718 - val_acc: 0.8672\n",
            "Epoch 991/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3940 - acc: 0.8633 - val_loss: 0.3726 - val_acc: 0.8693\n",
            "Epoch 992/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3935 - acc: 0.8631 - val_loss: 0.3749 - val_acc: 0.8696\n",
            "Epoch 993/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8636 - val_loss: 0.3771 - val_acc: 0.8679\n",
            "Epoch 994/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3930 - acc: 0.8625 - val_loss: 0.3776 - val_acc: 0.8682\n",
            "Epoch 995/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3946 - acc: 0.8627 - val_loss: 0.3697 - val_acc: 0.8715\n",
            "Epoch 996/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3951 - acc: 0.8630 - val_loss: 0.3773 - val_acc: 0.8686\n",
            "Epoch 997/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3937 - acc: 0.8626 - val_loss: 0.3741 - val_acc: 0.8689\n",
            "Epoch 998/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3936 - acc: 0.8635 - val_loss: 0.3735 - val_acc: 0.8689\n",
            "Epoch 999/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8624 - val_loss: 0.3695 - val_acc: 0.8717\n",
            "Epoch 1000/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3960 - acc: 0.8615 - val_loss: 0.3829 - val_acc: 0.8639\n",
            "Epoch 1001/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3951 - acc: 0.8628 - val_loss: 0.3743 - val_acc: 0.8692\n",
            "Epoch 1002/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3951 - acc: 0.8623 - val_loss: 0.3789 - val_acc: 0.8664\n",
            "Epoch 1003/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3940 - acc: 0.8631 - val_loss: 0.3721 - val_acc: 0.8703\n",
            "Epoch 1004/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3947 - acc: 0.8634 - val_loss: 0.3780 - val_acc: 0.8702\n",
            "Epoch 1005/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3948 - acc: 0.8626 - val_loss: 0.3745 - val_acc: 0.8694\n",
            "Epoch 1006/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3941 - acc: 0.8625 - val_loss: 0.3785 - val_acc: 0.8693\n",
            "Epoch 1007/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3961 - acc: 0.8629 - val_loss: 0.3733 - val_acc: 0.8713\n",
            "Epoch 1008/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3940 - acc: 0.8631 - val_loss: 0.3726 - val_acc: 0.8718\n",
            "Epoch 1009/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3957 - acc: 0.8626 - val_loss: 0.3783 - val_acc: 0.8662\n",
            "Epoch 1010/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3939 - acc: 0.8633 - val_loss: 0.3772 - val_acc: 0.8681\n",
            "Epoch 1011/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3986 - acc: 0.8620 - val_loss: 0.3750 - val_acc: 0.8688\n",
            "Epoch 1012/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3937 - acc: 0.8622 - val_loss: 0.3759 - val_acc: 0.8691\n",
            "Epoch 1013/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3940 - acc: 0.8624 - val_loss: 0.3722 - val_acc: 0.8715\n",
            "Epoch 1014/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3947 - acc: 0.8628 - val_loss: 0.3738 - val_acc: 0.8700\n",
            "Epoch 1015/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3932 - acc: 0.8641 - val_loss: 0.3746 - val_acc: 0.8703\n",
            "Epoch 1016/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3940 - acc: 0.8622 - val_loss: 0.3724 - val_acc: 0.8718\n",
            "Epoch 1017/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3939 - acc: 0.8633 - val_loss: 0.3755 - val_acc: 0.8669\n",
            "Epoch 1018/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3938 - acc: 0.8634 - val_loss: 0.3806 - val_acc: 0.8653\n",
            "Epoch 1019/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3938 - acc: 0.8625 - val_loss: 0.3797 - val_acc: 0.8660\n",
            "Epoch 1020/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3929 - acc: 0.8629 - val_loss: 0.3717 - val_acc: 0.8696\n",
            "Epoch 1021/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8633 - val_loss: 0.3717 - val_acc: 0.8703\n",
            "Epoch 1022/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3934 - acc: 0.8632 - val_loss: 0.3766 - val_acc: 0.8708\n",
            "Epoch 1023/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3934 - acc: 0.8635 - val_loss: 0.3781 - val_acc: 0.8693\n",
            "Epoch 1024/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3952 - acc: 0.8620 - val_loss: 0.3756 - val_acc: 0.8689\n",
            "Epoch 1025/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3931 - acc: 0.8633 - val_loss: 0.3865 - val_acc: 0.8632\n",
            "Epoch 1026/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3947 - acc: 0.8629 - val_loss: 0.3708 - val_acc: 0.8691\n",
            "Epoch 1027/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3945 - acc: 0.8625 - val_loss: 0.3735 - val_acc: 0.8697\n",
            "Epoch 1028/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8631 - val_loss: 0.3745 - val_acc: 0.8696\n",
            "Epoch 1029/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3937 - acc: 0.8624 - val_loss: 0.3822 - val_acc: 0.8666\n",
            "Epoch 1030/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3931 - acc: 0.8633 - val_loss: 0.3715 - val_acc: 0.8703\n",
            "Epoch 1031/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8626 - val_loss: 0.3740 - val_acc: 0.8707\n",
            "Epoch 1032/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3933 - acc: 0.8633 - val_loss: 0.3726 - val_acc: 0.8714\n",
            "Epoch 1033/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3924 - acc: 0.8635 - val_loss: 0.3725 - val_acc: 0.8689\n",
            "Epoch 1034/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3939 - acc: 0.8632 - val_loss: 0.3702 - val_acc: 0.8708\n",
            "Epoch 1035/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3951 - acc: 0.8630 - val_loss: 0.3751 - val_acc: 0.8707\n",
            "Epoch 1036/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3920 - acc: 0.8633 - val_loss: 0.3733 - val_acc: 0.8694\n",
            "Epoch 1037/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3927 - acc: 0.8633 - val_loss: 0.3705 - val_acc: 0.8700\n",
            "Epoch 1038/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3945 - acc: 0.8625 - val_loss: 0.3744 - val_acc: 0.8697\n",
            "Epoch 1039/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3932 - acc: 0.8637 - val_loss: 0.3726 - val_acc: 0.8690\n",
            "Epoch 1040/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3945 - acc: 0.8623 - val_loss: 0.3754 - val_acc: 0.8712\n",
            "Epoch 1041/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3950 - acc: 0.8622 - val_loss: 0.3733 - val_acc: 0.8685\n",
            "Epoch 1042/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3937 - acc: 0.8631 - val_loss: 0.3732 - val_acc: 0.8707\n",
            "Epoch 1043/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3924 - acc: 0.8641 - val_loss: 0.3754 - val_acc: 0.8691\n",
            "Epoch 1044/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3937 - acc: 0.8628 - val_loss: 0.3717 - val_acc: 0.8694\n",
            "Epoch 1045/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8628 - val_loss: 0.3741 - val_acc: 0.8704\n",
            "Epoch 1046/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3925 - acc: 0.8631 - val_loss: 0.3743 - val_acc: 0.8686\n",
            "Epoch 1047/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3938 - acc: 0.8635 - val_loss: 0.3735 - val_acc: 0.8695\n",
            "Epoch 1048/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3964 - acc: 0.8628 - val_loss: 0.3754 - val_acc: 0.8697\n",
            "Epoch 1049/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3969 - acc: 0.8613 - val_loss: 0.3736 - val_acc: 0.8693\n",
            "Epoch 1050/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3929 - acc: 0.8627 - val_loss: 0.3685 - val_acc: 0.8699\n",
            "Epoch 1051/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3934 - acc: 0.8630 - val_loss: 0.3726 - val_acc: 0.8700\n",
            "Epoch 1052/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3951 - acc: 0.8624 - val_loss: 0.3827 - val_acc: 0.8651\n",
            "Epoch 1053/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3925 - acc: 0.8635 - val_loss: 0.3736 - val_acc: 0.8693\n",
            "Epoch 1054/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3934 - acc: 0.8630 - val_loss: 0.3736 - val_acc: 0.8705\n",
            "Epoch 1055/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3933 - acc: 0.8636 - val_loss: 0.3757 - val_acc: 0.8671\n",
            "Epoch 1056/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3931 - acc: 0.8632 - val_loss: 0.3729 - val_acc: 0.8687\n",
            "Epoch 1057/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3940 - acc: 0.8636 - val_loss: 0.3769 - val_acc: 0.8691\n",
            "Epoch 1058/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8640 - val_loss: 0.3766 - val_acc: 0.8680\n",
            "Epoch 1059/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3927 - acc: 0.8630 - val_loss: 0.3784 - val_acc: 0.8680\n",
            "Epoch 1060/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3964 - acc: 0.8624 - val_loss: 0.3723 - val_acc: 0.8701\n",
            "Epoch 1061/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3921 - acc: 0.8631 - val_loss: 0.3751 - val_acc: 0.8691\n",
            "Epoch 1062/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3945 - acc: 0.8636 - val_loss: 0.3736 - val_acc: 0.8712\n",
            "Epoch 1063/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3927 - acc: 0.8637 - val_loss: 0.3765 - val_acc: 0.8707\n",
            "Epoch 1064/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3929 - acc: 0.8634 - val_loss: 0.3693 - val_acc: 0.8721\n",
            "Epoch 1065/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3916 - acc: 0.8630 - val_loss: 0.3805 - val_acc: 0.8669\n",
            "Epoch 1066/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3946 - acc: 0.8629 - val_loss: 0.3763 - val_acc: 0.8669\n",
            "Epoch 1067/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3946 - acc: 0.8625 - val_loss: 0.3738 - val_acc: 0.8697\n",
            "Epoch 1068/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3927 - acc: 0.8633 - val_loss: 0.3797 - val_acc: 0.8703\n",
            "Epoch 1069/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3937 - acc: 0.8630 - val_loss: 0.3717 - val_acc: 0.8697\n",
            "Epoch 1070/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8639 - val_loss: 0.3727 - val_acc: 0.8703\n",
            "Epoch 1071/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3923 - acc: 0.8633 - val_loss: 0.3754 - val_acc: 0.8681\n",
            "Epoch 1072/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3919 - acc: 0.8640 - val_loss: 0.3775 - val_acc: 0.8688\n",
            "Epoch 1073/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3933 - acc: 0.8626 - val_loss: 0.3710 - val_acc: 0.8718\n",
            "Epoch 1074/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3950 - acc: 0.8613 - val_loss: 0.3753 - val_acc: 0.8689\n",
            "Epoch 1075/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3932 - acc: 0.8623 - val_loss: 0.3733 - val_acc: 0.8693\n",
            "Epoch 1076/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3950 - acc: 0.8622 - val_loss: 0.3743 - val_acc: 0.8678\n",
            "Epoch 1077/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3922 - acc: 0.8636 - val_loss: 0.3714 - val_acc: 0.8691\n",
            "Epoch 1078/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3919 - acc: 0.8632 - val_loss: 0.3704 - val_acc: 0.8705\n",
            "Epoch 1079/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3931 - acc: 0.8634 - val_loss: 0.3765 - val_acc: 0.8670\n",
            "Epoch 1080/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3928 - acc: 0.8624 - val_loss: 0.3727 - val_acc: 0.8712\n",
            "Epoch 1081/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3942 - acc: 0.8631 - val_loss: 0.3733 - val_acc: 0.8705\n",
            "Epoch 1082/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3931 - acc: 0.8630 - val_loss: 0.3701 - val_acc: 0.8706\n",
            "Epoch 1083/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3952 - acc: 0.8621 - val_loss: 0.3729 - val_acc: 0.8703\n",
            "Epoch 1084/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3931 - acc: 0.8631 - val_loss: 0.3848 - val_acc: 0.8654\n",
            "Epoch 1085/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3926 - acc: 0.8633 - val_loss: 0.3784 - val_acc: 0.8688\n",
            "Epoch 1086/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3979 - acc: 0.8623 - val_loss: 0.3732 - val_acc: 0.8691\n",
            "Epoch 1087/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3923 - acc: 0.8637 - val_loss: 0.3684 - val_acc: 0.8718\n",
            "Epoch 1088/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3928 - acc: 0.8631 - val_loss: 0.3726 - val_acc: 0.8700\n",
            "Epoch 1089/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3932 - acc: 0.8627 - val_loss: 0.3813 - val_acc: 0.8693\n",
            "Epoch 1090/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3936 - acc: 0.8629 - val_loss: 0.3675 - val_acc: 0.8723\n",
            "Epoch 1091/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3926 - acc: 0.8638 - val_loss: 0.3716 - val_acc: 0.8700\n",
            "Epoch 1092/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3928 - acc: 0.8632 - val_loss: 0.3743 - val_acc: 0.8697\n",
            "Epoch 1093/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3923 - acc: 0.8630 - val_loss: 0.3715 - val_acc: 0.8700\n",
            "Epoch 1094/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3913 - acc: 0.8641 - val_loss: 0.3704 - val_acc: 0.8710\n",
            "Epoch 1095/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3920 - acc: 0.8636 - val_loss: 0.3762 - val_acc: 0.8691\n",
            "Epoch 1096/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3918 - acc: 0.8633 - val_loss: 0.3785 - val_acc: 0.8697\n",
            "Epoch 1097/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3936 - acc: 0.8630 - val_loss: 0.3739 - val_acc: 0.8685\n",
            "Epoch 1098/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3950 - acc: 0.8625 - val_loss: 0.3710 - val_acc: 0.8703\n",
            "Epoch 1099/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3950 - acc: 0.8627 - val_loss: 0.3728 - val_acc: 0.8701\n",
            "Epoch 1100/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3932 - acc: 0.8633 - val_loss: 0.3768 - val_acc: 0.8669\n",
            "Epoch 1101/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3947 - acc: 0.8632 - val_loss: 0.3737 - val_acc: 0.8715\n",
            "Epoch 1102/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3924 - acc: 0.8631 - val_loss: 0.3757 - val_acc: 0.8680\n",
            "Epoch 1103/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3912 - acc: 0.8639 - val_loss: 0.3808 - val_acc: 0.8677\n",
            "Epoch 1104/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3930 - acc: 0.8628 - val_loss: 0.3719 - val_acc: 0.8693\n",
            "Epoch 1105/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3925 - acc: 0.8636 - val_loss: 0.3725 - val_acc: 0.8711\n",
            "Epoch 1106/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3927 - acc: 0.8635 - val_loss: 0.3734 - val_acc: 0.8696\n",
            "Epoch 1107/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3931 - acc: 0.8628 - val_loss: 0.3718 - val_acc: 0.8705\n",
            "Epoch 1108/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3931 - acc: 0.8626 - val_loss: 0.3715 - val_acc: 0.8705\n",
            "Epoch 1109/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3916 - acc: 0.8637 - val_loss: 0.3745 - val_acc: 0.8693\n",
            "Epoch 1110/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3917 - acc: 0.8632 - val_loss: 0.3729 - val_acc: 0.8703\n",
            "Epoch 1111/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3908 - acc: 0.8644 - val_loss: 0.3822 - val_acc: 0.8657\n",
            "Epoch 1112/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3941 - acc: 0.8636 - val_loss: 0.3794 - val_acc: 0.8678\n",
            "Epoch 1113/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3920 - acc: 0.8635 - val_loss: 0.3766 - val_acc: 0.8683\n",
            "Epoch 1114/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3930 - acc: 0.8632 - val_loss: 0.3734 - val_acc: 0.8699\n",
            "Epoch 1115/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3920 - acc: 0.8637 - val_loss: 0.3712 - val_acc: 0.8726\n",
            "Epoch 1116/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3914 - acc: 0.8634 - val_loss: 0.3746 - val_acc: 0.8682\n",
            "Epoch 1117/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3927 - acc: 0.8632 - val_loss: 0.3716 - val_acc: 0.8697\n",
            "Epoch 1118/5000\n",
            "179991/179991 [==============================] - 10s 54us/step - loss: 0.3923 - acc: 0.8635 - val_loss: 0.3715 - val_acc: 0.8688\n",
            "Epoch 1119/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3917 - acc: 0.8644 - val_loss: 0.3723 - val_acc: 0.8712\n",
            "Epoch 1120/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3929 - acc: 0.8639 - val_loss: 0.3758 - val_acc: 0.8679\n",
            "Epoch 1121/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3921 - acc: 0.8631 - val_loss: 0.3764 - val_acc: 0.8682\n",
            "Epoch 1122/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3935 - acc: 0.8638 - val_loss: 0.3739 - val_acc: 0.8686\n",
            "Epoch 1123/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3934 - acc: 0.8626 - val_loss: 0.3827 - val_acc: 0.8673\n",
            "Epoch 1124/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3928 - acc: 0.8634 - val_loss: 0.3754 - val_acc: 0.8701\n",
            "Epoch 1125/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3915 - acc: 0.8637 - val_loss: 0.3720 - val_acc: 0.8709\n",
            "Epoch 1126/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3932 - acc: 0.8632 - val_loss: 0.3726 - val_acc: 0.8678\n",
            "Epoch 1127/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3926 - acc: 0.8631 - val_loss: 0.3702 - val_acc: 0.8693\n",
            "Epoch 1128/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3935 - acc: 0.8631 - val_loss: 0.3729 - val_acc: 0.8683\n",
            "Epoch 1129/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3939 - acc: 0.8632 - val_loss: 0.3748 - val_acc: 0.8670\n",
            "Epoch 1130/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3911 - acc: 0.8636 - val_loss: 0.3739 - val_acc: 0.8701\n",
            "Epoch 1131/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3915 - acc: 0.8629 - val_loss: 0.3719 - val_acc: 0.8701\n",
            "Epoch 1132/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3926 - acc: 0.8631 - val_loss: 0.3757 - val_acc: 0.8689\n",
            "Epoch 1133/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3925 - acc: 0.8633 - val_loss: 0.3794 - val_acc: 0.8674\n",
            "Epoch 1134/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3926 - acc: 0.8634 - val_loss: 0.3708 - val_acc: 0.8709\n",
            "Epoch 1135/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3927 - acc: 0.8639 - val_loss: 0.3792 - val_acc: 0.8672\n",
            "Epoch 1136/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3924 - acc: 0.8625 - val_loss: 0.3710 - val_acc: 0.8694\n",
            "Epoch 1137/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3935 - acc: 0.8623 - val_loss: 0.3766 - val_acc: 0.8670\n",
            "Epoch 1138/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3926 - acc: 0.8634 - val_loss: 0.3720 - val_acc: 0.8690\n",
            "Epoch 1139/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3921 - acc: 0.8643 - val_loss: 0.3720 - val_acc: 0.8709\n",
            "Epoch 1140/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3930 - acc: 0.8628 - val_loss: 0.3741 - val_acc: 0.8676\n",
            "Epoch 1141/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3920 - acc: 0.8632 - val_loss: 0.3777 - val_acc: 0.8692\n",
            "Epoch 1142/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3916 - acc: 0.8634 - val_loss: 0.3770 - val_acc: 0.8661\n",
            "Epoch 1143/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3921 - acc: 0.8633 - val_loss: 0.3754 - val_acc: 0.8683\n",
            "Epoch 1144/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3929 - acc: 0.8631 - val_loss: 0.3833 - val_acc: 0.8679\n",
            "Epoch 1145/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3921 - acc: 0.8643 - val_loss: 0.3718 - val_acc: 0.8691\n",
            "Epoch 1146/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3933 - acc: 0.8629 - val_loss: 0.3757 - val_acc: 0.8667\n",
            "Epoch 1147/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3954 - acc: 0.8624 - val_loss: 0.3747 - val_acc: 0.8690\n",
            "Epoch 1148/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3934 - acc: 0.8636 - val_loss: 0.3733 - val_acc: 0.8684\n",
            "Epoch 1149/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3927 - acc: 0.8628 - val_loss: 0.3715 - val_acc: 0.8716\n",
            "Epoch 1150/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8641 - val_loss: 0.3698 - val_acc: 0.8675\n",
            "Epoch 1151/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8640 - val_loss: 0.3762 - val_acc: 0.8681\n",
            "Epoch 1152/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3935 - acc: 0.8631 - val_loss: 0.3724 - val_acc: 0.8688\n",
            "Epoch 1153/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3933 - acc: 0.8634 - val_loss: 0.3746 - val_acc: 0.8672\n",
            "Epoch 1154/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8636 - val_loss: 0.3723 - val_acc: 0.8708\n",
            "Epoch 1155/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3921 - acc: 0.8633 - val_loss: 0.3749 - val_acc: 0.8683\n",
            "Epoch 1156/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3940 - acc: 0.8623 - val_loss: 0.3772 - val_acc: 0.8684\n",
            "Epoch 1157/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3926 - acc: 0.8640 - val_loss: 0.3702 - val_acc: 0.8715\n",
            "Epoch 1158/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8638 - val_loss: 0.3778 - val_acc: 0.8670\n",
            "Epoch 1159/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3922 - acc: 0.8635 - val_loss: 0.3740 - val_acc: 0.8693\n",
            "Epoch 1160/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3928 - acc: 0.8636 - val_loss: 0.3728 - val_acc: 0.8685\n",
            "Epoch 1161/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3919 - acc: 0.8633 - val_loss: 0.3702 - val_acc: 0.8728\n",
            "Epoch 1162/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8635 - val_loss: 0.3703 - val_acc: 0.8697\n",
            "Epoch 1163/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3923 - acc: 0.8629 - val_loss: 0.3720 - val_acc: 0.8708\n",
            "Epoch 1164/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3929 - acc: 0.8629 - val_loss: 0.3753 - val_acc: 0.8700\n",
            "Epoch 1165/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8634 - val_loss: 0.3714 - val_acc: 0.8701\n",
            "Epoch 1166/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3922 - acc: 0.8639 - val_loss: 0.3727 - val_acc: 0.8701\n",
            "Epoch 1167/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3921 - acc: 0.8632 - val_loss: 0.3713 - val_acc: 0.8699\n",
            "Epoch 1168/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3933 - acc: 0.8631 - val_loss: 0.3736 - val_acc: 0.8689\n",
            "Epoch 1169/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3921 - acc: 0.8636 - val_loss: 0.3709 - val_acc: 0.8708\n",
            "Epoch 1170/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3919 - acc: 0.8630 - val_loss: 0.3766 - val_acc: 0.8663\n",
            "Epoch 1171/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3910 - acc: 0.8639 - val_loss: 0.3864 - val_acc: 0.8632\n",
            "Epoch 1172/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3930 - acc: 0.8638 - val_loss: 0.3711 - val_acc: 0.8703\n",
            "Epoch 1173/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3942 - acc: 0.8626 - val_loss: 0.3758 - val_acc: 0.8678\n",
            "Epoch 1174/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3917 - acc: 0.8637 - val_loss: 0.3708 - val_acc: 0.8706\n",
            "Epoch 1175/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3933 - acc: 0.8638 - val_loss: 0.3735 - val_acc: 0.8701\n",
            "Epoch 1176/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3939 - acc: 0.8631 - val_loss: 0.3724 - val_acc: 0.8694\n",
            "Epoch 1177/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3899 - acc: 0.8644 - val_loss: 0.3736 - val_acc: 0.8674\n",
            "Epoch 1178/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3903 - acc: 0.8645 - val_loss: 0.3739 - val_acc: 0.8682\n",
            "Epoch 1179/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3921 - acc: 0.8638 - val_loss: 0.3749 - val_acc: 0.8686\n",
            "Epoch 1180/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3931 - acc: 0.8621 - val_loss: 0.3720 - val_acc: 0.8729\n",
            "Epoch 1181/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3937 - acc: 0.8636 - val_loss: 0.3723 - val_acc: 0.8699\n",
            "Epoch 1182/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3947 - acc: 0.8630 - val_loss: 0.3752 - val_acc: 0.8694\n",
            "Epoch 1183/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3900 - acc: 0.8645 - val_loss: 0.3735 - val_acc: 0.8706\n",
            "Epoch 1184/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3925 - acc: 0.8628 - val_loss: 0.3726 - val_acc: 0.8717\n",
            "Epoch 1185/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8640 - val_loss: 0.3709 - val_acc: 0.8709\n",
            "Epoch 1186/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8631 - val_loss: 0.3726 - val_acc: 0.8697\n",
            "Epoch 1187/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3919 - acc: 0.8631 - val_loss: 0.3725 - val_acc: 0.8711\n",
            "Epoch 1188/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8631 - val_loss: 0.3710 - val_acc: 0.8716\n",
            "Epoch 1189/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3934 - acc: 0.8634 - val_loss: 0.3753 - val_acc: 0.8695\n",
            "Epoch 1190/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3907 - acc: 0.8638 - val_loss: 0.3712 - val_acc: 0.8712\n",
            "Epoch 1191/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3936 - acc: 0.8638 - val_loss: 0.3725 - val_acc: 0.8715\n",
            "Epoch 1192/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3911 - acc: 0.8643 - val_loss: 0.3715 - val_acc: 0.8697\n",
            "Epoch 1193/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3911 - acc: 0.8636 - val_loss: 0.3739 - val_acc: 0.8681\n",
            "Epoch 1194/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3921 - acc: 0.8640 - val_loss: 0.3735 - val_acc: 0.8675\n",
            "Epoch 1195/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3935 - acc: 0.8626 - val_loss: 0.3846 - val_acc: 0.8674\n",
            "Epoch 1196/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3918 - acc: 0.8639 - val_loss: 0.3723 - val_acc: 0.8707\n",
            "Epoch 1197/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3918 - acc: 0.8631 - val_loss: 0.3779 - val_acc: 0.8690\n",
            "Epoch 1198/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3900 - acc: 0.8639 - val_loss: 0.3745 - val_acc: 0.8690\n",
            "Epoch 1199/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3925 - acc: 0.8633 - val_loss: 0.3727 - val_acc: 0.8703\n",
            "Epoch 1200/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3921 - acc: 0.8633 - val_loss: 0.3732 - val_acc: 0.8709\n",
            "Epoch 1201/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3914 - acc: 0.8639 - val_loss: 0.3684 - val_acc: 0.8733\n",
            "Epoch 1202/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3913 - acc: 0.8637 - val_loss: 0.3756 - val_acc: 0.8657\n",
            "Epoch 1203/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3901 - acc: 0.8639 - val_loss: 0.3868 - val_acc: 0.8638\n",
            "Epoch 1204/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3914 - acc: 0.8641 - val_loss: 0.3703 - val_acc: 0.8697\n",
            "Epoch 1205/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8640 - val_loss: 0.3712 - val_acc: 0.8713\n",
            "Epoch 1206/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3921 - acc: 0.8629 - val_loss: 0.3803 - val_acc: 0.8690\n",
            "Epoch 1207/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3922 - acc: 0.8627 - val_loss: 0.3721 - val_acc: 0.8712\n",
            "Epoch 1208/5000\n",
            "179991/179991 [==============================] - 10s 54us/step - loss: 0.3914 - acc: 0.8636 - val_loss: 0.3760 - val_acc: 0.8718\n",
            "Epoch 1209/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3942 - acc: 0.8628 - val_loss: 0.3773 - val_acc: 0.8688\n",
            "Epoch 1210/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3934 - acc: 0.8634 - val_loss: 0.3726 - val_acc: 0.8693\n",
            "Epoch 1211/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3904 - acc: 0.8633 - val_loss: 0.3753 - val_acc: 0.8668\n",
            "Epoch 1212/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3916 - acc: 0.8634 - val_loss: 0.3704 - val_acc: 0.8709\n",
            "Epoch 1213/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8634 - val_loss: 0.3705 - val_acc: 0.8720\n",
            "Epoch 1214/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3902 - acc: 0.8639 - val_loss: 0.3737 - val_acc: 0.8692\n",
            "Epoch 1215/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3939 - acc: 0.8637 - val_loss: 0.3725 - val_acc: 0.8679\n",
            "Epoch 1216/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3913 - acc: 0.8630 - val_loss: 0.3739 - val_acc: 0.8708\n",
            "Epoch 1217/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3907 - acc: 0.8636 - val_loss: 0.3780 - val_acc: 0.8672\n",
            "Epoch 1218/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3914 - acc: 0.8635 - val_loss: 0.3760 - val_acc: 0.8700\n",
            "Epoch 1219/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3925 - acc: 0.8637 - val_loss: 0.3751 - val_acc: 0.8682\n",
            "Epoch 1220/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8630 - val_loss: 0.3721 - val_acc: 0.8699\n",
            "Epoch 1221/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3922 - acc: 0.8632 - val_loss: 0.3743 - val_acc: 0.8682\n",
            "Epoch 1222/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3911 - acc: 0.8628 - val_loss: 0.3782 - val_acc: 0.8683\n",
            "Epoch 1223/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3907 - acc: 0.8634 - val_loss: 0.3859 - val_acc: 0.8627\n",
            "Epoch 1224/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3908 - acc: 0.8641 - val_loss: 0.3740 - val_acc: 0.8697\n",
            "Epoch 1225/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3917 - acc: 0.8641 - val_loss: 0.3698 - val_acc: 0.8720\n",
            "Epoch 1226/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3909 - acc: 0.8646 - val_loss: 0.3771 - val_acc: 0.8690\n",
            "Epoch 1227/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3907 - acc: 0.8642 - val_loss: 0.3691 - val_acc: 0.8730\n",
            "Epoch 1228/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3910 - acc: 0.8641 - val_loss: 0.3707 - val_acc: 0.8717\n",
            "Epoch 1229/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3919 - acc: 0.8633 - val_loss: 0.3738 - val_acc: 0.8692\n",
            "Epoch 1230/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8640 - val_loss: 0.3711 - val_acc: 0.8720\n",
            "Epoch 1231/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8636 - val_loss: 0.3768 - val_acc: 0.8665\n",
            "Epoch 1232/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8643 - val_loss: 0.3758 - val_acc: 0.8698\n",
            "Epoch 1233/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3927 - acc: 0.8639 - val_loss: 0.3734 - val_acc: 0.8716\n",
            "Epoch 1234/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3932 - acc: 0.8640 - val_loss: 0.3748 - val_acc: 0.8706\n",
            "Epoch 1235/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8636 - val_loss: 0.3720 - val_acc: 0.8693\n",
            "Epoch 1236/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3904 - acc: 0.8639 - val_loss: 0.3709 - val_acc: 0.8712\n",
            "Epoch 1237/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3918 - acc: 0.8630 - val_loss: 0.3722 - val_acc: 0.8696\n",
            "Epoch 1238/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3923 - acc: 0.8631 - val_loss: 0.3761 - val_acc: 0.8691\n",
            "Epoch 1239/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3926 - acc: 0.8629 - val_loss: 0.3800 - val_acc: 0.8685\n",
            "Epoch 1240/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3925 - acc: 0.8637 - val_loss: 0.3767 - val_acc: 0.8696\n",
            "Epoch 1241/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3949 - acc: 0.8621 - val_loss: 0.3764 - val_acc: 0.8688\n",
            "Epoch 1242/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3911 - acc: 0.8634 - val_loss: 0.3788 - val_acc: 0.8683\n",
            "Epoch 1243/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3911 - acc: 0.8633 - val_loss: 0.3952 - val_acc: 0.8597\n",
            "Epoch 1244/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3916 - acc: 0.8630 - val_loss: 0.3755 - val_acc: 0.8689\n",
            "Epoch 1245/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3917 - acc: 0.8634 - val_loss: 0.3783 - val_acc: 0.8698\n",
            "Epoch 1246/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3906 - acc: 0.8640 - val_loss: 0.3725 - val_acc: 0.8706\n",
            "Epoch 1247/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3904 - acc: 0.8635 - val_loss: 0.3780 - val_acc: 0.8671\n",
            "Epoch 1248/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3919 - acc: 0.8637 - val_loss: 0.3772 - val_acc: 0.8677\n",
            "Epoch 1249/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8631 - val_loss: 0.3720 - val_acc: 0.8694\n",
            "Epoch 1250/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3918 - acc: 0.8641 - val_loss: 0.3777 - val_acc: 0.8693\n",
            "Epoch 1251/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3920 - acc: 0.8631 - val_loss: 0.3770 - val_acc: 0.8695\n",
            "Epoch 1252/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3930 - acc: 0.8626 - val_loss: 0.3781 - val_acc: 0.8688\n",
            "Epoch 1253/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8639 - val_loss: 0.3721 - val_acc: 0.8719\n",
            "Epoch 1254/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3918 - acc: 0.8637 - val_loss: 0.3729 - val_acc: 0.8701\n",
            "Epoch 1255/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3920 - acc: 0.8630 - val_loss: 0.3713 - val_acc: 0.8705\n",
            "Epoch 1256/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3933 - acc: 0.8627 - val_loss: 0.3737 - val_acc: 0.8713\n",
            "Epoch 1257/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3897 - acc: 0.8640 - val_loss: 0.3701 - val_acc: 0.8700\n",
            "Epoch 1258/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3912 - acc: 0.8633 - val_loss: 0.3712 - val_acc: 0.8720\n",
            "Epoch 1259/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8640 - val_loss: 0.3681 - val_acc: 0.8733\n",
            "Epoch 1260/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3907 - acc: 0.8644 - val_loss: 0.3725 - val_acc: 0.8716\n",
            "Epoch 1261/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3914 - acc: 0.8635 - val_loss: 0.3732 - val_acc: 0.8696\n",
            "Epoch 1262/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3911 - acc: 0.8632 - val_loss: 0.3691 - val_acc: 0.8716\n",
            "Epoch 1263/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3931 - acc: 0.8630 - val_loss: 0.3745 - val_acc: 0.8701\n",
            "Epoch 1264/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3922 - acc: 0.8636 - val_loss: 0.3746 - val_acc: 0.8685\n",
            "Epoch 1265/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3921 - acc: 0.8635 - val_loss: 0.3725 - val_acc: 0.8703\n",
            "Epoch 1266/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3904 - acc: 0.8635 - val_loss: 0.3721 - val_acc: 0.8699\n",
            "Epoch 1267/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8646 - val_loss: 0.3776 - val_acc: 0.8678\n",
            "Epoch 1268/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3919 - acc: 0.8636 - val_loss: 0.3777 - val_acc: 0.8685\n",
            "Epoch 1269/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3926 - acc: 0.8631 - val_loss: 0.3724 - val_acc: 0.8712\n",
            "Epoch 1270/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3921 - acc: 0.8630 - val_loss: 0.3706 - val_acc: 0.8697\n",
            "Epoch 1271/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3914 - acc: 0.8641 - val_loss: 0.3769 - val_acc: 0.8683\n",
            "Epoch 1272/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3918 - acc: 0.8630 - val_loss: 0.3745 - val_acc: 0.8700\n",
            "Epoch 1273/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3922 - acc: 0.8632 - val_loss: 0.3743 - val_acc: 0.8693\n",
            "Epoch 1274/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3923 - acc: 0.8635 - val_loss: 0.3752 - val_acc: 0.8677\n",
            "Epoch 1275/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3923 - acc: 0.8631 - val_loss: 0.3734 - val_acc: 0.8703\n",
            "Epoch 1276/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3924 - acc: 0.8639 - val_loss: 0.3751 - val_acc: 0.8681\n",
            "Epoch 1277/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3922 - acc: 0.8642 - val_loss: 0.3738 - val_acc: 0.8679\n",
            "Epoch 1278/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3918 - acc: 0.8641 - val_loss: 0.3764 - val_acc: 0.8694\n",
            "Epoch 1279/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3914 - acc: 0.8639 - val_loss: 0.3756 - val_acc: 0.8693\n",
            "Epoch 1280/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3904 - acc: 0.8640 - val_loss: 0.3709 - val_acc: 0.8713\n",
            "Epoch 1281/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3908 - acc: 0.8632 - val_loss: 0.3727 - val_acc: 0.8707\n",
            "Epoch 1282/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3918 - acc: 0.8641 - val_loss: 0.3722 - val_acc: 0.8701\n",
            "Epoch 1283/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3923 - acc: 0.8633 - val_loss: 0.3789 - val_acc: 0.8675\n",
            "Epoch 1284/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8639 - val_loss: 0.3739 - val_acc: 0.8700\n",
            "Epoch 1285/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3916 - acc: 0.8632 - val_loss: 0.3772 - val_acc: 0.8700\n",
            "Epoch 1286/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3902 - acc: 0.8643 - val_loss: 0.3767 - val_acc: 0.8688\n",
            "Epoch 1287/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3919 - acc: 0.8635 - val_loss: 0.3708 - val_acc: 0.8728\n",
            "Epoch 1288/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3919 - acc: 0.8633 - val_loss: 0.3774 - val_acc: 0.8679\n",
            "Epoch 1289/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3918 - acc: 0.8634 - val_loss: 0.3715 - val_acc: 0.8720\n",
            "Epoch 1290/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3914 - acc: 0.8638 - val_loss: 0.3722 - val_acc: 0.8713\n",
            "Epoch 1291/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3915 - acc: 0.8633 - val_loss: 0.3803 - val_acc: 0.8683\n",
            "Epoch 1292/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8643 - val_loss: 0.3700 - val_acc: 0.8725\n",
            "Epoch 1293/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3922 - acc: 0.8641 - val_loss: 0.3775 - val_acc: 0.8681\n",
            "Epoch 1294/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3896 - acc: 0.8642 - val_loss: 0.3713 - val_acc: 0.8709\n",
            "Epoch 1295/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3899 - acc: 0.8645 - val_loss: 0.3720 - val_acc: 0.8715\n",
            "Epoch 1296/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3925 - acc: 0.8627 - val_loss: 0.3769 - val_acc: 0.8693\n",
            "Epoch 1297/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3902 - acc: 0.8637 - val_loss: 0.3703 - val_acc: 0.8710\n",
            "Epoch 1298/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3925 - acc: 0.8640 - val_loss: 0.3741 - val_acc: 0.8672\n",
            "Epoch 1299/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3904 - acc: 0.8642 - val_loss: 0.3708 - val_acc: 0.8705\n",
            "Epoch 1300/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8644 - val_loss: 0.3771 - val_acc: 0.8683\n",
            "Epoch 1301/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3914 - acc: 0.8642 - val_loss: 0.3737 - val_acc: 0.8691\n",
            "Epoch 1302/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3902 - acc: 0.8642 - val_loss: 0.3684 - val_acc: 0.8722\n",
            "Epoch 1303/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3911 - acc: 0.8636 - val_loss: 0.3712 - val_acc: 0.8713\n",
            "Epoch 1304/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3898 - acc: 0.8639 - val_loss: 0.3736 - val_acc: 0.8701\n",
            "Epoch 1305/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3930 - acc: 0.8636 - val_loss: 0.3765 - val_acc: 0.8676\n",
            "Epoch 1306/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3902 - acc: 0.8638 - val_loss: 0.3802 - val_acc: 0.8670\n",
            "Epoch 1307/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3906 - acc: 0.8634 - val_loss: 0.3729 - val_acc: 0.8700\n",
            "Epoch 1308/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8635 - val_loss: 0.3679 - val_acc: 0.8713\n",
            "Epoch 1309/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8644 - val_loss: 0.3720 - val_acc: 0.8710\n",
            "Epoch 1310/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3905 - acc: 0.8644 - val_loss: 0.3726 - val_acc: 0.8697\n",
            "Epoch 1311/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3897 - acc: 0.8640 - val_loss: 0.3743 - val_acc: 0.8699\n",
            "Epoch 1312/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3926 - acc: 0.8637 - val_loss: 0.3796 - val_acc: 0.8668\n",
            "Epoch 1313/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3913 - acc: 0.8636 - val_loss: 0.3757 - val_acc: 0.8684\n",
            "Epoch 1314/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8645 - val_loss: 0.3716 - val_acc: 0.8698\n",
            "Epoch 1315/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3915 - acc: 0.8629 - val_loss: 0.3743 - val_acc: 0.8688\n",
            "Epoch 1316/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3881 - acc: 0.8644 - val_loss: 0.3694 - val_acc: 0.8722\n",
            "Epoch 1317/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8641 - val_loss: 0.3776 - val_acc: 0.8649\n",
            "Epoch 1318/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3898 - acc: 0.8642 - val_loss: 0.3717 - val_acc: 0.8712\n",
            "Epoch 1319/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3919 - acc: 0.8643 - val_loss: 0.3735 - val_acc: 0.8688\n",
            "Epoch 1320/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3909 - acc: 0.8649 - val_loss: 0.3742 - val_acc: 0.8690\n",
            "Epoch 1321/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3908 - acc: 0.8642 - val_loss: 0.3734 - val_acc: 0.8700\n",
            "Epoch 1322/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3937 - acc: 0.8633 - val_loss: 0.3798 - val_acc: 0.8679\n",
            "Epoch 1323/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3909 - acc: 0.8634 - val_loss: 0.3750 - val_acc: 0.8676\n",
            "Epoch 1324/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3898 - acc: 0.8637 - val_loss: 0.3748 - val_acc: 0.8693\n",
            "Epoch 1325/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8644 - val_loss: 0.3712 - val_acc: 0.8719\n",
            "Epoch 1326/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3930 - acc: 0.8633 - val_loss: 0.3773 - val_acc: 0.8672\n",
            "Epoch 1327/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3909 - acc: 0.8642 - val_loss: 0.3745 - val_acc: 0.8708\n",
            "Epoch 1328/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3912 - acc: 0.8641 - val_loss: 0.3745 - val_acc: 0.8693\n",
            "Epoch 1329/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3915 - acc: 0.8637 - val_loss: 0.3716 - val_acc: 0.8683\n",
            "Epoch 1330/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3914 - acc: 0.8634 - val_loss: 0.3725 - val_acc: 0.8703\n",
            "Epoch 1331/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3906 - acc: 0.8644 - val_loss: 0.3750 - val_acc: 0.8693\n",
            "Epoch 1332/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3923 - acc: 0.8627 - val_loss: 0.3719 - val_acc: 0.8711\n",
            "Epoch 1333/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3912 - acc: 0.8633 - val_loss: 0.3722 - val_acc: 0.8712\n",
            "Epoch 1334/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3904 - acc: 0.8628 - val_loss: 0.3732 - val_acc: 0.8718\n",
            "Epoch 1335/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3904 - acc: 0.8647 - val_loss: 0.3752 - val_acc: 0.8673\n",
            "Epoch 1336/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3916 - acc: 0.8633 - val_loss: 0.3730 - val_acc: 0.8690\n",
            "Epoch 1337/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3917 - acc: 0.8630 - val_loss: 0.3701 - val_acc: 0.8708\n",
            "Epoch 1338/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3891 - acc: 0.8643 - val_loss: 0.3742 - val_acc: 0.8703\n",
            "Epoch 1339/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3907 - acc: 0.8646 - val_loss: 0.3686 - val_acc: 0.8705\n",
            "Epoch 1340/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3899 - acc: 0.8641 - val_loss: 0.3730 - val_acc: 0.8721\n",
            "Epoch 1341/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8649 - val_loss: 0.3734 - val_acc: 0.8701\n",
            "Epoch 1342/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8631 - val_loss: 0.3680 - val_acc: 0.8732\n",
            "Epoch 1343/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3893 - acc: 0.8644 - val_loss: 0.3690 - val_acc: 0.8712\n",
            "Epoch 1344/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3926 - acc: 0.8640 - val_loss: 0.3753 - val_acc: 0.8690\n",
            "Epoch 1345/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3885 - acc: 0.8645 - val_loss: 0.3788 - val_acc: 0.8700\n",
            "Epoch 1346/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8643 - val_loss: 0.3700 - val_acc: 0.8712\n",
            "Epoch 1347/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8644 - val_loss: 0.3710 - val_acc: 0.8725\n",
            "Epoch 1348/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8637 - val_loss: 0.3781 - val_acc: 0.8694\n",
            "Epoch 1349/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3899 - acc: 0.8640 - val_loss: 0.3772 - val_acc: 0.8675\n",
            "Epoch 1350/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3909 - acc: 0.8642 - val_loss: 0.3746 - val_acc: 0.8697\n",
            "Epoch 1351/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3907 - acc: 0.8638 - val_loss: 0.3726 - val_acc: 0.8714\n",
            "Epoch 1352/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8637 - val_loss: 0.3704 - val_acc: 0.8720\n",
            "Epoch 1353/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8640 - val_loss: 0.3709 - val_acc: 0.8694\n",
            "Epoch 1354/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3920 - acc: 0.8633 - val_loss: 0.3718 - val_acc: 0.8710\n",
            "Epoch 1355/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3894 - acc: 0.8648 - val_loss: 0.3738 - val_acc: 0.8694\n",
            "Epoch 1356/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3899 - acc: 0.8645 - val_loss: 0.3779 - val_acc: 0.8696\n",
            "Epoch 1357/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8640 - val_loss: 0.3724 - val_acc: 0.8695\n",
            "Epoch 1358/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3907 - acc: 0.8641 - val_loss: 0.3725 - val_acc: 0.8694\n",
            "Epoch 1359/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3920 - acc: 0.8631 - val_loss: 0.3737 - val_acc: 0.8713\n",
            "Epoch 1360/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3923 - acc: 0.8630 - val_loss: 0.3742 - val_acc: 0.8697\n",
            "Epoch 1361/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3897 - acc: 0.8645 - val_loss: 0.3718 - val_acc: 0.8706\n",
            "Epoch 1362/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3901 - acc: 0.8643 - val_loss: 0.3723 - val_acc: 0.8707\n",
            "Epoch 1363/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3902 - acc: 0.8642 - val_loss: 0.3761 - val_acc: 0.8686\n",
            "Epoch 1364/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3929 - acc: 0.8628 - val_loss: 0.3697 - val_acc: 0.8724\n",
            "Epoch 1365/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3909 - acc: 0.8646 - val_loss: 0.3751 - val_acc: 0.8687\n",
            "Epoch 1366/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8651 - val_loss: 0.3730 - val_acc: 0.8715\n",
            "Epoch 1367/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8630 - val_loss: 0.3740 - val_acc: 0.8685\n",
            "Epoch 1368/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3888 - acc: 0.8641 - val_loss: 0.3723 - val_acc: 0.8696\n",
            "Epoch 1369/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3901 - acc: 0.8644 - val_loss: 0.3707 - val_acc: 0.8713\n",
            "Epoch 1370/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3931 - acc: 0.8634 - val_loss: 0.3753 - val_acc: 0.8708\n",
            "Epoch 1371/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3897 - acc: 0.8638 - val_loss: 0.3719 - val_acc: 0.8712\n",
            "Epoch 1372/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3889 - acc: 0.8646 - val_loss: 0.3739 - val_acc: 0.8713\n",
            "Epoch 1373/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3909 - acc: 0.8645 - val_loss: 0.3733 - val_acc: 0.8690\n",
            "Epoch 1374/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3915 - acc: 0.8642 - val_loss: 0.3691 - val_acc: 0.8713\n",
            "Epoch 1375/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3899 - acc: 0.8644 - val_loss: 0.3761 - val_acc: 0.8685\n",
            "Epoch 1376/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3919 - acc: 0.8639 - val_loss: 0.3682 - val_acc: 0.8716\n",
            "Epoch 1377/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3900 - acc: 0.8637 - val_loss: 0.3779 - val_acc: 0.8688\n",
            "Epoch 1378/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3905 - acc: 0.8642 - val_loss: 0.3720 - val_acc: 0.8694\n",
            "Epoch 1379/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8641 - val_loss: 0.3790 - val_acc: 0.8698\n",
            "Epoch 1380/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3910 - acc: 0.8633 - val_loss: 0.3719 - val_acc: 0.8713\n",
            "Epoch 1381/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3898 - acc: 0.8647 - val_loss: 0.3734 - val_acc: 0.8730\n",
            "Epoch 1382/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8641 - val_loss: 0.3791 - val_acc: 0.8658\n",
            "Epoch 1383/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8632 - val_loss: 0.3711 - val_acc: 0.8718\n",
            "Epoch 1384/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3913 - acc: 0.8631 - val_loss: 0.3725 - val_acc: 0.8700\n",
            "Epoch 1385/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8644 - val_loss: 0.3709 - val_acc: 0.8709\n",
            "Epoch 1386/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3903 - acc: 0.8640 - val_loss: 0.3727 - val_acc: 0.8727\n",
            "Epoch 1387/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3896 - acc: 0.8641 - val_loss: 0.3753 - val_acc: 0.8679\n",
            "Epoch 1388/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8640 - val_loss: 0.3738 - val_acc: 0.8703\n",
            "Epoch 1389/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3896 - acc: 0.8631 - val_loss: 0.3733 - val_acc: 0.8719\n",
            "Epoch 1390/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8641 - val_loss: 0.3726 - val_acc: 0.8701\n",
            "Epoch 1391/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3892 - acc: 0.8647 - val_loss: 0.3763 - val_acc: 0.8684\n",
            "Epoch 1392/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3898 - acc: 0.8647 - val_loss: 0.3789 - val_acc: 0.8668\n",
            "Epoch 1393/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3911 - acc: 0.8638 - val_loss: 0.3752 - val_acc: 0.8674\n",
            "Epoch 1394/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3900 - acc: 0.8639 - val_loss: 0.3858 - val_acc: 0.8648\n",
            "Epoch 1395/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3911 - acc: 0.8637 - val_loss: 0.3730 - val_acc: 0.8705\n",
            "Epoch 1396/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3892 - acc: 0.8643 - val_loss: 0.3788 - val_acc: 0.8681\n",
            "Epoch 1397/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3916 - acc: 0.8633 - val_loss: 0.3744 - val_acc: 0.8679\n",
            "Epoch 1398/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3904 - acc: 0.8636 - val_loss: 0.3792 - val_acc: 0.8690\n",
            "Epoch 1399/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3903 - acc: 0.8639 - val_loss: 0.3721 - val_acc: 0.8703\n",
            "Epoch 1400/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3911 - acc: 0.8630 - val_loss: 0.3725 - val_acc: 0.8674\n",
            "Epoch 1401/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3897 - acc: 0.8638 - val_loss: 0.3721 - val_acc: 0.8729\n",
            "Epoch 1402/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3897 - acc: 0.8643 - val_loss: 0.3751 - val_acc: 0.8685\n",
            "Epoch 1403/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8631 - val_loss: 0.3717 - val_acc: 0.8703\n",
            "Epoch 1404/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8631 - val_loss: 0.3783 - val_acc: 0.8688\n",
            "Epoch 1405/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3929 - acc: 0.8631 - val_loss: 0.3721 - val_acc: 0.8710\n",
            "Epoch 1406/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3907 - acc: 0.8639 - val_loss: 0.3743 - val_acc: 0.8683\n",
            "Epoch 1407/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3902 - acc: 0.8636 - val_loss: 0.3710 - val_acc: 0.8709\n",
            "Epoch 1408/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3914 - acc: 0.8635 - val_loss: 0.3754 - val_acc: 0.8700\n",
            "Epoch 1409/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3900 - acc: 0.8633 - val_loss: 0.3711 - val_acc: 0.8694\n",
            "Epoch 1410/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3901 - acc: 0.8643 - val_loss: 0.3745 - val_acc: 0.8677\n",
            "Epoch 1411/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3909 - acc: 0.8640 - val_loss: 0.3710 - val_acc: 0.8718\n",
            "Epoch 1412/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3907 - acc: 0.8637 - val_loss: 0.3764 - val_acc: 0.8685\n",
            "Epoch 1413/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3913 - acc: 0.8637 - val_loss: 0.3715 - val_acc: 0.8723\n",
            "Epoch 1414/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8643 - val_loss: 0.3710 - val_acc: 0.8720\n",
            "Epoch 1415/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3915 - acc: 0.8644 - val_loss: 0.3734 - val_acc: 0.8684\n",
            "Epoch 1416/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3883 - acc: 0.8643 - val_loss: 0.3758 - val_acc: 0.8700\n",
            "Epoch 1417/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3902 - acc: 0.8641 - val_loss: 0.3726 - val_acc: 0.8696\n",
            "Epoch 1418/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3892 - acc: 0.8641 - val_loss: 0.3686 - val_acc: 0.8697\n",
            "Epoch 1419/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8645 - val_loss: 0.3709 - val_acc: 0.8716\n",
            "Epoch 1420/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3909 - acc: 0.8639 - val_loss: 0.3774 - val_acc: 0.8703\n",
            "Epoch 1421/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8646 - val_loss: 0.3716 - val_acc: 0.8712\n",
            "Epoch 1422/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3913 - acc: 0.8644 - val_loss: 0.3767 - val_acc: 0.8648\n",
            "Epoch 1423/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3907 - acc: 0.8635 - val_loss: 0.3757 - val_acc: 0.8667\n",
            "Epoch 1424/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3900 - acc: 0.8637 - val_loss: 0.3735 - val_acc: 0.8704\n",
            "Epoch 1425/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3910 - acc: 0.8639 - val_loss: 0.3717 - val_acc: 0.8700\n",
            "Epoch 1426/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3908 - acc: 0.8643 - val_loss: 0.3745 - val_acc: 0.8712\n",
            "Epoch 1427/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3887 - acc: 0.8647 - val_loss: 0.3718 - val_acc: 0.8726\n",
            "Epoch 1428/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8652 - val_loss: 0.3707 - val_acc: 0.8716\n",
            "Epoch 1429/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3901 - acc: 0.8642 - val_loss: 0.3687 - val_acc: 0.8736\n",
            "Epoch 1430/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3905 - acc: 0.8637 - val_loss: 0.3713 - val_acc: 0.8690\n",
            "Epoch 1431/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3885 - acc: 0.8640 - val_loss: 0.3707 - val_acc: 0.8691\n",
            "Epoch 1432/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8633 - val_loss: 0.3714 - val_acc: 0.8713\n",
            "Epoch 1433/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3896 - acc: 0.8645 - val_loss: 0.3710 - val_acc: 0.8704\n",
            "Epoch 1434/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3904 - acc: 0.8636 - val_loss: 0.3712 - val_acc: 0.8708\n",
            "Epoch 1435/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3914 - acc: 0.8633 - val_loss: 0.3740 - val_acc: 0.8699\n",
            "Epoch 1436/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3904 - acc: 0.8640 - val_loss: 0.3713 - val_acc: 0.8698\n",
            "Epoch 1437/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8647 - val_loss: 0.3761 - val_acc: 0.8679\n",
            "Epoch 1438/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3902 - acc: 0.8647 - val_loss: 0.3691 - val_acc: 0.8720\n",
            "Epoch 1439/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8648 - val_loss: 0.3737 - val_acc: 0.8714\n",
            "Epoch 1440/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3889 - acc: 0.8645 - val_loss: 0.3721 - val_acc: 0.8701\n",
            "Epoch 1441/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3892 - acc: 0.8645 - val_loss: 0.3699 - val_acc: 0.8726\n",
            "Epoch 1442/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3900 - acc: 0.8645 - val_loss: 0.3740 - val_acc: 0.8658\n",
            "Epoch 1443/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3911 - acc: 0.8639 - val_loss: 0.3740 - val_acc: 0.8675\n",
            "Epoch 1444/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3902 - acc: 0.8637 - val_loss: 0.3706 - val_acc: 0.8720\n",
            "Epoch 1445/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3920 - acc: 0.8637 - val_loss: 0.3711 - val_acc: 0.8709\n",
            "Epoch 1446/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3898 - acc: 0.8641 - val_loss: 0.3755 - val_acc: 0.8704\n",
            "Epoch 1447/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8642 - val_loss: 0.3785 - val_acc: 0.8703\n",
            "Epoch 1448/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8641 - val_loss: 0.3780 - val_acc: 0.8682\n",
            "Epoch 1449/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3911 - acc: 0.8631 - val_loss: 0.3730 - val_acc: 0.8708\n",
            "Epoch 1450/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3906 - acc: 0.8637 - val_loss: 0.3704 - val_acc: 0.8724\n",
            "Epoch 1451/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3907 - acc: 0.8637 - val_loss: 0.3714 - val_acc: 0.8708\n",
            "Epoch 1452/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3906 - acc: 0.8646 - val_loss: 0.3734 - val_acc: 0.8706\n",
            "Epoch 1453/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3899 - acc: 0.8638 - val_loss: 0.3729 - val_acc: 0.8693\n",
            "Epoch 1454/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3883 - acc: 0.8641 - val_loss: 0.3736 - val_acc: 0.8707\n",
            "Epoch 1455/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3886 - acc: 0.8651 - val_loss: 0.3784 - val_acc: 0.8697\n",
            "Epoch 1456/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8638 - val_loss: 0.3762 - val_acc: 0.8694\n",
            "Epoch 1457/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8641 - val_loss: 0.3705 - val_acc: 0.8722\n",
            "Epoch 1458/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3898 - acc: 0.8643 - val_loss: 0.3729 - val_acc: 0.8705\n",
            "Epoch 1459/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3881 - acc: 0.8649 - val_loss: 0.3814 - val_acc: 0.8669\n",
            "Epoch 1460/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3900 - acc: 0.8639 - val_loss: 0.3757 - val_acc: 0.8687\n",
            "Epoch 1461/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3911 - acc: 0.8637 - val_loss: 0.3756 - val_acc: 0.8689\n",
            "Epoch 1462/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3893 - acc: 0.8647 - val_loss: 0.3730 - val_acc: 0.8691\n",
            "Epoch 1463/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3907 - acc: 0.8631 - val_loss: 0.3732 - val_acc: 0.8691\n",
            "Epoch 1464/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3892 - acc: 0.8648 - val_loss: 0.3711 - val_acc: 0.8705\n",
            "Epoch 1465/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3908 - acc: 0.8642 - val_loss: 0.3738 - val_acc: 0.8685\n",
            "Epoch 1466/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8643 - val_loss: 0.3753 - val_acc: 0.8682\n",
            "Epoch 1467/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3901 - acc: 0.8643 - val_loss: 0.3723 - val_acc: 0.8705\n",
            "Epoch 1468/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3893 - acc: 0.8645 - val_loss: 0.3741 - val_acc: 0.8693\n",
            "Epoch 1469/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3905 - acc: 0.8636 - val_loss: 0.3734 - val_acc: 0.8694\n",
            "Epoch 1470/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3917 - acc: 0.8633 - val_loss: 0.3717 - val_acc: 0.8720\n",
            "Epoch 1471/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3896 - acc: 0.8640 - val_loss: 0.3767 - val_acc: 0.8659\n",
            "Epoch 1472/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3885 - acc: 0.8645 - val_loss: 0.3719 - val_acc: 0.8681\n",
            "Epoch 1473/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8639 - val_loss: 0.3690 - val_acc: 0.8721\n",
            "Epoch 1474/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8640 - val_loss: 0.3752 - val_acc: 0.8703\n",
            "Epoch 1475/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3892 - acc: 0.8647 - val_loss: 0.3719 - val_acc: 0.8700\n",
            "Epoch 1476/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3883 - acc: 0.8643 - val_loss: 0.3735 - val_acc: 0.8700\n",
            "Epoch 1477/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3907 - acc: 0.8641 - val_loss: 0.3718 - val_acc: 0.8700\n",
            "Epoch 1478/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3901 - acc: 0.8645 - val_loss: 0.3744 - val_acc: 0.8696\n",
            "Epoch 1479/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3879 - acc: 0.8650 - val_loss: 0.3700 - val_acc: 0.8708\n",
            "Epoch 1480/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8646 - val_loss: 0.3708 - val_acc: 0.8706\n",
            "Epoch 1481/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8637 - val_loss: 0.3732 - val_acc: 0.8695\n",
            "Epoch 1482/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3899 - acc: 0.8643 - val_loss: 0.3818 - val_acc: 0.8659\n",
            "Epoch 1483/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8646 - val_loss: 0.3709 - val_acc: 0.8697\n",
            "Epoch 1484/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3901 - acc: 0.8646 - val_loss: 0.3734 - val_acc: 0.8693\n",
            "Epoch 1485/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3908 - acc: 0.8635 - val_loss: 0.3732 - val_acc: 0.8690\n",
            "Epoch 1486/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8635 - val_loss: 0.3724 - val_acc: 0.8699\n",
            "Epoch 1487/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3895 - acc: 0.8636 - val_loss: 0.3744 - val_acc: 0.8693\n",
            "Epoch 1488/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3921 - acc: 0.8636 - val_loss: 0.3827 - val_acc: 0.8660\n",
            "Epoch 1489/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8640 - val_loss: 0.3761 - val_acc: 0.8709\n",
            "Epoch 1490/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3878 - acc: 0.8652 - val_loss: 0.3744 - val_acc: 0.8707\n",
            "Epoch 1491/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8646 - val_loss: 0.3717 - val_acc: 0.8696\n",
            "Epoch 1492/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3907 - acc: 0.8643 - val_loss: 0.3734 - val_acc: 0.8715\n",
            "Epoch 1493/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3883 - acc: 0.8649 - val_loss: 0.3692 - val_acc: 0.8713\n",
            "Epoch 1494/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3889 - acc: 0.8645 - val_loss: 0.3741 - val_acc: 0.8703\n",
            "Epoch 1495/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3889 - acc: 0.8640 - val_loss: 0.3729 - val_acc: 0.8699\n",
            "Epoch 1496/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3899 - acc: 0.8643 - val_loss: 0.3747 - val_acc: 0.8688\n",
            "Epoch 1497/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3904 - acc: 0.8637 - val_loss: 0.3710 - val_acc: 0.8697\n",
            "Epoch 1498/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3891 - acc: 0.8643 - val_loss: 0.3716 - val_acc: 0.8711\n",
            "Epoch 1499/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3871 - acc: 0.8654 - val_loss: 0.3779 - val_acc: 0.8690\n",
            "Epoch 1500/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8641 - val_loss: 0.3709 - val_acc: 0.8689\n",
            "Epoch 1501/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3889 - acc: 0.8650 - val_loss: 0.3759 - val_acc: 0.8700\n",
            "Epoch 1502/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3906 - acc: 0.8635 - val_loss: 0.3725 - val_acc: 0.8705\n",
            "Epoch 1503/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8640 - val_loss: 0.3748 - val_acc: 0.8671\n",
            "Epoch 1504/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3919 - acc: 0.8636 - val_loss: 0.3747 - val_acc: 0.8709\n",
            "Epoch 1505/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3897 - acc: 0.8646 - val_loss: 0.3754 - val_acc: 0.8672\n",
            "Epoch 1506/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8644 - val_loss: 0.3692 - val_acc: 0.8707\n",
            "Epoch 1507/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8642 - val_loss: 0.3720 - val_acc: 0.8710\n",
            "Epoch 1508/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3892 - acc: 0.8640 - val_loss: 0.3766 - val_acc: 0.8684\n",
            "Epoch 1509/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8641 - val_loss: 0.3743 - val_acc: 0.8679\n",
            "Epoch 1510/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8641 - val_loss: 0.3709 - val_acc: 0.8710\n",
            "Epoch 1511/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8642 - val_loss: 0.3763 - val_acc: 0.8701\n",
            "Epoch 1512/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3924 - acc: 0.8637 - val_loss: 0.3700 - val_acc: 0.8702\n",
            "Epoch 1513/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3889 - acc: 0.8643 - val_loss: 0.3702 - val_acc: 0.8709\n",
            "Epoch 1514/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3899 - acc: 0.8639 - val_loss: 0.3768 - val_acc: 0.8685\n",
            "Epoch 1515/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8634 - val_loss: 0.3731 - val_acc: 0.8685\n",
            "Epoch 1516/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3893 - acc: 0.8645 - val_loss: 0.3717 - val_acc: 0.8726\n",
            "Epoch 1517/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3919 - acc: 0.8642 - val_loss: 0.3705 - val_acc: 0.8736\n",
            "Epoch 1518/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8655 - val_loss: 0.3718 - val_acc: 0.8720\n",
            "Epoch 1519/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3885 - acc: 0.8651 - val_loss: 0.3702 - val_acc: 0.8723\n",
            "Epoch 1520/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8641 - val_loss: 0.3730 - val_acc: 0.8701\n",
            "Epoch 1521/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3907 - acc: 0.8638 - val_loss: 0.3757 - val_acc: 0.8678\n",
            "Epoch 1522/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3905 - acc: 0.8639 - val_loss: 0.3738 - val_acc: 0.8693\n",
            "Epoch 1523/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8649 - val_loss: 0.3704 - val_acc: 0.8718\n",
            "Epoch 1524/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3879 - acc: 0.8645 - val_loss: 0.3709 - val_acc: 0.8697\n",
            "Epoch 1525/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3900 - acc: 0.8640 - val_loss: 0.3696 - val_acc: 0.8725\n",
            "Epoch 1526/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3899 - acc: 0.8643 - val_loss: 0.3774 - val_acc: 0.8657\n",
            "Epoch 1527/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3904 - acc: 0.8646 - val_loss: 0.3758 - val_acc: 0.8701\n",
            "Epoch 1528/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3889 - acc: 0.8640 - val_loss: 0.3732 - val_acc: 0.8701\n",
            "Epoch 1529/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3877 - acc: 0.8645 - val_loss: 0.3741 - val_acc: 0.8702\n",
            "Epoch 1530/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3888 - acc: 0.8639 - val_loss: 0.3709 - val_acc: 0.8707\n",
            "Epoch 1531/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3903 - acc: 0.8637 - val_loss: 0.3738 - val_acc: 0.8689\n",
            "Epoch 1532/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8648 - val_loss: 0.3729 - val_acc: 0.8695\n",
            "Epoch 1533/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3899 - acc: 0.8646 - val_loss: 0.3751 - val_acc: 0.8676\n",
            "Epoch 1534/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3888 - acc: 0.8647 - val_loss: 0.3708 - val_acc: 0.8704\n",
            "Epoch 1535/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3892 - acc: 0.8645 - val_loss: 0.3719 - val_acc: 0.8707\n",
            "Epoch 1536/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8637 - val_loss: 0.3784 - val_acc: 0.8679\n",
            "Epoch 1537/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8648 - val_loss: 0.3714 - val_acc: 0.8703\n",
            "Epoch 1538/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3889 - acc: 0.8647 - val_loss: 0.3721 - val_acc: 0.8689\n",
            "Epoch 1539/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3893 - acc: 0.8645 - val_loss: 0.3730 - val_acc: 0.8709\n",
            "Epoch 1540/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3896 - acc: 0.8637 - val_loss: 0.3719 - val_acc: 0.8720\n",
            "Epoch 1541/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3890 - acc: 0.8650 - val_loss: 0.3745 - val_acc: 0.8711\n",
            "Epoch 1542/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3900 - acc: 0.8643 - val_loss: 0.3673 - val_acc: 0.8718\n",
            "Epoch 1543/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8641 - val_loss: 0.3744 - val_acc: 0.8721\n",
            "Epoch 1544/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3870 - acc: 0.8652 - val_loss: 0.3727 - val_acc: 0.8703\n",
            "Epoch 1545/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8640 - val_loss: 0.3732 - val_acc: 0.8710\n",
            "Epoch 1546/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3889 - acc: 0.8642 - val_loss: 0.3725 - val_acc: 0.8695\n",
            "Epoch 1547/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8651 - val_loss: 0.3703 - val_acc: 0.8717\n",
            "Epoch 1548/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3905 - acc: 0.8645 - val_loss: 0.3725 - val_acc: 0.8683\n",
            "Epoch 1549/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3893 - acc: 0.8642 - val_loss: 0.3724 - val_acc: 0.8683\n",
            "Epoch 1550/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3873 - acc: 0.8641 - val_loss: 0.3826 - val_acc: 0.8671\n",
            "Epoch 1551/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8644 - val_loss: 0.3781 - val_acc: 0.8679\n",
            "Epoch 1552/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8641 - val_loss: 0.3727 - val_acc: 0.8694\n",
            "Epoch 1553/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3896 - acc: 0.8645 - val_loss: 0.3692 - val_acc: 0.8717\n",
            "Epoch 1554/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3890 - acc: 0.8646 - val_loss: 0.3735 - val_acc: 0.8690\n",
            "Epoch 1555/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3897 - acc: 0.8644 - val_loss: 0.3803 - val_acc: 0.8687\n",
            "Epoch 1556/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8640 - val_loss: 0.3765 - val_acc: 0.8687\n",
            "Epoch 1557/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3871 - acc: 0.8644 - val_loss: 0.3708 - val_acc: 0.8710\n",
            "Epoch 1558/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3897 - acc: 0.8641 - val_loss: 0.3743 - val_acc: 0.8698\n",
            "Epoch 1559/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3898 - acc: 0.8645 - val_loss: 0.3784 - val_acc: 0.8690\n",
            "Epoch 1560/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3913 - acc: 0.8637 - val_loss: 0.3739 - val_acc: 0.8701\n",
            "Epoch 1561/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3903 - acc: 0.8644 - val_loss: 0.3722 - val_acc: 0.8703\n",
            "Epoch 1562/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3897 - acc: 0.8646 - val_loss: 0.3713 - val_acc: 0.8721\n",
            "Epoch 1563/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8646 - val_loss: 0.3731 - val_acc: 0.8721\n",
            "Epoch 1564/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3888 - acc: 0.8643 - val_loss: 0.3724 - val_acc: 0.8718\n",
            "Epoch 1565/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3882 - acc: 0.8645 - val_loss: 0.3743 - val_acc: 0.8690\n",
            "Epoch 1566/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8643 - val_loss: 0.3710 - val_acc: 0.8718\n",
            "Epoch 1567/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3903 - acc: 0.8641 - val_loss: 0.3736 - val_acc: 0.8696\n",
            "Epoch 1568/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3899 - acc: 0.8645 - val_loss: 0.3763 - val_acc: 0.8707\n",
            "Epoch 1569/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3898 - acc: 0.8647 - val_loss: 0.3848 - val_acc: 0.8679\n",
            "Epoch 1570/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3900 - acc: 0.8637 - val_loss: 0.3702 - val_acc: 0.8717\n",
            "Epoch 1571/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8648 - val_loss: 0.3780 - val_acc: 0.8683\n",
            "Epoch 1572/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3900 - acc: 0.8640 - val_loss: 0.3807 - val_acc: 0.8672\n",
            "Epoch 1573/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3890 - acc: 0.8642 - val_loss: 0.3734 - val_acc: 0.8711\n",
            "Epoch 1574/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8644 - val_loss: 0.3719 - val_acc: 0.8718\n",
            "Epoch 1575/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8648 - val_loss: 0.3754 - val_acc: 0.8702\n",
            "Epoch 1576/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3896 - acc: 0.8645 - val_loss: 0.3726 - val_acc: 0.8718\n",
            "Epoch 1577/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8646 - val_loss: 0.3767 - val_acc: 0.8685\n",
            "Epoch 1578/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3890 - acc: 0.8640 - val_loss: 0.3694 - val_acc: 0.8726\n",
            "Epoch 1579/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3887 - acc: 0.8648 - val_loss: 0.3718 - val_acc: 0.8713\n",
            "Epoch 1580/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3908 - acc: 0.8637 - val_loss: 0.3699 - val_acc: 0.8707\n",
            "Epoch 1581/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3900 - acc: 0.8636 - val_loss: 0.3720 - val_acc: 0.8723\n",
            "Epoch 1582/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3868 - acc: 0.8659 - val_loss: 0.3740 - val_acc: 0.8677\n",
            "Epoch 1583/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3901 - acc: 0.8649 - val_loss: 0.3760 - val_acc: 0.8666\n",
            "Epoch 1584/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3909 - acc: 0.8635 - val_loss: 0.3729 - val_acc: 0.8707\n",
            "Epoch 1585/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3888 - acc: 0.8647 - val_loss: 0.3729 - val_acc: 0.8696\n",
            "Epoch 1586/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3903 - acc: 0.8637 - val_loss: 0.3721 - val_acc: 0.8708\n",
            "Epoch 1587/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8649 - val_loss: 0.3743 - val_acc: 0.8694\n",
            "Epoch 1588/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3907 - acc: 0.8645 - val_loss: 0.3745 - val_acc: 0.8703\n",
            "Epoch 1589/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3880 - acc: 0.8647 - val_loss: 0.3724 - val_acc: 0.8700\n",
            "Epoch 1590/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3890 - acc: 0.8637 - val_loss: 0.3689 - val_acc: 0.8712\n",
            "Epoch 1591/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3900 - acc: 0.8634 - val_loss: 0.3707 - val_acc: 0.8708\n",
            "Epoch 1592/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3878 - acc: 0.8647 - val_loss: 0.3756 - val_acc: 0.8695\n",
            "Epoch 1593/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8644 - val_loss: 0.3735 - val_acc: 0.8708\n",
            "Epoch 1594/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8642 - val_loss: 0.3681 - val_acc: 0.8712\n",
            "Epoch 1595/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3897 - acc: 0.8649 - val_loss: 0.3711 - val_acc: 0.8705\n",
            "Epoch 1596/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3888 - acc: 0.8646 - val_loss: 0.3741 - val_acc: 0.8689\n",
            "Epoch 1597/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8646 - val_loss: 0.3684 - val_acc: 0.8717\n",
            "Epoch 1598/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3880 - acc: 0.8657 - val_loss: 0.3725 - val_acc: 0.8705\n",
            "Epoch 1599/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3872 - acc: 0.8657 - val_loss: 0.3683 - val_acc: 0.8720\n",
            "Epoch 1600/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3888 - acc: 0.8645 - val_loss: 0.3748 - val_acc: 0.8679\n",
            "Epoch 1601/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8641 - val_loss: 0.3742 - val_acc: 0.8696\n",
            "Epoch 1602/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8654 - val_loss: 0.3711 - val_acc: 0.8709\n",
            "Epoch 1603/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8644 - val_loss: 0.3767 - val_acc: 0.8656\n",
            "Epoch 1604/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8651 - val_loss: 0.3752 - val_acc: 0.8701\n",
            "Epoch 1605/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8648 - val_loss: 0.3737 - val_acc: 0.8696\n",
            "Epoch 1606/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8643 - val_loss: 0.3726 - val_acc: 0.8695\n",
            "Epoch 1607/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3878 - acc: 0.8649 - val_loss: 0.3773 - val_acc: 0.8719\n",
            "Epoch 1608/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3886 - acc: 0.8643 - val_loss: 0.3726 - val_acc: 0.8709\n",
            "Epoch 1609/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3903 - acc: 0.8646 - val_loss: 0.3718 - val_acc: 0.8712\n",
            "Epoch 1610/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3903 - acc: 0.8646 - val_loss: 0.3706 - val_acc: 0.8718\n",
            "Epoch 1611/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3888 - acc: 0.8638 - val_loss: 0.3723 - val_acc: 0.8693\n",
            "Epoch 1612/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3875 - acc: 0.8650 - val_loss: 0.3722 - val_acc: 0.8687\n",
            "Epoch 1613/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3881 - acc: 0.8643 - val_loss: 0.3755 - val_acc: 0.8697\n",
            "Epoch 1614/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8646 - val_loss: 0.3844 - val_acc: 0.8627\n",
            "Epoch 1615/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8645 - val_loss: 0.3709 - val_acc: 0.8707\n",
            "Epoch 1616/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3915 - acc: 0.8641 - val_loss: 0.3717 - val_acc: 0.8690\n",
            "Epoch 1617/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3899 - acc: 0.8637 - val_loss: 0.3723 - val_acc: 0.8715\n",
            "Epoch 1618/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3878 - acc: 0.8643 - val_loss: 0.3691 - val_acc: 0.8720\n",
            "Epoch 1619/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8646 - val_loss: 0.3762 - val_acc: 0.8692\n",
            "Epoch 1620/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3912 - acc: 0.8637 - val_loss: 0.3729 - val_acc: 0.8716\n",
            "Epoch 1621/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3881 - acc: 0.8658 - val_loss: 0.3729 - val_acc: 0.8670\n",
            "Epoch 1622/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8645 - val_loss: 0.3784 - val_acc: 0.8701\n",
            "Epoch 1623/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3878 - acc: 0.8646 - val_loss: 0.3714 - val_acc: 0.8700\n",
            "Epoch 1624/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8640 - val_loss: 0.3701 - val_acc: 0.8710\n",
            "Epoch 1625/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3895 - acc: 0.8640 - val_loss: 0.3764 - val_acc: 0.8709\n",
            "Epoch 1626/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3912 - acc: 0.8637 - val_loss: 0.3728 - val_acc: 0.8707\n",
            "Epoch 1627/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8657 - val_loss: 0.3729 - val_acc: 0.8702\n",
            "Epoch 1628/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8647 - val_loss: 0.3764 - val_acc: 0.8700\n",
            "Epoch 1629/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3892 - acc: 0.8644 - val_loss: 0.3753 - val_acc: 0.8697\n",
            "Epoch 1630/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3886 - acc: 0.8646 - val_loss: 0.3700 - val_acc: 0.8715\n",
            "Epoch 1631/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3889 - acc: 0.8650 - val_loss: 0.3798 - val_acc: 0.8700\n",
            "Epoch 1632/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8646 - val_loss: 0.3715 - val_acc: 0.8704\n",
            "Epoch 1633/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3876 - acc: 0.8653 - val_loss: 0.3731 - val_acc: 0.8707\n",
            "Epoch 1634/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3883 - acc: 0.8648 - val_loss: 0.3759 - val_acc: 0.8693\n",
            "Epoch 1635/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3914 - acc: 0.8638 - val_loss: 0.3719 - val_acc: 0.8679\n",
            "Epoch 1636/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3886 - acc: 0.8643 - val_loss: 0.3742 - val_acc: 0.8696\n",
            "Epoch 1637/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8646 - val_loss: 0.3724 - val_acc: 0.8716\n",
            "Epoch 1638/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3904 - acc: 0.8639 - val_loss: 0.3766 - val_acc: 0.8697\n",
            "Epoch 1639/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3878 - acc: 0.8650 - val_loss: 0.3744 - val_acc: 0.8685\n",
            "Epoch 1640/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3902 - acc: 0.8642 - val_loss: 0.3735 - val_acc: 0.8687\n",
            "Epoch 1641/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3910 - acc: 0.8635 - val_loss: 0.3887 - val_acc: 0.8639\n",
            "Epoch 1642/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3871 - acc: 0.8651 - val_loss: 0.3744 - val_acc: 0.8699\n",
            "Epoch 1643/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3875 - acc: 0.8647 - val_loss: 0.3721 - val_acc: 0.8709\n",
            "Epoch 1644/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8647 - val_loss: 0.3722 - val_acc: 0.8690\n",
            "Epoch 1645/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3886 - acc: 0.8643 - val_loss: 0.3711 - val_acc: 0.8700\n",
            "Epoch 1646/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3910 - acc: 0.8639 - val_loss: 0.3744 - val_acc: 0.8699\n",
            "Epoch 1647/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3889 - acc: 0.8643 - val_loss: 0.3729 - val_acc: 0.8702\n",
            "Epoch 1648/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3911 - acc: 0.8641 - val_loss: 0.3734 - val_acc: 0.8706\n",
            "Epoch 1649/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3898 - acc: 0.8643 - val_loss: 0.3724 - val_acc: 0.8711\n",
            "Epoch 1650/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8655 - val_loss: 0.3714 - val_acc: 0.8689\n",
            "Epoch 1651/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3875 - acc: 0.8651 - val_loss: 0.3743 - val_acc: 0.8701\n",
            "Epoch 1652/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8643 - val_loss: 0.3741 - val_acc: 0.8698\n",
            "Epoch 1653/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3890 - acc: 0.8640 - val_loss: 0.3786 - val_acc: 0.8700\n",
            "Epoch 1654/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8647 - val_loss: 0.3714 - val_acc: 0.8712\n",
            "Epoch 1655/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3881 - acc: 0.8647 - val_loss: 0.3748 - val_acc: 0.8691\n",
            "Epoch 1656/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3882 - acc: 0.8638 - val_loss: 0.3729 - val_acc: 0.8699\n",
            "Epoch 1657/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8653 - val_loss: 0.3727 - val_acc: 0.8696\n",
            "Epoch 1658/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3880 - acc: 0.8647 - val_loss: 0.3786 - val_acc: 0.8666\n",
            "Epoch 1659/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8645 - val_loss: 0.3700 - val_acc: 0.8696\n",
            "Epoch 1660/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8647 - val_loss: 0.3711 - val_acc: 0.8723\n",
            "Epoch 1661/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3892 - acc: 0.8646 - val_loss: 0.3807 - val_acc: 0.8671\n",
            "Epoch 1662/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3895 - acc: 0.8641 - val_loss: 0.3707 - val_acc: 0.8701\n",
            "Epoch 1663/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8637 - val_loss: 0.3725 - val_acc: 0.8711\n",
            "Epoch 1664/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8657 - val_loss: 0.3749 - val_acc: 0.8678\n",
            "Epoch 1665/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3904 - acc: 0.8639 - val_loss: 0.3704 - val_acc: 0.8730\n",
            "Epoch 1666/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3902 - acc: 0.8643 - val_loss: 0.3724 - val_acc: 0.8670\n",
            "Epoch 1667/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3887 - acc: 0.8643 - val_loss: 0.3691 - val_acc: 0.8737\n",
            "Epoch 1668/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3897 - acc: 0.8643 - val_loss: 0.3825 - val_acc: 0.8671\n",
            "Epoch 1669/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8648 - val_loss: 0.3709 - val_acc: 0.8700\n",
            "Epoch 1670/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3876 - acc: 0.8651 - val_loss: 0.3736 - val_acc: 0.8693\n",
            "Epoch 1671/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8652 - val_loss: 0.3730 - val_acc: 0.8709\n",
            "Epoch 1672/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8648 - val_loss: 0.3699 - val_acc: 0.8719\n",
            "Epoch 1673/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3874 - acc: 0.8647 - val_loss: 0.3811 - val_acc: 0.8677\n",
            "Epoch 1674/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8652 - val_loss: 0.3766 - val_acc: 0.8697\n",
            "Epoch 1675/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8647 - val_loss: 0.3717 - val_acc: 0.8681\n",
            "Epoch 1676/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8645 - val_loss: 0.3684 - val_acc: 0.8732\n",
            "Epoch 1677/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3905 - acc: 0.8644 - val_loss: 0.3706 - val_acc: 0.8710\n",
            "Epoch 1678/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3894 - acc: 0.8645 - val_loss: 0.3698 - val_acc: 0.8721\n",
            "Epoch 1679/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8648 - val_loss: 0.3690 - val_acc: 0.8711\n",
            "Epoch 1680/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8647 - val_loss: 0.3684 - val_acc: 0.8702\n",
            "Epoch 1681/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3870 - acc: 0.8645 - val_loss: 0.3717 - val_acc: 0.8700\n",
            "Epoch 1682/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8646 - val_loss: 0.3735 - val_acc: 0.8695\n",
            "Epoch 1683/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8642 - val_loss: 0.3731 - val_acc: 0.8691\n",
            "Epoch 1684/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3890 - acc: 0.8642 - val_loss: 0.3700 - val_acc: 0.8719\n",
            "Epoch 1685/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3895 - acc: 0.8645 - val_loss: 0.3739 - val_acc: 0.8697\n",
            "Epoch 1686/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3888 - acc: 0.8647 - val_loss: 0.3713 - val_acc: 0.8706\n",
            "Epoch 1687/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3890 - acc: 0.8651 - val_loss: 0.3699 - val_acc: 0.8708\n",
            "Epoch 1688/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8641 - val_loss: 0.3703 - val_acc: 0.8694\n",
            "Epoch 1689/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8645 - val_loss: 0.3733 - val_acc: 0.8701\n",
            "Epoch 1690/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3864 - acc: 0.8650 - val_loss: 0.3712 - val_acc: 0.8716\n",
            "Epoch 1691/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3896 - acc: 0.8644 - val_loss: 0.3708 - val_acc: 0.8710\n",
            "Epoch 1692/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3888 - acc: 0.8649 - val_loss: 0.3687 - val_acc: 0.8717\n",
            "Epoch 1693/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8649 - val_loss: 0.3706 - val_acc: 0.8701\n",
            "Epoch 1694/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8649 - val_loss: 0.3698 - val_acc: 0.8716\n",
            "Epoch 1695/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8644 - val_loss: 0.3788 - val_acc: 0.8657\n",
            "Epoch 1696/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3883 - acc: 0.8644 - val_loss: 0.3740 - val_acc: 0.8668\n",
            "Epoch 1697/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8649 - val_loss: 0.3774 - val_acc: 0.8648\n",
            "Epoch 1698/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8646 - val_loss: 0.3787 - val_acc: 0.8679\n",
            "Epoch 1699/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8640 - val_loss: 0.3759 - val_acc: 0.8692\n",
            "Epoch 1700/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3876 - acc: 0.8650 - val_loss: 0.3712 - val_acc: 0.8696\n",
            "Epoch 1701/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3874 - acc: 0.8642 - val_loss: 0.3725 - val_acc: 0.8697\n",
            "Epoch 1702/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3872 - acc: 0.8659 - val_loss: 0.3713 - val_acc: 0.8697\n",
            "Epoch 1703/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8652 - val_loss: 0.3705 - val_acc: 0.8701\n",
            "Epoch 1704/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8654 - val_loss: 0.3724 - val_acc: 0.8703\n",
            "Epoch 1705/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3888 - acc: 0.8644 - val_loss: 0.3784 - val_acc: 0.8678\n",
            "Epoch 1706/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3885 - acc: 0.8652 - val_loss: 0.3737 - val_acc: 0.8705\n",
            "Epoch 1707/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3865 - acc: 0.8647 - val_loss: 0.3746 - val_acc: 0.8705\n",
            "Epoch 1708/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3893 - acc: 0.8646 - val_loss: 0.3715 - val_acc: 0.8699\n",
            "Epoch 1709/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3871 - acc: 0.8654 - val_loss: 0.3694 - val_acc: 0.8717\n",
            "Epoch 1710/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3879 - acc: 0.8650 - val_loss: 0.3702 - val_acc: 0.8706\n",
            "Epoch 1711/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3886 - acc: 0.8650 - val_loss: 0.3769 - val_acc: 0.8698\n",
            "Epoch 1712/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3875 - acc: 0.8655 - val_loss: 0.3722 - val_acc: 0.8697\n",
            "Epoch 1713/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3898 - acc: 0.8637 - val_loss: 0.3768 - val_acc: 0.8683\n",
            "Epoch 1714/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3887 - acc: 0.8645 - val_loss: 0.3772 - val_acc: 0.8678\n",
            "Epoch 1715/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3888 - acc: 0.8646 - val_loss: 0.3712 - val_acc: 0.8691\n",
            "Epoch 1716/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3866 - acc: 0.8658 - val_loss: 0.3785 - val_acc: 0.8674\n",
            "Epoch 1717/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3891 - acc: 0.8658 - val_loss: 0.3682 - val_acc: 0.8711\n",
            "Epoch 1718/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3875 - acc: 0.8654 - val_loss: 0.3774 - val_acc: 0.8669\n",
            "Epoch 1719/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3879 - acc: 0.8655 - val_loss: 0.3766 - val_acc: 0.8670\n",
            "Epoch 1720/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3879 - acc: 0.8648 - val_loss: 0.3706 - val_acc: 0.8719\n",
            "Epoch 1721/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3878 - acc: 0.8650 - val_loss: 0.3706 - val_acc: 0.8715\n",
            "Epoch 1722/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3875 - acc: 0.8647 - val_loss: 0.3744 - val_acc: 0.8696\n",
            "Epoch 1723/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3885 - acc: 0.8649 - val_loss: 0.3771 - val_acc: 0.8679\n",
            "Epoch 1724/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3874 - acc: 0.8644 - val_loss: 0.3697 - val_acc: 0.8697\n",
            "Epoch 1725/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3880 - acc: 0.8643 - val_loss: 0.3697 - val_acc: 0.8711\n",
            "Epoch 1726/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3887 - acc: 0.8644 - val_loss: 0.3716 - val_acc: 0.8715\n",
            "Epoch 1727/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3879 - acc: 0.8649 - val_loss: 0.3707 - val_acc: 0.8705\n",
            "Epoch 1728/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3884 - acc: 0.8648 - val_loss: 0.3721 - val_acc: 0.8691\n",
            "Epoch 1729/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3892 - acc: 0.8647 - val_loss: 0.3755 - val_acc: 0.8723\n",
            "Epoch 1730/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3895 - acc: 0.8641 - val_loss: 0.3751 - val_acc: 0.8697\n",
            "Epoch 1731/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3871 - acc: 0.8645 - val_loss: 0.3735 - val_acc: 0.8700\n",
            "Epoch 1732/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3883 - acc: 0.8652 - val_loss: 0.3701 - val_acc: 0.8712\n",
            "Epoch 1733/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3876 - acc: 0.8648 - val_loss: 0.3714 - val_acc: 0.8709\n",
            "Epoch 1734/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3876 - acc: 0.8649 - val_loss: 0.3728 - val_acc: 0.8687\n",
            "Epoch 1735/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3876 - acc: 0.8657 - val_loss: 0.3781 - val_acc: 0.8669\n",
            "Epoch 1736/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3860 - acc: 0.8654 - val_loss: 0.3733 - val_acc: 0.8678\n",
            "Epoch 1737/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8659 - val_loss: 0.3795 - val_acc: 0.8670\n",
            "Epoch 1738/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3861 - acc: 0.8659 - val_loss: 0.3745 - val_acc: 0.8698\n",
            "Epoch 1739/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3878 - acc: 0.8641 - val_loss: 0.3716 - val_acc: 0.8670\n",
            "Epoch 1740/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3871 - acc: 0.8657 - val_loss: 0.3761 - val_acc: 0.8697\n",
            "Epoch 1741/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3893 - acc: 0.8643 - val_loss: 0.3732 - val_acc: 0.8703\n",
            "Epoch 1742/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8649 - val_loss: 0.3739 - val_acc: 0.8715\n",
            "Epoch 1743/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3865 - acc: 0.8650 - val_loss: 0.3746 - val_acc: 0.8721\n",
            "Epoch 1744/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3890 - acc: 0.8648 - val_loss: 0.3683 - val_acc: 0.8707\n",
            "Epoch 1745/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8652 - val_loss: 0.3703 - val_acc: 0.8726\n",
            "Epoch 1746/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8648 - val_loss: 0.3696 - val_acc: 0.8692\n",
            "Epoch 1747/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3872 - acc: 0.8650 - val_loss: 0.3711 - val_acc: 0.8701\n",
            "Epoch 1748/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3882 - acc: 0.8652 - val_loss: 0.3742 - val_acc: 0.8675\n",
            "Epoch 1749/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3873 - acc: 0.8651 - val_loss: 0.3729 - val_acc: 0.8703\n",
            "Epoch 1750/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3873 - acc: 0.8650 - val_loss: 0.3727 - val_acc: 0.8682\n",
            "Epoch 1751/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3878 - acc: 0.8649 - val_loss: 0.3732 - val_acc: 0.8690\n",
            "Epoch 1752/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8641 - val_loss: 0.3734 - val_acc: 0.8693\n",
            "Epoch 1753/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3885 - acc: 0.8647 - val_loss: 0.3717 - val_acc: 0.8692\n",
            "Epoch 1754/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3858 - acc: 0.8648 - val_loss: 0.3773 - val_acc: 0.8683\n",
            "Epoch 1755/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8646 - val_loss: 0.3770 - val_acc: 0.8704\n",
            "Epoch 1756/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8652 - val_loss: 0.3707 - val_acc: 0.8703\n",
            "Epoch 1757/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3904 - acc: 0.8637 - val_loss: 0.3767 - val_acc: 0.8672\n",
            "Epoch 1758/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3872 - acc: 0.8651 - val_loss: 0.3830 - val_acc: 0.8669\n",
            "Epoch 1759/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8646 - val_loss: 0.3731 - val_acc: 0.8707\n",
            "Epoch 1760/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8648 - val_loss: 0.3745 - val_acc: 0.8695\n",
            "Epoch 1761/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3862 - acc: 0.8653 - val_loss: 0.3707 - val_acc: 0.8732\n",
            "Epoch 1762/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3883 - acc: 0.8650 - val_loss: 0.3705 - val_acc: 0.8731\n",
            "Epoch 1763/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3874 - acc: 0.8651 - val_loss: 0.3709 - val_acc: 0.8722\n",
            "Epoch 1764/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3894 - acc: 0.8639 - val_loss: 0.3724 - val_acc: 0.8694\n",
            "Epoch 1765/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8639 - val_loss: 0.3715 - val_acc: 0.8705\n",
            "Epoch 1766/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8645 - val_loss: 0.3771 - val_acc: 0.8698\n",
            "Epoch 1767/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3890 - acc: 0.8645 - val_loss: 0.3730 - val_acc: 0.8709\n",
            "Epoch 1768/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3868 - acc: 0.8646 - val_loss: 0.3704 - val_acc: 0.8723\n",
            "Epoch 1769/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3890 - acc: 0.8646 - val_loss: 0.3688 - val_acc: 0.8707\n",
            "Epoch 1770/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3871 - acc: 0.8649 - val_loss: 0.3695 - val_acc: 0.8724\n",
            "Epoch 1771/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3855 - acc: 0.8653 - val_loss: 0.3691 - val_acc: 0.8722\n",
            "Epoch 1772/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8647 - val_loss: 0.3753 - val_acc: 0.8673\n",
            "Epoch 1773/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8647 - val_loss: 0.3740 - val_acc: 0.8700\n",
            "Epoch 1774/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8650 - val_loss: 0.3755 - val_acc: 0.8691\n",
            "Epoch 1775/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8654 - val_loss: 0.3697 - val_acc: 0.8710\n",
            "Epoch 1776/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3876 - acc: 0.8644 - val_loss: 0.3723 - val_acc: 0.8696\n",
            "Epoch 1777/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3902 - acc: 0.8639 - val_loss: 0.3708 - val_acc: 0.8704\n",
            "Epoch 1778/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8649 - val_loss: 0.3711 - val_acc: 0.8725\n",
            "Epoch 1779/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8650 - val_loss: 0.3741 - val_acc: 0.8689\n",
            "Epoch 1780/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8643 - val_loss: 0.3722 - val_acc: 0.8692\n",
            "Epoch 1781/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8655 - val_loss: 0.3704 - val_acc: 0.8708\n",
            "Epoch 1782/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3874 - acc: 0.8657 - val_loss: 0.3697 - val_acc: 0.8734\n",
            "Epoch 1783/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8651 - val_loss: 0.3742 - val_acc: 0.8679\n",
            "Epoch 1784/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3859 - acc: 0.8660 - val_loss: 0.3819 - val_acc: 0.8674\n",
            "Epoch 1785/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8649 - val_loss: 0.3725 - val_acc: 0.8725\n",
            "Epoch 1786/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3898 - acc: 0.8644 - val_loss: 0.3788 - val_acc: 0.8687\n",
            "Epoch 1787/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3873 - acc: 0.8645 - val_loss: 0.3703 - val_acc: 0.8729\n",
            "Epoch 1788/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3872 - acc: 0.8647 - val_loss: 0.3687 - val_acc: 0.8721\n",
            "Epoch 1789/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3879 - acc: 0.8651 - val_loss: 0.3740 - val_acc: 0.8703\n",
            "Epoch 1790/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3885 - acc: 0.8649 - val_loss: 0.3733 - val_acc: 0.8678\n",
            "Epoch 1791/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3864 - acc: 0.8656 - val_loss: 0.3783 - val_acc: 0.8703\n",
            "Epoch 1792/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3862 - acc: 0.8649 - val_loss: 0.3754 - val_acc: 0.8701\n",
            "Epoch 1793/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3878 - acc: 0.8656 - val_loss: 0.3753 - val_acc: 0.8681\n",
            "Epoch 1794/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3874 - acc: 0.8647 - val_loss: 0.3694 - val_acc: 0.8708\n",
            "Epoch 1795/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3892 - acc: 0.8646 - val_loss: 0.3689 - val_acc: 0.8729\n",
            "Epoch 1796/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3879 - acc: 0.8652 - val_loss: 0.3829 - val_acc: 0.8659\n",
            "Epoch 1797/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3861 - acc: 0.8653 - val_loss: 0.3732 - val_acc: 0.8693\n",
            "Epoch 1798/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8649 - val_loss: 0.3744 - val_acc: 0.8679\n",
            "Epoch 1799/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8645 - val_loss: 0.3761 - val_acc: 0.8675\n",
            "Epoch 1800/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8647 - val_loss: 0.3774 - val_acc: 0.8676\n",
            "Epoch 1801/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3866 - acc: 0.8656 - val_loss: 0.3759 - val_acc: 0.8693\n",
            "Epoch 1802/5000\n",
            "179991/179991 [==============================] - 10s 55us/step - loss: 0.3858 - acc: 0.8647 - val_loss: 0.3702 - val_acc: 0.8700\n",
            "Epoch 1803/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3862 - acc: 0.8659 - val_loss: 0.3752 - val_acc: 0.8697\n",
            "Epoch 1804/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3883 - acc: 0.8649 - val_loss: 0.3712 - val_acc: 0.8694\n",
            "Epoch 1805/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8640 - val_loss: 0.3696 - val_acc: 0.8705\n",
            "Epoch 1806/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3873 - acc: 0.8652 - val_loss: 0.3716 - val_acc: 0.8714\n",
            "Epoch 1807/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8653 - val_loss: 0.3672 - val_acc: 0.8726\n",
            "Epoch 1808/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8644 - val_loss: 0.3744 - val_acc: 0.8687\n",
            "Epoch 1809/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8643 - val_loss: 0.3721 - val_acc: 0.8713\n",
            "Epoch 1810/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3890 - acc: 0.8644 - val_loss: 0.3757 - val_acc: 0.8676\n",
            "Epoch 1811/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3888 - acc: 0.8640 - val_loss: 0.3710 - val_acc: 0.8715\n",
            "Epoch 1812/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3869 - acc: 0.8653 - val_loss: 0.3773 - val_acc: 0.8688\n",
            "Epoch 1813/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3876 - acc: 0.8648 - val_loss: 0.3724 - val_acc: 0.8701\n",
            "Epoch 1814/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8646 - val_loss: 0.3723 - val_acc: 0.8715\n",
            "Epoch 1815/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3875 - acc: 0.8651 - val_loss: 0.3740 - val_acc: 0.8703\n",
            "Epoch 1816/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8652 - val_loss: 0.3724 - val_acc: 0.8727\n",
            "Epoch 1817/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3887 - acc: 0.8641 - val_loss: 0.3741 - val_acc: 0.8711\n",
            "Epoch 1818/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3862 - acc: 0.8657 - val_loss: 0.3716 - val_acc: 0.8703\n",
            "Epoch 1819/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3865 - acc: 0.8652 - val_loss: 0.3766 - val_acc: 0.8692\n",
            "Epoch 1820/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3887 - acc: 0.8646 - val_loss: 0.3760 - val_acc: 0.8687\n",
            "Epoch 1821/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8658 - val_loss: 0.3759 - val_acc: 0.8661\n",
            "Epoch 1822/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3880 - acc: 0.8648 - val_loss: 0.3709 - val_acc: 0.8715\n",
            "Epoch 1823/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3882 - acc: 0.8655 - val_loss: 0.3779 - val_acc: 0.8688\n",
            "Epoch 1824/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3875 - acc: 0.8647 - val_loss: 0.3755 - val_acc: 0.8690\n",
            "Epoch 1825/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3895 - acc: 0.8640 - val_loss: 0.3745 - val_acc: 0.8708\n",
            "Epoch 1826/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8644 - val_loss: 0.3696 - val_acc: 0.8707\n",
            "Epoch 1827/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3908 - acc: 0.8639 - val_loss: 0.3724 - val_acc: 0.8687\n",
            "Epoch 1828/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8654 - val_loss: 0.3687 - val_acc: 0.8712\n",
            "Epoch 1829/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3867 - acc: 0.8649 - val_loss: 0.3747 - val_acc: 0.8691\n",
            "Epoch 1830/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3876 - acc: 0.8650 - val_loss: 0.3737 - val_acc: 0.8704\n",
            "Epoch 1831/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3855 - acc: 0.8653 - val_loss: 0.3707 - val_acc: 0.8719\n",
            "Epoch 1832/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8656 - val_loss: 0.3748 - val_acc: 0.8695\n",
            "Epoch 1833/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3884 - acc: 0.8640 - val_loss: 0.3698 - val_acc: 0.8720\n",
            "Epoch 1834/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3879 - acc: 0.8651 - val_loss: 0.3708 - val_acc: 0.8730\n",
            "Epoch 1835/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8645 - val_loss: 0.3730 - val_acc: 0.8699\n",
            "Epoch 1836/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3881 - acc: 0.8650 - val_loss: 0.3813 - val_acc: 0.8650\n",
            "Epoch 1837/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3877 - acc: 0.8656 - val_loss: 0.3748 - val_acc: 0.8691\n",
            "Epoch 1838/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3875 - acc: 0.8655 - val_loss: 0.3694 - val_acc: 0.8731\n",
            "Epoch 1839/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3872 - acc: 0.8653 - val_loss: 0.3717 - val_acc: 0.8714\n",
            "Epoch 1840/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3861 - acc: 0.8653 - val_loss: 0.3769 - val_acc: 0.8686\n",
            "Epoch 1841/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8644 - val_loss: 0.3835 - val_acc: 0.8685\n",
            "Epoch 1842/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3881 - acc: 0.8651 - val_loss: 0.3731 - val_acc: 0.8712\n",
            "Epoch 1843/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3886 - acc: 0.8642 - val_loss: 0.3711 - val_acc: 0.8707\n",
            "Epoch 1844/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3888 - acc: 0.8647 - val_loss: 0.3735 - val_acc: 0.8688\n",
            "Epoch 1845/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3897 - acc: 0.8642 - val_loss: 0.3688 - val_acc: 0.8738\n",
            "Epoch 1846/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3878 - acc: 0.8645 - val_loss: 0.3731 - val_acc: 0.8700\n",
            "Epoch 1847/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3879 - acc: 0.8656 - val_loss: 0.3719 - val_acc: 0.8695\n",
            "Epoch 1848/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8643 - val_loss: 0.3726 - val_acc: 0.8696\n",
            "Epoch 1849/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3878 - acc: 0.8644 - val_loss: 0.3685 - val_acc: 0.8711\n",
            "Epoch 1850/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3850 - acc: 0.8656 - val_loss: 0.3726 - val_acc: 0.8708\n",
            "Epoch 1851/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3855 - acc: 0.8653 - val_loss: 0.3772 - val_acc: 0.8663\n",
            "Epoch 1852/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3864 - acc: 0.8659 - val_loss: 0.3719 - val_acc: 0.8697\n",
            "Epoch 1853/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3885 - acc: 0.8642 - val_loss: 0.3758 - val_acc: 0.8692\n",
            "Epoch 1854/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8643 - val_loss: 0.3734 - val_acc: 0.8701\n",
            "Epoch 1855/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8648 - val_loss: 0.3690 - val_acc: 0.8729\n",
            "Epoch 1856/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8648 - val_loss: 0.3751 - val_acc: 0.8701\n",
            "Epoch 1857/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3875 - acc: 0.8644 - val_loss: 0.3738 - val_acc: 0.8683\n",
            "Epoch 1858/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8643 - val_loss: 0.3744 - val_acc: 0.8679\n",
            "Epoch 1859/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3884 - acc: 0.8648 - val_loss: 0.3744 - val_acc: 0.8690\n",
            "Epoch 1860/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8655 - val_loss: 0.3732 - val_acc: 0.8714\n",
            "Epoch 1861/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3868 - acc: 0.8652 - val_loss: 0.3773 - val_acc: 0.8697\n",
            "Epoch 1862/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3862 - acc: 0.8654 - val_loss: 0.3733 - val_acc: 0.8685\n",
            "Epoch 1863/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3870 - acc: 0.8656 - val_loss: 0.3757 - val_acc: 0.8694\n",
            "Epoch 1864/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3884 - acc: 0.8646 - val_loss: 0.3768 - val_acc: 0.8707\n",
            "Epoch 1865/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8658 - val_loss: 0.3735 - val_acc: 0.8687\n",
            "Epoch 1866/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3889 - acc: 0.8646 - val_loss: 0.3741 - val_acc: 0.8697\n",
            "Epoch 1867/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3880 - acc: 0.8643 - val_loss: 0.3712 - val_acc: 0.8690\n",
            "Epoch 1868/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3856 - acc: 0.8654 - val_loss: 0.3709 - val_acc: 0.8701\n",
            "Epoch 1869/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3870 - acc: 0.8651 - val_loss: 0.3724 - val_acc: 0.8696\n",
            "Epoch 1870/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3867 - acc: 0.8658 - val_loss: 0.3691 - val_acc: 0.8719\n",
            "Epoch 1871/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3891 - acc: 0.8647 - val_loss: 0.3709 - val_acc: 0.8706\n",
            "Epoch 1872/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3878 - acc: 0.8648 - val_loss: 0.3694 - val_acc: 0.8720\n",
            "Epoch 1873/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8649 - val_loss: 0.3722 - val_acc: 0.8694\n",
            "Epoch 1874/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3876 - acc: 0.8645 - val_loss: 0.3734 - val_acc: 0.8710\n",
            "Epoch 1875/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3879 - acc: 0.8654 - val_loss: 0.3708 - val_acc: 0.8717\n",
            "Epoch 1876/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3883 - acc: 0.8646 - val_loss: 0.3752 - val_acc: 0.8700\n",
            "Epoch 1877/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3876 - acc: 0.8645 - val_loss: 0.3700 - val_acc: 0.8706\n",
            "Epoch 1878/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3880 - acc: 0.8654 - val_loss: 0.3717 - val_acc: 0.8708\n",
            "Epoch 1879/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8660 - val_loss: 0.3739 - val_acc: 0.8709\n",
            "Epoch 1880/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3876 - acc: 0.8650 - val_loss: 0.3686 - val_acc: 0.8720\n",
            "Epoch 1881/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3867 - acc: 0.8650 - val_loss: 0.3740 - val_acc: 0.8696\n",
            "Epoch 1882/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3873 - acc: 0.8653 - val_loss: 0.3685 - val_acc: 0.8712\n",
            "Epoch 1883/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3871 - acc: 0.8655 - val_loss: 0.3746 - val_acc: 0.8697\n",
            "Epoch 1884/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8651 - val_loss: 0.3687 - val_acc: 0.8724\n",
            "Epoch 1885/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3879 - acc: 0.8649 - val_loss: 0.3684 - val_acc: 0.8722\n",
            "Epoch 1886/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3882 - acc: 0.8650 - val_loss: 0.3736 - val_acc: 0.8707\n",
            "Epoch 1887/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8642 - val_loss: 0.3741 - val_acc: 0.8697\n",
            "Epoch 1888/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3889 - acc: 0.8645 - val_loss: 0.3732 - val_acc: 0.8705\n",
            "Epoch 1889/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3884 - acc: 0.8648 - val_loss: 0.3744 - val_acc: 0.8690\n",
            "Epoch 1890/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3854 - acc: 0.8656 - val_loss: 0.3720 - val_acc: 0.8694\n",
            "Epoch 1891/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3855 - acc: 0.8652 - val_loss: 0.3710 - val_acc: 0.8697\n",
            "Epoch 1892/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3873 - acc: 0.8648 - val_loss: 0.3768 - val_acc: 0.8688\n",
            "Epoch 1893/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3878 - acc: 0.8647 - val_loss: 0.3717 - val_acc: 0.8702\n",
            "Epoch 1894/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8653 - val_loss: 0.3712 - val_acc: 0.8690\n",
            "Epoch 1895/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3879 - acc: 0.8652 - val_loss: 0.3743 - val_acc: 0.8700\n",
            "Epoch 1896/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3870 - acc: 0.8651 - val_loss: 0.3719 - val_acc: 0.8717\n",
            "Epoch 1897/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8647 - val_loss: 0.3721 - val_acc: 0.8715\n",
            "Epoch 1898/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3852 - acc: 0.8654 - val_loss: 0.3684 - val_acc: 0.8732\n",
            "Epoch 1899/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3872 - acc: 0.8646 - val_loss: 0.3692 - val_acc: 0.8707\n",
            "Epoch 1900/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3868 - acc: 0.8652 - val_loss: 0.3750 - val_acc: 0.8673\n",
            "Epoch 1901/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3872 - acc: 0.8643 - val_loss: 0.3691 - val_acc: 0.8711\n",
            "Epoch 1902/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3877 - acc: 0.8649 - val_loss: 0.3743 - val_acc: 0.8694\n",
            "Epoch 1903/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3861 - acc: 0.8655 - val_loss: 0.3773 - val_acc: 0.8706\n",
            "Epoch 1904/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8649 - val_loss: 0.3709 - val_acc: 0.8729\n",
            "Epoch 1905/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3880 - acc: 0.8647 - val_loss: 0.3773 - val_acc: 0.8689\n",
            "Epoch 1906/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3867 - acc: 0.8654 - val_loss: 0.3742 - val_acc: 0.8685\n",
            "Epoch 1907/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3880 - acc: 0.8645 - val_loss: 0.3718 - val_acc: 0.8711\n",
            "Epoch 1908/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3884 - acc: 0.8649 - val_loss: 0.3717 - val_acc: 0.8709\n",
            "Epoch 1909/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3875 - acc: 0.8655 - val_loss: 0.3750 - val_acc: 0.8713\n",
            "Epoch 1910/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3861 - acc: 0.8658 - val_loss: 0.3718 - val_acc: 0.8711\n",
            "Epoch 1911/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8648 - val_loss: 0.3726 - val_acc: 0.8709\n",
            "Epoch 1912/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3858 - acc: 0.8661 - val_loss: 0.3727 - val_acc: 0.8710\n",
            "Epoch 1913/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8652 - val_loss: 0.3698 - val_acc: 0.8727\n",
            "Epoch 1914/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3868 - acc: 0.8652 - val_loss: 0.3753 - val_acc: 0.8689\n",
            "Epoch 1915/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8654 - val_loss: 0.3728 - val_acc: 0.8701\n",
            "Epoch 1916/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3852 - acc: 0.8652 - val_loss: 0.3765 - val_acc: 0.8670\n",
            "Epoch 1917/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3850 - acc: 0.8658 - val_loss: 0.3700 - val_acc: 0.8715\n",
            "Epoch 1918/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8648 - val_loss: 0.3762 - val_acc: 0.8687\n",
            "Epoch 1919/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3872 - acc: 0.8660 - val_loss: 0.3745 - val_acc: 0.8700\n",
            "Epoch 1920/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3867 - acc: 0.8657 - val_loss: 0.3707 - val_acc: 0.8706\n",
            "Epoch 1921/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3883 - acc: 0.8644 - val_loss: 0.3722 - val_acc: 0.8727\n",
            "Epoch 1922/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3857 - acc: 0.8650 - val_loss: 0.3725 - val_acc: 0.8697\n",
            "Epoch 1923/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3883 - acc: 0.8650 - val_loss: 0.3711 - val_acc: 0.8720\n",
            "Epoch 1924/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3842 - acc: 0.8664 - val_loss: 0.3747 - val_acc: 0.8710\n",
            "Epoch 1925/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3887 - acc: 0.8644 - val_loss: 0.3743 - val_acc: 0.8700\n",
            "Epoch 1926/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8654 - val_loss: 0.3727 - val_acc: 0.8714\n",
            "Epoch 1927/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3867 - acc: 0.8649 - val_loss: 0.3719 - val_acc: 0.8699\n",
            "Epoch 1928/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8649 - val_loss: 0.3699 - val_acc: 0.8693\n",
            "Epoch 1929/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3871 - acc: 0.8654 - val_loss: 0.3784 - val_acc: 0.8696\n",
            "Epoch 1930/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3868 - acc: 0.8650 - val_loss: 0.3751 - val_acc: 0.8713\n",
            "Epoch 1931/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3865 - acc: 0.8649 - val_loss: 0.3723 - val_acc: 0.8697\n",
            "Epoch 1932/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3875 - acc: 0.8651 - val_loss: 0.3721 - val_acc: 0.8686\n",
            "Epoch 1933/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3864 - acc: 0.8646 - val_loss: 0.3730 - val_acc: 0.8714\n",
            "Epoch 1934/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8648 - val_loss: 0.3773 - val_acc: 0.8679\n",
            "Epoch 1935/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3858 - acc: 0.8655 - val_loss: 0.3706 - val_acc: 0.8718\n",
            "Epoch 1936/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3859 - acc: 0.8658 - val_loss: 0.3703 - val_acc: 0.8725\n",
            "Epoch 1937/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8649 - val_loss: 0.3753 - val_acc: 0.8712\n",
            "Epoch 1938/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3883 - acc: 0.8642 - val_loss: 0.3748 - val_acc: 0.8679\n",
            "Epoch 1939/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3862 - acc: 0.8661 - val_loss: 0.3706 - val_acc: 0.8696\n",
            "Epoch 1940/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3880 - acc: 0.8640 - val_loss: 0.3727 - val_acc: 0.8708\n",
            "Epoch 1941/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8647 - val_loss: 0.3807 - val_acc: 0.8648\n",
            "Epoch 1942/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3865 - acc: 0.8648 - val_loss: 0.3751 - val_acc: 0.8701\n",
            "Epoch 1943/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3861 - acc: 0.8649 - val_loss: 0.3747 - val_acc: 0.8685\n",
            "Epoch 1944/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8650 - val_loss: 0.3746 - val_acc: 0.8704\n",
            "Epoch 1945/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8656 - val_loss: 0.3714 - val_acc: 0.8724\n",
            "Epoch 1946/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3862 - acc: 0.8650 - val_loss: 0.3714 - val_acc: 0.8717\n",
            "Epoch 1947/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3862 - acc: 0.8649 - val_loss: 0.3731 - val_acc: 0.8710\n",
            "Epoch 1948/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3844 - acc: 0.8660 - val_loss: 0.3733 - val_acc: 0.8721\n",
            "Epoch 1949/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3853 - acc: 0.8655 - val_loss: 0.3765 - val_acc: 0.8687\n",
            "Epoch 1950/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3875 - acc: 0.8651 - val_loss: 0.3679 - val_acc: 0.8705\n",
            "Epoch 1951/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3875 - acc: 0.8649 - val_loss: 0.3760 - val_acc: 0.8675\n",
            "Epoch 1952/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8653 - val_loss: 0.3727 - val_acc: 0.8690\n",
            "Epoch 1953/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3880 - acc: 0.8646 - val_loss: 0.3714 - val_acc: 0.8734\n",
            "Epoch 1954/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8639 - val_loss: 0.3749 - val_acc: 0.8713\n",
            "Epoch 1955/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3875 - acc: 0.8649 - val_loss: 0.3708 - val_acc: 0.8703\n",
            "Epoch 1956/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8655 - val_loss: 0.3724 - val_acc: 0.8690\n",
            "Epoch 1957/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8648 - val_loss: 0.3694 - val_acc: 0.8724\n",
            "Epoch 1958/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3857 - acc: 0.8652 - val_loss: 0.3734 - val_acc: 0.8686\n",
            "Epoch 1959/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3863 - acc: 0.8655 - val_loss: 0.3716 - val_acc: 0.8718\n",
            "Epoch 1960/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3848 - acc: 0.8651 - val_loss: 0.3677 - val_acc: 0.8708\n",
            "Epoch 1961/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3867 - acc: 0.8643 - val_loss: 0.3705 - val_acc: 0.8701\n",
            "Epoch 1962/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8647 - val_loss: 0.3724 - val_acc: 0.8709\n",
            "Epoch 1963/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8646 - val_loss: 0.3726 - val_acc: 0.8713\n",
            "Epoch 1964/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3863 - acc: 0.8651 - val_loss: 0.3726 - val_acc: 0.8700\n",
            "Epoch 1965/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8651 - val_loss: 0.3711 - val_acc: 0.8722\n",
            "Epoch 1966/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8642 - val_loss: 0.3738 - val_acc: 0.8695\n",
            "Epoch 1967/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3865 - acc: 0.8651 - val_loss: 0.3778 - val_acc: 0.8708\n",
            "Epoch 1968/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3866 - acc: 0.8661 - val_loss: 0.3711 - val_acc: 0.8711\n",
            "Epoch 1969/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8643 - val_loss: 0.3718 - val_acc: 0.8701\n",
            "Epoch 1970/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3864 - acc: 0.8650 - val_loss: 0.3718 - val_acc: 0.8700\n",
            "Epoch 1971/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3866 - acc: 0.8652 - val_loss: 0.3720 - val_acc: 0.8712\n",
            "Epoch 1972/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3859 - acc: 0.8648 - val_loss: 0.3714 - val_acc: 0.8708\n",
            "Epoch 1973/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3862 - acc: 0.8658 - val_loss: 0.3748 - val_acc: 0.8688\n",
            "Epoch 1974/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8651 - val_loss: 0.3704 - val_acc: 0.8713\n",
            "Epoch 1975/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8646 - val_loss: 0.3723 - val_acc: 0.8707\n",
            "Epoch 1976/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8659 - val_loss: 0.3718 - val_acc: 0.8708\n",
            "Epoch 1977/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3868 - acc: 0.8647 - val_loss: 0.3738 - val_acc: 0.8701\n",
            "Epoch 1978/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8656 - val_loss: 0.3730 - val_acc: 0.8708\n",
            "Epoch 1979/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3872 - acc: 0.8651 - val_loss: 0.3703 - val_acc: 0.8703\n",
            "Epoch 1980/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3871 - acc: 0.8651 - val_loss: 0.3718 - val_acc: 0.8702\n",
            "Epoch 1981/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3889 - acc: 0.8640 - val_loss: 0.3754 - val_acc: 0.8685\n",
            "Epoch 1982/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3859 - acc: 0.8657 - val_loss: 0.3722 - val_acc: 0.8709\n",
            "Epoch 1983/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3861 - acc: 0.8650 - val_loss: 0.3721 - val_acc: 0.8715\n",
            "Epoch 1984/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3870 - acc: 0.8655 - val_loss: 0.3679 - val_acc: 0.8732\n",
            "Epoch 1985/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3855 - acc: 0.8658 - val_loss: 0.3706 - val_acc: 0.8709\n",
            "Epoch 1986/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3846 - acc: 0.8663 - val_loss: 0.3700 - val_acc: 0.8722\n",
            "Epoch 1987/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8644 - val_loss: 0.3703 - val_acc: 0.8720\n",
            "Epoch 1988/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3867 - acc: 0.8651 - val_loss: 0.3751 - val_acc: 0.8713\n",
            "Epoch 1989/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3862 - acc: 0.8662 - val_loss: 0.3794 - val_acc: 0.8688\n",
            "Epoch 1990/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8637 - val_loss: 0.3704 - val_acc: 0.8708\n",
            "Epoch 1991/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8657 - val_loss: 0.3709 - val_acc: 0.8701\n",
            "Epoch 1992/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3878 - acc: 0.8651 - val_loss: 0.3750 - val_acc: 0.8697\n",
            "Epoch 1993/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8647 - val_loss: 0.3757 - val_acc: 0.8676\n",
            "Epoch 1994/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3867 - acc: 0.8655 - val_loss: 0.3712 - val_acc: 0.8714\n",
            "Epoch 1995/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8648 - val_loss: 0.3739 - val_acc: 0.8683\n",
            "Epoch 1996/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8646 - val_loss: 0.3738 - val_acc: 0.8683\n",
            "Epoch 1997/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3868 - acc: 0.8656 - val_loss: 0.3704 - val_acc: 0.8718\n",
            "Epoch 1998/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3872 - acc: 0.8651 - val_loss: 0.3708 - val_acc: 0.8702\n",
            "Epoch 1999/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8649 - val_loss: 0.3698 - val_acc: 0.8723\n",
            "Epoch 2000/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3872 - acc: 0.8649 - val_loss: 0.3767 - val_acc: 0.8688\n",
            "Epoch 2001/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3851 - acc: 0.8658 - val_loss: 0.3816 - val_acc: 0.8656\n",
            "Epoch 2002/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3867 - acc: 0.8655 - val_loss: 0.3715 - val_acc: 0.8681\n",
            "Epoch 2003/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3873 - acc: 0.8655 - val_loss: 0.3704 - val_acc: 0.8697\n",
            "Epoch 2004/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3885 - acc: 0.8652 - val_loss: 0.3704 - val_acc: 0.8717\n",
            "Epoch 2005/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3849 - acc: 0.8654 - val_loss: 0.3766 - val_acc: 0.8670\n",
            "Epoch 2006/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8651 - val_loss: 0.3708 - val_acc: 0.8707\n",
            "Epoch 2007/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8654 - val_loss: 0.3712 - val_acc: 0.8694\n",
            "Epoch 2008/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3858 - acc: 0.8652 - val_loss: 0.3726 - val_acc: 0.8687\n",
            "Epoch 2009/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3862 - acc: 0.8646 - val_loss: 0.3713 - val_acc: 0.8689\n",
            "Epoch 2010/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8660 - val_loss: 0.3795 - val_acc: 0.8704\n",
            "Epoch 2011/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3856 - acc: 0.8652 - val_loss: 0.3796 - val_acc: 0.8688\n",
            "Epoch 2012/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3846 - acc: 0.8657 - val_loss: 0.3690 - val_acc: 0.8731\n",
            "Epoch 2013/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3853 - acc: 0.8651 - val_loss: 0.3760 - val_acc: 0.8690\n",
            "Epoch 2014/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3864 - acc: 0.8654 - val_loss: 0.3712 - val_acc: 0.8711\n",
            "Epoch 2015/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3863 - acc: 0.8653 - val_loss: 0.3691 - val_acc: 0.8728\n",
            "Epoch 2016/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3859 - acc: 0.8657 - val_loss: 0.3751 - val_acc: 0.8679\n",
            "Epoch 2017/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3862 - acc: 0.8651 - val_loss: 0.3716 - val_acc: 0.8703\n",
            "Epoch 2018/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3865 - acc: 0.8654 - val_loss: 0.3683 - val_acc: 0.8721\n",
            "Epoch 2019/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3855 - acc: 0.8659 - val_loss: 0.3730 - val_acc: 0.8693\n",
            "Epoch 2020/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3886 - acc: 0.8650 - val_loss: 0.3698 - val_acc: 0.8707\n",
            "Epoch 2021/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8660 - val_loss: 0.3726 - val_acc: 0.8708\n",
            "Epoch 2022/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3868 - acc: 0.8651 - val_loss: 0.3719 - val_acc: 0.8685\n",
            "Epoch 2023/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3847 - acc: 0.8652 - val_loss: 0.3739 - val_acc: 0.8696\n",
            "Epoch 2024/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3863 - acc: 0.8654 - val_loss: 0.3748 - val_acc: 0.8688\n",
            "Epoch 2025/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3882 - acc: 0.8652 - val_loss: 0.3791 - val_acc: 0.8673\n",
            "Epoch 2026/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3876 - acc: 0.8645 - val_loss: 0.3738 - val_acc: 0.8711\n",
            "Epoch 2027/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8654 - val_loss: 0.3699 - val_acc: 0.8720\n",
            "Epoch 2028/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3852 - acc: 0.8651 - val_loss: 0.3702 - val_acc: 0.8713\n",
            "Epoch 2029/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3879 - acc: 0.8645 - val_loss: 0.3707 - val_acc: 0.8720\n",
            "Epoch 2030/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8656 - val_loss: 0.3762 - val_acc: 0.8700\n",
            "Epoch 2031/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3864 - acc: 0.8659 - val_loss: 0.3727 - val_acc: 0.8693\n",
            "Epoch 2032/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8659 - val_loss: 0.3742 - val_acc: 0.8694\n",
            "Epoch 2033/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3875 - acc: 0.8650 - val_loss: 0.3720 - val_acc: 0.8700\n",
            "Epoch 2034/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3869 - acc: 0.8645 - val_loss: 0.3721 - val_acc: 0.8711\n",
            "Epoch 2035/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3860 - acc: 0.8658 - val_loss: 0.3709 - val_acc: 0.8722\n",
            "Epoch 2036/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3871 - acc: 0.8651 - val_loss: 0.3734 - val_acc: 0.8702\n",
            "Epoch 2037/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3851 - acc: 0.8660 - val_loss: 0.3694 - val_acc: 0.8710\n",
            "Epoch 2038/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3839 - acc: 0.8664 - val_loss: 0.3741 - val_acc: 0.8701\n",
            "Epoch 2039/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3850 - acc: 0.8655 - val_loss: 0.3729 - val_acc: 0.8704\n",
            "Epoch 2040/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3855 - acc: 0.8652 - val_loss: 0.3728 - val_acc: 0.8712\n",
            "Epoch 2041/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8653 - val_loss: 0.3723 - val_acc: 0.8693\n",
            "Epoch 2042/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3872 - acc: 0.8646 - val_loss: 0.3764 - val_acc: 0.8705\n",
            "Epoch 2043/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8652 - val_loss: 0.3698 - val_acc: 0.8726\n",
            "Epoch 2044/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8655 - val_loss: 0.3722 - val_acc: 0.8703\n",
            "Epoch 2045/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3870 - acc: 0.8647 - val_loss: 0.3731 - val_acc: 0.8693\n",
            "Epoch 2046/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3874 - acc: 0.8649 - val_loss: 0.3692 - val_acc: 0.8724\n",
            "Epoch 2047/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3858 - acc: 0.8656 - val_loss: 0.3744 - val_acc: 0.8694\n",
            "Epoch 2048/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8657 - val_loss: 0.3711 - val_acc: 0.8701\n",
            "Epoch 2049/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3861 - acc: 0.8650 - val_loss: 0.3690 - val_acc: 0.8707\n",
            "Epoch 2050/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3861 - acc: 0.8652 - val_loss: 0.3694 - val_acc: 0.8720\n",
            "Epoch 2051/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3872 - acc: 0.8651 - val_loss: 0.3716 - val_acc: 0.8690\n",
            "Epoch 2052/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8651 - val_loss: 0.3715 - val_acc: 0.8700\n",
            "Epoch 2053/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3876 - acc: 0.8649 - val_loss: 0.3677 - val_acc: 0.8721\n",
            "Epoch 2054/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8659 - val_loss: 0.3731 - val_acc: 0.8705\n",
            "Epoch 2055/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3861 - acc: 0.8654 - val_loss: 0.3775 - val_acc: 0.8689\n",
            "Epoch 2056/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3858 - acc: 0.8656 - val_loss: 0.3713 - val_acc: 0.8708\n",
            "Epoch 2057/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3872 - acc: 0.8643 - val_loss: 0.3686 - val_acc: 0.8715\n",
            "Epoch 2058/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3861 - acc: 0.8657 - val_loss: 0.3696 - val_acc: 0.8716\n",
            "Epoch 2059/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3862 - acc: 0.8660 - val_loss: 0.3685 - val_acc: 0.8701\n",
            "Epoch 2060/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3855 - acc: 0.8657 - val_loss: 0.3751 - val_acc: 0.8700\n",
            "Epoch 2061/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3871 - acc: 0.8657 - val_loss: 0.3731 - val_acc: 0.8687\n",
            "Epoch 2062/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3834 - acc: 0.8666 - val_loss: 0.3704 - val_acc: 0.8718\n",
            "Epoch 2063/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3854 - acc: 0.8655 - val_loss: 0.3693 - val_acc: 0.8732\n",
            "Epoch 2064/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3840 - acc: 0.8658 - val_loss: 0.3708 - val_acc: 0.8723\n",
            "Epoch 2065/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3868 - acc: 0.8654 - val_loss: 0.3747 - val_acc: 0.8712\n",
            "Epoch 2066/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3864 - acc: 0.8658 - val_loss: 0.3707 - val_acc: 0.8697\n",
            "Epoch 2067/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8651 - val_loss: 0.3733 - val_acc: 0.8699\n",
            "Epoch 2068/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3874 - acc: 0.8649 - val_loss: 0.3754 - val_acc: 0.8698\n",
            "Epoch 2069/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8648 - val_loss: 0.3726 - val_acc: 0.8706\n",
            "Epoch 2070/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3852 - acc: 0.8657 - val_loss: 0.3720 - val_acc: 0.8715\n",
            "Epoch 2071/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3872 - acc: 0.8651 - val_loss: 0.3726 - val_acc: 0.8694\n",
            "Epoch 2072/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8648 - val_loss: 0.3757 - val_acc: 0.8687\n",
            "Epoch 2073/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3862 - acc: 0.8657 - val_loss: 0.3713 - val_acc: 0.8710\n",
            "Epoch 2074/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3861 - acc: 0.8651 - val_loss: 0.3699 - val_acc: 0.8728\n",
            "Epoch 2075/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3860 - acc: 0.8656 - val_loss: 0.3707 - val_acc: 0.8733\n",
            "Epoch 2076/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3871 - acc: 0.8651 - val_loss: 0.3746 - val_acc: 0.8696\n",
            "Epoch 2077/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3893 - acc: 0.8648 - val_loss: 0.3735 - val_acc: 0.8708\n",
            "Epoch 2078/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3847 - acc: 0.8661 - val_loss: 0.3763 - val_acc: 0.8705\n",
            "Epoch 2079/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3860 - acc: 0.8655 - val_loss: 0.3724 - val_acc: 0.8712\n",
            "Epoch 2080/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3863 - acc: 0.8656 - val_loss: 0.3730 - val_acc: 0.8716\n",
            "Epoch 2081/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3850 - acc: 0.8655 - val_loss: 0.3737 - val_acc: 0.8690\n",
            "Epoch 2082/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3860 - acc: 0.8658 - val_loss: 0.3788 - val_acc: 0.8689\n",
            "Epoch 2083/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3867 - acc: 0.8652 - val_loss: 0.3759 - val_acc: 0.8693\n",
            "Epoch 2084/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3881 - acc: 0.8644 - val_loss: 0.3711 - val_acc: 0.8714\n",
            "Epoch 2085/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3858 - acc: 0.8662 - val_loss: 0.3716 - val_acc: 0.8707\n",
            "Epoch 2086/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3853 - acc: 0.8656 - val_loss: 0.3763 - val_acc: 0.8667\n",
            "Epoch 2087/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3864 - acc: 0.8653 - val_loss: 0.3715 - val_acc: 0.8704\n",
            "Epoch 2088/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3857 - acc: 0.8662 - val_loss: 0.3707 - val_acc: 0.8707\n",
            "Epoch 2089/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3850 - acc: 0.8652 - val_loss: 0.3771 - val_acc: 0.8696\n",
            "Epoch 2090/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8652 - val_loss: 0.3724 - val_acc: 0.8704\n",
            "Epoch 2091/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3860 - acc: 0.8647 - val_loss: 0.3731 - val_acc: 0.8714\n",
            "Epoch 2092/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3862 - acc: 0.8655 - val_loss: 0.3726 - val_acc: 0.8700\n",
            "Epoch 2093/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3876 - acc: 0.8644 - val_loss: 0.3758 - val_acc: 0.8701\n",
            "Epoch 2094/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3852 - acc: 0.8662 - val_loss: 0.3702 - val_acc: 0.8720\n",
            "Epoch 2095/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3858 - acc: 0.8649 - val_loss: 0.3703 - val_acc: 0.8714\n",
            "Epoch 2096/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3860 - acc: 0.8650 - val_loss: 0.3712 - val_acc: 0.8711\n",
            "Epoch 2097/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3873 - acc: 0.8650 - val_loss: 0.3742 - val_acc: 0.8681\n",
            "Epoch 2098/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3862 - acc: 0.8656 - val_loss: 0.3743 - val_acc: 0.8700\n",
            "Epoch 2099/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8655 - val_loss: 0.3712 - val_acc: 0.8713\n",
            "Epoch 2100/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3853 - acc: 0.8652 - val_loss: 0.3694 - val_acc: 0.8719\n",
            "Epoch 2101/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3858 - acc: 0.8652 - val_loss: 0.3715 - val_acc: 0.8710\n",
            "Epoch 2102/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3858 - acc: 0.8664 - val_loss: 0.3743 - val_acc: 0.8699\n",
            "Epoch 2103/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3870 - acc: 0.8641 - val_loss: 0.3752 - val_acc: 0.8687\n",
            "Epoch 2104/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3881 - acc: 0.8640 - val_loss: 0.3719 - val_acc: 0.8724\n",
            "Epoch 2105/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3867 - acc: 0.8642 - val_loss: 0.3742 - val_acc: 0.8690\n",
            "Epoch 2106/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3870 - acc: 0.8646 - val_loss: 0.3692 - val_acc: 0.8727\n",
            "Epoch 2107/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3854 - acc: 0.8666 - val_loss: 0.3774 - val_acc: 0.8673\n",
            "Epoch 2108/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3849 - acc: 0.8655 - val_loss: 0.3807 - val_acc: 0.8646\n",
            "Epoch 2109/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3847 - acc: 0.8660 - val_loss: 0.3684 - val_acc: 0.8722\n",
            "Epoch 2110/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3856 - acc: 0.8662 - val_loss: 0.3734 - val_acc: 0.8709\n",
            "Epoch 2111/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3865 - acc: 0.8663 - val_loss: 0.3757 - val_acc: 0.8703\n",
            "Epoch 2112/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3860 - acc: 0.8652 - val_loss: 0.3691 - val_acc: 0.8710\n",
            "Epoch 2113/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3837 - acc: 0.8662 - val_loss: 0.3721 - val_acc: 0.8691\n",
            "Epoch 2114/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3850 - acc: 0.8650 - val_loss: 0.3691 - val_acc: 0.8713\n",
            "Epoch 2115/5000\n",
            "179991/179991 [==============================] - 9s 53us/step - loss: 0.3836 - acc: 0.8658 - val_loss: 0.3749 - val_acc: 0.8693\n",
            "Epoch 2116/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3847 - acc: 0.8661 - val_loss: 0.3755 - val_acc: 0.8689\n",
            "Epoch 2117/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3861 - acc: 0.8653 - val_loss: 0.3736 - val_acc: 0.8703\n",
            "Epoch 2118/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3871 - acc: 0.8649 - val_loss: 0.3696 - val_acc: 0.8722\n",
            "Epoch 2119/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3853 - acc: 0.8654 - val_loss: 0.3687 - val_acc: 0.8725\n",
            "Epoch 2120/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3856 - acc: 0.8656 - val_loss: 0.3712 - val_acc: 0.8693\n",
            "Epoch 2121/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3849 - acc: 0.8655 - val_loss: 0.3695 - val_acc: 0.8728\n",
            "Epoch 2122/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3865 - acc: 0.8653 - val_loss: 0.3713 - val_acc: 0.8716\n",
            "Epoch 2123/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3873 - acc: 0.8651 - val_loss: 0.3728 - val_acc: 0.8710\n",
            "Epoch 2124/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3851 - acc: 0.8644 - val_loss: 0.3733 - val_acc: 0.8721\n",
            "Epoch 2125/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3862 - acc: 0.8651 - val_loss: 0.3721 - val_acc: 0.8716\n",
            "Epoch 2126/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3864 - acc: 0.8652 - val_loss: 0.3734 - val_acc: 0.8710\n",
            "Epoch 2127/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3854 - acc: 0.8647 - val_loss: 0.3710 - val_acc: 0.8717\n",
            "Epoch 2128/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3868 - acc: 0.8647 - val_loss: 0.3722 - val_acc: 0.8706\n",
            "Epoch 2129/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3860 - acc: 0.8663 - val_loss: 0.3743 - val_acc: 0.8687\n",
            "Epoch 2130/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3849 - acc: 0.8660 - val_loss: 0.3720 - val_acc: 0.8703\n",
            "Epoch 2131/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3870 - acc: 0.8642 - val_loss: 0.3735 - val_acc: 0.8688\n",
            "Epoch 2132/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3854 - acc: 0.8653 - val_loss: 0.3737 - val_acc: 0.8701\n",
            "Epoch 2133/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3864 - acc: 0.8655 - val_loss: 0.3716 - val_acc: 0.8703\n",
            "Epoch 2134/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3863 - acc: 0.8657 - val_loss: 0.3734 - val_acc: 0.8705\n",
            "Epoch 2135/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3858 - acc: 0.8656 - val_loss: 0.3801 - val_acc: 0.8668\n",
            "Epoch 2136/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3869 - acc: 0.8649 - val_loss: 0.3729 - val_acc: 0.8715\n",
            "Epoch 2137/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3868 - acc: 0.8642 - val_loss: 0.3723 - val_acc: 0.8710\n",
            "Epoch 2138/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3861 - acc: 0.8656 - val_loss: 0.3694 - val_acc: 0.8718\n",
            "Epoch 2139/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8659 - val_loss: 0.3783 - val_acc: 0.8690\n",
            "Epoch 2140/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3870 - acc: 0.8655 - val_loss: 0.3725 - val_acc: 0.8718\n",
            "Epoch 2141/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3862 - acc: 0.8658 - val_loss: 0.3747 - val_acc: 0.8687\n",
            "Epoch 2142/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3842 - acc: 0.8649 - val_loss: 0.3700 - val_acc: 0.8711\n",
            "Epoch 2143/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3855 - acc: 0.8654 - val_loss: 0.3704 - val_acc: 0.8705\n",
            "Epoch 2144/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8647 - val_loss: 0.3726 - val_acc: 0.8697\n",
            "Epoch 2145/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3888 - acc: 0.8652 - val_loss: 0.3738 - val_acc: 0.8693\n",
            "Epoch 2146/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8649 - val_loss: 0.3726 - val_acc: 0.8701\n",
            "Epoch 2147/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3876 - acc: 0.8650 - val_loss: 0.3721 - val_acc: 0.8697\n",
            "Epoch 2148/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3877 - acc: 0.8646 - val_loss: 0.3697 - val_acc: 0.8714\n",
            "Epoch 2149/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3863 - acc: 0.8653 - val_loss: 0.3723 - val_acc: 0.8666\n",
            "Epoch 2150/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3863 - acc: 0.8654 - val_loss: 0.3733 - val_acc: 0.8701\n",
            "Epoch 2151/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3869 - acc: 0.8644 - val_loss: 0.3759 - val_acc: 0.8664\n",
            "Epoch 2152/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3864 - acc: 0.8651 - val_loss: 0.3787 - val_acc: 0.8655\n",
            "Epoch 2153/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3861 - acc: 0.8654 - val_loss: 0.3684 - val_acc: 0.8736\n",
            "Epoch 2154/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3860 - acc: 0.8657 - val_loss: 0.3738 - val_acc: 0.8689\n",
            "Epoch 2155/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3849 - acc: 0.8651 - val_loss: 0.3720 - val_acc: 0.8716\n",
            "Epoch 2156/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3865 - acc: 0.8654 - val_loss: 0.3697 - val_acc: 0.8732\n",
            "Epoch 2157/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3858 - acc: 0.8655 - val_loss: 0.3724 - val_acc: 0.8715\n",
            "Epoch 2158/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3855 - acc: 0.8652 - val_loss: 0.3698 - val_acc: 0.8709\n",
            "Epoch 2159/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3882 - acc: 0.8649 - val_loss: 0.3723 - val_acc: 0.8704\n",
            "Epoch 2160/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3847 - acc: 0.8650 - val_loss: 0.3703 - val_acc: 0.8713\n",
            "Epoch 2161/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3859 - acc: 0.8646 - val_loss: 0.3780 - val_acc: 0.8662\n",
            "Epoch 2162/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3859 - acc: 0.8660 - val_loss: 0.3767 - val_acc: 0.8703\n",
            "Epoch 2163/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3852 - acc: 0.8658 - val_loss: 0.3695 - val_acc: 0.8724\n",
            "Epoch 2164/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3863 - acc: 0.8652 - val_loss: 0.3718 - val_acc: 0.8693\n",
            "Epoch 2165/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3864 - acc: 0.8651 - val_loss: 0.3744 - val_acc: 0.8707\n",
            "Epoch 2166/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3865 - acc: 0.8648 - val_loss: 0.3696 - val_acc: 0.8713\n",
            "Epoch 2167/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3864 - acc: 0.8645 - val_loss: 0.3754 - val_acc: 0.8709\n",
            "Epoch 2168/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3858 - acc: 0.8654 - val_loss: 0.3728 - val_acc: 0.8723\n",
            "Epoch 2169/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3866 - acc: 0.8648 - val_loss: 0.3723 - val_acc: 0.8697\n",
            "Epoch 2170/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3858 - acc: 0.8652 - val_loss: 0.3720 - val_acc: 0.8703\n",
            "Epoch 2171/5000\n",
            "179991/179991 [==============================] - 9s 52us/step - loss: 0.3839 - acc: 0.8654 - val_loss: 0.3735 - val_acc: 0.8715\n",
            "Epoch 2172/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3860 - acc: 0.8650 - val_loss: 0.3708 - val_acc: 0.8722\n",
            "Epoch 2173/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3868 - acc: 0.8648 - val_loss: 0.3687 - val_acc: 0.8726\n",
            "Epoch 2174/5000\n",
            "179991/179991 [==============================] - 10s 53us/step - loss: 0.3848 - acc: 0.8663 - val_loss: 0.3730 - val_acc: 0.8707\n",
            "Epoch 2175/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3868 - acc: 0.8661 - val_loss: 0.3741 - val_acc: 0.8698\n",
            "Epoch 2176/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3860 - acc: 0.8662 - val_loss: 0.3764 - val_acc: 0.8683\n",
            "Epoch 2177/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3868 - acc: 0.8648 - val_loss: 0.3687 - val_acc: 0.8722\n",
            "Epoch 2178/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3850 - acc: 0.8653 - val_loss: 0.3699 - val_acc: 0.8718\n",
            "Epoch 2179/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3869 - acc: 0.8644 - val_loss: 0.3723 - val_acc: 0.8717\n",
            "Epoch 2180/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3852 - acc: 0.8656 - val_loss: 0.3737 - val_acc: 0.8707\n",
            "Epoch 2181/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3857 - acc: 0.8656 - val_loss: 0.3863 - val_acc: 0.8658\n",
            "Epoch 2182/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3849 - acc: 0.8656 - val_loss: 0.3714 - val_acc: 0.8713\n",
            "Epoch 2183/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3846 - acc: 0.8660 - val_loss: 0.3689 - val_acc: 0.8723\n",
            "Epoch 2184/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3851 - acc: 0.8650 - val_loss: 0.3781 - val_acc: 0.8694\n",
            "Epoch 2185/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3861 - acc: 0.8653 - val_loss: 0.3737 - val_acc: 0.8685\n",
            "Epoch 2186/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3873 - acc: 0.8646 - val_loss: 0.3704 - val_acc: 0.8722\n",
            "Epoch 2187/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3859 - acc: 0.8658 - val_loss: 0.3694 - val_acc: 0.8703\n",
            "Epoch 2188/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3865 - acc: 0.8649 - val_loss: 0.3782 - val_acc: 0.8659\n",
            "Epoch 2189/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3870 - acc: 0.8653 - val_loss: 0.3731 - val_acc: 0.8717\n",
            "Epoch 2190/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3866 - acc: 0.8651 - val_loss: 0.3785 - val_acc: 0.8687\n",
            "Epoch 2191/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3851 - acc: 0.8648 - val_loss: 0.3718 - val_acc: 0.8720\n",
            "Epoch 2192/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3845 - acc: 0.8656 - val_loss: 0.3721 - val_acc: 0.8707\n",
            "Epoch 2193/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3851 - acc: 0.8657 - val_loss: 0.3732 - val_acc: 0.8705\n",
            "Epoch 2194/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3854 - acc: 0.8657 - val_loss: 0.3690 - val_acc: 0.8722\n",
            "Epoch 2195/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3842 - acc: 0.8663 - val_loss: 0.3747 - val_acc: 0.8708\n",
            "Epoch 2196/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3842 - acc: 0.8655 - val_loss: 0.3714 - val_acc: 0.8703\n",
            "Epoch 2197/5000\n",
            "179991/179991 [==============================] - 9s 48us/step - loss: 0.3855 - acc: 0.8657 - val_loss: 0.3718 - val_acc: 0.8720\n",
            "Epoch 2198/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3847 - acc: 0.8661 - val_loss: 0.3726 - val_acc: 0.8690\n",
            "Epoch 2199/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3862 - acc: 0.8653 - val_loss: 0.3728 - val_acc: 0.8704\n",
            "Epoch 2200/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3865 - acc: 0.8657 - val_loss: 0.3717 - val_acc: 0.8713\n",
            "Epoch 2201/5000\n",
            "179991/179991 [==============================] - 9s 50us/step - loss: 0.3856 - acc: 0.8649 - val_loss: 0.3683 - val_acc: 0.8719\n",
            "Epoch 2202/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3857 - acc: 0.8657 - val_loss: 0.3719 - val_acc: 0.8707\n",
            "Epoch 2203/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3848 - acc: 0.8668 - val_loss: 0.3733 - val_acc: 0.8701\n",
            "Epoch 2204/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3871 - acc: 0.8650 - val_loss: 0.3715 - val_acc: 0.8708\n",
            "Epoch 2205/5000\n",
            "179991/179991 [==============================] - 9s 51us/step - loss: 0.3872 - acc: 0.8661 - val_loss: 0.3751 - val_acc: 0.8718\n",
            "Epoch 2206/5000\n",
            "179991/179991 [==============================] - 9s 49us/step - loss: 0.3867 - acc: 0.8651 - val_loss: 0.3681 - val_acc: 0.8729\n",
            "Epoch 2207/5000\n",
            "136960/179991 [=====================>........] - ETA: 2s - loss: 0.3887 - acc: 0.8646"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MvQveD-f3k1h",
        "outputId": "9e5d9480-df4e-437a-ea70-4f53af9e97b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# matplotlib으로 보기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('DACON DNN loss, acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss, acc')\n",
        "plt.legend(['train loss', 'test loss', 'train acc', 'test acc'])\n",
        "plt.show()\n",
        "\n",
        "# First\n",
        "# loss : 0.3751423681736819\n",
        "# acc : 0.8720957365285246\n",
        "\n",
        "# Second\n",
        "# loss : 0.37057404349997003\n",
        "# acc : 0.8689456582069397\n",
        "\n",
        "# Third\n",
        "# loss : 0.36412223417814554\n",
        "# acc : 0.8720468282699585\n",
        "\n",
        "# Fourth\n",
        "# loss: 0.3597\n",
        "\n",
        "# Fifth\n",
        "# loss: \n",
        "\n",
        "# 최소 0.35~0.33까지 떨어뜨려야 함\n",
        "# 참고 epoch 30% = earlystopping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7aHMjJFdEWA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}