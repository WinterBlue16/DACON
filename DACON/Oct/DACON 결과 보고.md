# DACON 결과 보고

> [산업제어시스템 보안위협 탐지 AI 경진대회](https://dacon.io/competitions/official/235624/overview/) 진행과정과 결과에 대한 보고

## 1. 정확도 변화

> 평가 점수 변화 기록

| 제출순서 |  제출일  |      점수       |
| :------: | :------: | :-------------: |
|    1     | 20.09.13 |  0.8903614536   |
|    2     | 20.09.14 |  0.8005963555   |
|    3     | 20.09.17 |  0.9328902426   |
|    4     | 20.09.18 |  0.9343413868   |
|    5     | 20.09.20 |  0.9361456159   |
|    6     | 20.09.21 |  0.9420776109   |
|    7     | 20.09.24 |  0.9450803133   |
|    8     | 20.09.27 | **0.954423468** |



## 2. 정확도 향상 과정

> 정확도 상승에 유의미한 영향을 미쳤던 파라미터를 정리하고 최적 파라미터 탐색

### 2.1 조정 하이퍼 파라미터 & 목표 기준 설정

본 대회에서 조정했던 파라미터는 다음과 같습니다. 정확도 향상에 큰 영향을 미쳤던 파라미터는 볼드체로 표시하였습니다. 



1. **TRAIN_DF normalize ewm(alpha)**
2. **THRESHOLD**
3. N_HIDDENS
4. N_LAYERS
5. BATCH_SIZE
6. WINDOW_GIVEN
7. WINDOW_SIZE



파라미터 조정만큼이나 중요했던 것은, 코드 내 TaP, TaR 점수가 실제 점수와 얼마나 유사점을 가지는가의 문제였습니다. 기준이 명확해야 목표 점수를 정할 수 있고, 어떤 파라미터가 결과에 영향을 미치는지 파악할 수 있기 때문입니다. 

파라미터 조정에 따라 어떤 경우에는 TaP만 증가하고, 어떤 경우에는 TaR이 증가하기도 했습니다. 꾸준히 submission을 제출하며 상관관계를 비교한 결과, TaP와 TaR이 동시에 높아야 하며, 한쪽의 점수가 높게 나온다고 하여 결과에 유의미한 영향을 미치는 것이 아니라는 점을 깨달았습니다. 특히, TaP와  TaR 점수의 차이가 어느 한쪽이 과도하게 높은 등 심각한 불균형을 이룰 때 결과 점수가 더욱 낮게 나오는 점을 확인하였습니다.



### 2.2 하이퍼 파라미터 조정

파라미터 조정 과정은 다음과 같습니다. 

초반에는 THRESHOLD 0.04를 기준으로 0.001 단위로 조정하며 정확도의 변화 추이를 관찰하였습니다. 



### 2.3 column 추가 및 삭제



### 2.4 최적 파라미터

> 실험 결과 정확도가 가장 높게 나온 최적 파라미터

| TRAIN_DF normalize ewm(alpha) | THRESHOLD | N_HIDDENS | N_LAYERS | BATCH_SIZE | WINDOW_GIVEN | WINDOW_SIZE | train_batchsize |
| :---------------------------: | :-------: | :-------: | :------: | :--------: | :----------: | :---------: | :-------------: |
|             0.81              |   0.391   |    100    |    3     |    512     |      89      |     90      |       32        |



## 3. 개선점

> 이상으로 배운 점과 개선할 점